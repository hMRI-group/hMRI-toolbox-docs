{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the hMRI Toolbox.</p>"},{"location":"contact/","title":"Contact","text":""},{"location":"contact/#contact-us","title":"Contact Us","text":"<p>Whether you are a seasoned user or a newcomer, we offer a variety of channels to assist you and facilitate insightful discussions. We are excited to help you make the most out of the hMRI Toolbox. If you are missing crucial information from the documentation pages here, please  open an issue and explain in detail what page needs to be improved or what additional information should be added.</p>"},{"location":"contact/#public-chat-on-gitter","title":"Public Chat on Gitter","text":"<p>Join our community on our public chat to engage in discussions and connect with other users as well as many hMRI Toolbox developers. It offers a space to share ideas, ask questions, and interact live with others.</p> <p>hMRI Toolbox Gitter Chat</p>"},{"location":"contact/#mailing-list","title":"Mailing List","text":"<p>Stay updated with the latest changes and discussions through our dedicated mailing list created for hMRI Toolbox users. Registered users can access the message archive on the list home page to catch up on previous discussions.</p> <p>Register for the mailing list</p>"},{"location":"contact/#issue-tracking-and-bug-reporting","title":"Issue Tracking and Bug Reporting","text":"<p>If you believe you have uncovered a bug, opening an issue on GitHub is the recommended way to proceed. However, it\u2019s always a good idea to browse open issues or ask on the mailing list or the chat first.</p> <p>Please refer to the Develop and Contribute page for detailed information on how to  report issues with all necessary information for us to reproduce it.</p>"},{"location":"information/","title":"Information","text":""},{"location":"information/#welcome","title":"Welcome","text":"<p>Neuroscience and clinical researchers are increasingly interested in quantitative magnetic resonance imaging (qMRI) due to its sensitivity to micro-structural properties of brain tissue such as axon, myelin, iron and water concentration (Weiskopf2015).</p> <p>The hMRI Toolbox is an easy-to-use open-source and flexible tool, for qMRI data handling and processing. It allows the estimation of high-quality multi-parameter qMRI maps (longitudinal and effective transverse relaxation rates R1 and R2*, proton density PD and magnetisation transfer MT saturation) (Weiskopf2013), followed by spatial registration in common space for statistical analysis (Draganski2011).</p> <p>Embedded in the Statistical Parametric Mapping (SPM) framework, it can be readily combined with existing SPM toolboxes for estimating diffusion MRI parameter maps, and it benefits from the extensive range of established SPM tools for high-accuracy spatial registration and statistical inferences.</p> <p>The qMRI maps generated by the toolbox can be used for quantitative parameter analysis and accurate delineation of subcortical brain structures. They are key input parameters for biophysical models designed to estimate tissue microstructure properties such as the MR g-ratio and to derive standard and novel MRI biomarkers (Mohammadi2015). The hMRI toolbox is therefore the first step towards in vivo histology using MRI (hMRI) and is being extended further in this direction.</p>"},{"location":"information/#developers-of-the-hmri-toolbox","title":"Developers of the hMRI Toolbox","text":"<p>The development of the hMRI Toolbox is an international collaborative effort including the following sites and developers:</p> <ul> <li>Luke Edwards, Baris Evren Ugurcan, Kornelius Podranski, Enrico Reimer, Tobias Leutritz, Nikolaus Weiskopf (Max Planck   Institute for Human Cognitive and Brain Sciences, Leipzig, Germany)</li> <li>Evelyne Balteau, Christophe Phillips (University of Liege, Liege, Belgium)</li> <li>Siawoosh Mohammadi (Medical Center Hamburg-Eppendorf, Hamburg, Germany)</li> <li>Martina F Callaghan, John Ashburner (University College London, London, United Kingdom)</li> <li>Karsten Tabelow (Weierstrass Institute for Applied Analysis and Stochastics, Berlin, Germany)</li> <li>Bogdan Draganski, Ferath Kerif, Antoine Lutti (LREN, DNC - CHUV, University Lausanne, Lausanne, Switzerland)</li> <li>Maryam Seif (University of Zurich, Zurich, Switzerland)</li> <li>Gunther Helms (Department of Medical Radiation Physics, Lund University, Lund, Sweden)</li> <li>Lars Ruthotto (Emory University, Atlanta, GA, United States)</li> <li>Gabriel Ziegler (Otto-von-Guericke-University Magdeburg, Magdeburg, Germany)</li> </ul>"},{"location":"information/#scientific-publications-and-how-to-cite","title":"Scientific Publications and How to Cite","text":"<p>For a reference on the scientific background, methods and concepts, or if you want to cite the hMRI Toolbox when  publishing results, please use the paper Tabelow et al., 2019:</p> <p>Info</p> <p>Tabelow K, Balteau E, Ashburner J, Callaghan MF, Draganski B, Helms G, Kherif F, Leutritz T, Lutti A, Phillips C, Reimer E, Ruthotto L, Seif M, Weiskopf N, Ziegler G, Mohammadi S (2019) hMRI \u2013 A toolbox for quantitative MRI in neuroscience and clinical research. Neuroimage. doi:10.1016/j.neuroimage.2019.01.029.</p> <p>This publication is also available as a pre-print paper and a conference poster is available here.</p>"},{"location":"information/#artwork","title":"Artwork","text":"<p>The official hMRI Toolbox artwork is available for download. It includes the banner and variations of the logo both for a dark and light background. Should you wish to incorporate our artwork into your own publication, we invite you to  download a ZIP file which contains all variations in different formats.</p> <p></p>"},{"location":"information/#acknowledgments-and-funding","title":"Acknowledgments and Funding","text":"<ul> <li>Evelyne Balteau received funding from the European Structural and Investment Fund / European Regional Development   Fund &amp; the Belgian Walloon Government, project BIOMED-HUB (programme 2014-2020).</li> <li>Nikolaus Weiskopf received funding from the European Research Council under the European Union\u2019s Seventh Framework   Programme (FP7/2007-2013) / ERC grant agreement No 616905. This project has received funding from the European Union\u2019s   Horizon 2020 research and innovation programme under the grant agreement No 681094, and is supported by the Swiss   State Secretariat for Education, Research and Innovation (SERI) under contract number 15.0137.</li> <li>Siawoosh Mohammadi received funding from the European Union\u2019s Horizon 2020 research and innovation programme under the   Marie Sklodowska-Curie grant agreement No 658589.</li> <li>Nikolaus Weiskopf and Siawoosh Mohammadi received funding from the BMBF (01EW1711A and B) in the framework of ERA-NET   NEURON. BD is supported by the Swiss National Science Foundation (NCCR Synapsy, project grant Nr 32003B_159780) and   Foundation Synapsis. LREN is very grateful to the Roger De Spoelberch and Partridge Foundations for their generous   financial support.</li> <li>Martina F Callaghan is supported by the MRC and Spinal Research Charity through the ERA-NET Neuron joint call (   MR/R000050/1).</li> <li>The Wellcome Centre for Human Neuroimaging is supported by core funding from the Wellcome [203147/Z/16/Z].</li> <li>Christophe Phillips is supported by the F.R.S.-FNRS, Belgium.</li> <li>The hMRI Toolbox project is supported by the Max Planck Society.</li> </ul>"},{"location":"development/","title":"Home","text":""},{"location":"development/#developing-the-hmri-toolbox","title":"Developing the hMRI Toolbox","text":"<p>The hMRI Toolbox is actively developed by a group of core developers together with contributions from community members. While most of the new method development happens inside the different scientific groups, some of the core developers participate in a monthly hackathon were we meet online, work on features, review pull requests and discuss issues or general software design.</p> <p>The pages here aim to give users all necessary information on how they can contribute to the hMRI Toolbox. This is by far not limited to writing code, but also includes improving the toolbox by reporting bugs and suggestions. For new developers, the guidelines show how to set up their own environment where they can work on improving the hMRI Toolbox and most importantly, merge it back into the main repository.</p>"},{"location":"development/api/","title":"API Reference","text":"<p>Below is only an example of what automatically generated function documentation could look like. However, to implement a tool that does the automatic extraction, it requires first that function comments within the hMRI Toolbox are consistent and follow a specific format that can be parsed.</p>"},{"location":"development/api/#function-hmri_calc_r1","title":"Function <code>hmri_calc_R1</code>","text":"<p>Calculate R1 map from PDw and T1w data.</p> Input <p>PDw and T1w are structs with the fields:</p> <ul> <li><code>{PDw,T1w}.data</code> (array of signals)</li> <li><code>{PDw,T1w}.fa</code>   (nominal flip angle, rad)</li> <li><code>{PDw,T1w}.TR</code>   (repetition time, s or ms)</li> <li><code>{PDw,T1w}.B1</code>   (array of B1 ratios: actual fa / nominal fa)</li> </ul> <p>small_angle_approx (bool which determines whether to use the small angle approximation [true] or to use a more exact formula [false])</p> Output <code>R1</code> (in reciprocal of TR units) Examples Estimate R1 using the small angle approximation: <pre><code>R1 = hmri_calc_R1(struct('data',data_pdw,'fa',fa_pdw,'TR',tr_pdw,'B1',b1map),...\nstruct('data',data_t1w,'fa',fa_t1w,'TR',tr_t1w,'B1',b1map), true);\nEstimate R1 without the small angle approximation:\nR1 = hmri_calc_R1(struct('data',data_pdw,'fa',fa_pdw,'TR',tr_pdw,'B1',b1map),...\nstruct('data',data_t1w,'fa',fa_t1w,'TR',tr_t1w,'B1',b1map), false);\n</code></pre> References <ul> <li>Helms et al. Magn. Reson. Med. (2008), \u201cQuantitative FLASH MRI at 3T using a rational approximation of the Ernst equation\u201d, https://doi.org/10.1002/mrm.21542</li> <li>If you use small_angle_approx=false: Edwards et al.  Magn. Reson. Mater. Phy. (2021), \u201cRational approximation of the Ernst equation for dual angle R1 mapping revisited: beyond the small flip-angle assumption\u201d in Book of Abstracts ESMRMB 2021, https://doi.org/10.1007/s10334-021-00947-8</li> </ul>"},{"location":"development/api/#function-hmri_calc_r1_1","title":"Function <code>hmri_calc_R1</code>","text":"<pre><code>function R1=hmri_calc_R1(PDw,T1w,small_angle_approx)\nhmri_calc_R1 Calculate R1 map from PDw and T1w data.\n\n Input:\n   PDw and T1w are structs with the fields:\n     {PDw,T1w}.data (array of signals)\n     {PDw,T1w}.fa   (nominal flip angle, rad)\n     {PDw,T1w}.TR   (repetition time, s or ms)\n     {PDw,T1w}.B1   (array of B1 ratios: actual fa / nominal fa)\n\n   small_angle_approx (bool which determines whether to use the small\n     angle approximation [true] or to use a more exact formula [false])\n\n Output:\n   R1 (in reciprocal of TR units)\n\n Examples:\n   Estimate R1 using the small angle approximation:\n       R1 = hmri_calc_R1(struct('data',data_pdw,'fa',fa_pdw,'TR',tr_pdw,'B1',b1map),...\n            struct('data',data_t1w,'fa',fa_t1w,'TR',tr_t1w,'B1',b1map), true);\n\n   Estimate R1 without the small angle approximation:\n       R1 = hmri_calc_R1(struct('data',data_pdw,'fa',fa_pdw,'TR',tr_pdw,'B1',b1map),...\n            struct('data',data_t1w,'fa',fa_t1w,'TR',tr_t1w,'B1',b1map), false);\n\n References:\n   Helms et al. Magn. Reson. Med. (2008), \"Quantitative FLASH MRI at 3T\n       using a rational approximation of the Ernst equation\",\n       https://doi.org/10.1002/mrm.21542\n\n   If you use small_angle_approx=false:\n       Edwards et al.  Magn. Reson. Mater. Phy. (2021), \"Rational\n           approximation of the Ernst equation for dual angle R1 mapping\n           revisited: beyond the small flip-angle assumption\" in Book of\n           Abstracts ESMRMB 2021,\n           https://doi.org/10.1007/s10334-021-00947-8\n</code></pre>"},{"location":"development/contribute/","title":"Contributing","text":""},{"location":"development/contribute/#contributing-to-the-hmri-toolbox","title":"Contributing to the hMRI Toolbox","text":"<p>Contributing to the hMRI Toolbox can be done in many ways and at many levels, from users to experienced developers. If you plan to contribute as a developer, an inspirational guide on how to contribute to open-source projects can be found here.</p> <p>However, contributing involves much more than just coding! It includes reporting bugs and discussing issues, supporting other users, contributing documentation and examples, making suggestions and writing new feature proposals, reviewing proposals, issues, and pull requests.</p> <p>Contributing to code by implementing bug fixes and new features is great, but contributing to any of these other aspects will be hugely appreciated.</p>"},{"location":"development/contribute/#issue-tracking","title":"Issue Tracking","text":"<p>There are several ways to contribute to the hMRI Toolbox issue tracker:</p> <ul> <li>by opening a new issue for discussion: e.g. if you believe that you have uncovered a bug,   creating a new issue in the hMRI Toolbox issue tracker is the way to report it.</li> <li>by helping to document an issue: either by providing supporting details   (e.g., a test case demonstrating a bug), or providing suggestions on how to address the issue.</li> <li>by tidying up issues: link duplicate issues, suggest new issue labels, go through open issues   and suggest closing old ones, ask clarifying questions on recently opened issues to move the discussion forward.</li> <li>by helping to resolve an issue: by opening a pull request    with the modified code that resolves the issue.</li> </ul> <p>When opening an issue, first check whether an issue on the same or related topic already exists. If not, go ahead, but make sure you include the following information:</p> <ul> <li>description of the issue (obviously!): as complete as possible, including error messages,   code snippets, type of input, screenshot of image output, options\u2026   whatever may help us to identify the source of the problem!</li> <li>version of the hMRI Toolbox:   if you are using an official release, the release number contained in the version.txt file of your release is all you need.   If you are working on a fork or clone of the master branch, please also report the commit hash you forked from.</li> <li>Matlab version</li> <li>SPM version</li> <li>operating system</li> </ul> <p>You are encouraged to help other contributors and to solve issues collaboratively.</p> <p>Responses that provide neither additional context nor supporting detail are not helpful. In many cases, such responses are simply annoying and unfriendly. Don\u2019t :).</p> <p>Be friendly and supportive!</p>"},{"location":"development/contribute/#setting-up-your-development-branch","title":"Setting up your development branch","text":"<p>Before going into the forking and branching process, you must have the following elements installed on your system (see the Get started page):</p> <ul> <li>Matlab</li> <li>SPM12 (version 12.4 or later is recommended)</li> <li>Git</li> </ul> <p>The following steps are described using the command line tool for <code>git</code>.</p> <p>You must create a GitHub account or log in to your existing account to proceed.</p>"},{"location":"development/contribute/#step-1-fork","title":"Step 1: Fork","text":"<p>You can refer to the GitHub documentation on how to fork a repository.</p> <p>For the hMRI Toolbox: - on GitHub, navigate to the hMRI toolbox repository, - in the top-right corner of the page, click on the <code>Fork</code> button - your own fork of the repository is now created, somewhere like <code>https://github.com/&lt;username&gt;/hMRI-toolbox</code>.</p>"},{"location":"development/contribute/#step-2-clone-configure","title":"Step 2: Clone &amp; configure","text":"<p>Now create a local copy of your fork on your computer:</p> <pre><code>$ git clone https://github.com/&lt;username&gt;/hMRI-toolbox.git\n</code></pre> <p>Also set the hMRI toolbox public repository as upstream:</p> <pre><code>$ git remote add upstream https://github.com/hMRI-group/hMRI-toolbox.git\n</code></pre> <p>We recommend you configure <code>git</code> so that it knows who you are, for example:</p> <pre><code>$ git config user.name \"Peter Pepperpot\"\n$ git config user.email \"peter.pepperpot@email.com\"\n</code></pre>"},{"location":"development/contribute/#step-3-branch","title":"Step 3: Branch","text":"<p>Create a new (development) branch with a name related to the bug fix or feature you plan to implement, for example:</p> <pre><code>$ git branch myBugFixIssue41\n$ git checkout myBugFixIssue41\n</code></pre>"},{"location":"development/contribute/#developments-and-pull-requests","title":"Developments and Pull Requests","text":""},{"location":"development/contribute/#step-4-code-and-commit","title":"Step 4: Code and Commit","text":"<p>Now you can start implementing your solution. Please document each commit clearly, always referring to the specific bug you\u2019re trying to resolve, or the specific feature you\u2019re implementing. If your patch fixes an open issue, you can reference it in your commit.</p>"},{"location":"development/contribute/#step-5-rebase","title":"Step 5: Rebase","text":"<p>When you\u2019re done with the implementation on your development branch, make sure your master branch is up-to-date, and if necessary, rebase your development branch to the latest commit from the hMRI toolbox public repository.</p> <p></p><pre><code>$ git fetch upstream\n$ git rebase upstream/master\n</code></pre> This ensures that your development branch has the latest changes from the hMRI toolbox master branch."},{"location":"development/contribute/#step-6-push","title":"Step 6: Push","text":"<p>Push your development branch to your fork on GitHub. According to the previous example:</p> <pre><code>$ git push origin myBugFixIssue41\n</code></pre>"},{"location":"development/contribute/#step-7-open-a-pull-request","title":"Step 7: Open a Pull Request","text":"<p>The process for opening and reviewing a Pull Request is similar to that of opening issues. Like issues, pull requests have their own discussion forum. The Pull Request will be followed by a review and approval workflow to ensure that the proposed changes meet the minimal quality and functional guidelines of the hMRI toolbox.</p> <p>For more information about Pull Requests, visit the GitHub Pull Request help pages.</p>"},{"location":"development/contribute/#future-features","title":"Future features","text":"<p>The hMRI-toolbox is an ongoing project, and many features are still on our to-do list. The list below includes features that are either under development, being tested, or not implemented at all. If you wish to contribute to these or add new ones, before you implement anything, please contact one of the main hMRI developers to check for current status of developments, or open an issue describing your proposal.</p> <ul> <li> <p>implementation of the classic Driven Equilibrium Single-Pulse   Observation of T1 (DESPOT1) algorithm, also known as the   Variable Flip-Angle (VFA) method for T1 mapping [ref].</p> </li> <li> <p>map creation for phantom data</p> </li> <li> <p>MR g-ratio</p> </li> <li> <p>susceptibility mapping</p> </li> <li> <p>denoising: spatially adaptive noise removal methods (Tabelow et al., 2016)   and appropriate handling of the Rician bias problem (Polzehl and Tabelow, 2016;   Tabelow et al., 2017)</p> </li> </ul>"},{"location":"development/releases/","title":"Releases","text":""},{"location":"development/releases/#releases-and-versioning","title":"Releases and Versioning","text":"<p>These notes describe how to release a new version. They are meant to clarify the way version numbers change and their relation to the current master branch. The process described is applied in a clean copy of the repository, after all bug fixes and changes have been accepted and merged into the master branch for a new release.</p> <ul> <li>Run all unit tests</li> <li>Update CHANGELOG.md to include the new version number, the release date and a summary of the changes +   Commit</li> <li>Update version.txt (e.g. from <code>v0.1.2-dev</code> to <code>v0.1.2</code>) + Commit</li> <li>Tag the release and upload it to the public repository</li> <li>Update version.txt again (e.g. from <code>v0.1.2</code> to <code>v0.1.3-dev</code>) + Commit</li> <li>Update CHANGELOG.md with new empty entry (e.g. <code>v0.1.3-dev</code>) + Commit</li> <li>Push all commits to the public repository.</li> </ul> <p>Warning</p> <p>Before release, the update of the version number may include more than simply removing the <code>-dev</code> suffix. For example, if the new release includes a major change, the update could go from <code>v0.1.2-dev</code> to <code>v1.0.0</code>. After release, the update of the version number will always increment the patch number only and append the <code>-dev</code> suffix.</p>"},{"location":"development/releases/#version-tracking","title":"Version tracking","text":"<p>Between releases, the CHANGELOG.md file should be kept up-to-date by filling in the new version entry with a summary of the changes. The detailed list of changes can be obtained by checking individual commits.</p> <p>The version.txt and CHANGELOG.md files are therefore the (humanly readable) landmarks of the current version.</p> <p>Please report the version number from version.txt when opening an issue or emailing a question. If you\u2019re using the version from the master branch, please also report the latest commit hash known on the public repository.</p> <p>Note that only the version number contained in version.txt is logged in the JSON files accompanying the output of the hMRI Toolbox modules.</p>"},{"location":"development/unit_tests/","title":"Unit Testing","text":""},{"location":"development/unit_tests/#unit-testing","title":"Unit Testing","text":"<p>Unit test functions (and with them their filenames) should end with <code>Test</code>. So assuming you have a function <code>example</code> in a file <code>example.m</code> you should create a test file <code>exampleTest.m</code> with the following function in it:</p> <pre><code>%% Main function to generate tests\nfunction tests = exampleTest\ntests = functiontests(localfunctions);\nend\n</code></pre> <p>This enables the unit test environment.</p> <p>In this file you can now add test functions. Each of those test functions must do a qualification at its end. Available qualifications can be found on the  Mathworks website. Assuming our function <code>example</code> computes the square root of the input the first test case could be this:</p> <pre><code>function testFunctionA(testData)\nactRoot = example(3*3);\nexpRoot = 3;\nverifyEqual(testData,actRoot,expRoot)\nend\n</code></pre> <p><code>testData</code> is the internal data structure to keep track of the testing (and thus is given to the qualification <code>verifyEqual</code> as first parameter). If you have multiple test cases you want to check, just add another test function. All of them will be tested.</p> <p>The tests can be run via <code>runtests</code> with the name of the testfile as parameter. In our case <code>runtests('exampleTest.m')</code></p>"},{"location":"development/unit_tests/#setting-up-a-test-environment","title":"Setting up a Test Environment","text":"<p>Sometimes it is necessary to prepare data or other things for the test. Those can be done globally (wont be changed for the whole test run) and locally (will be reset for each test case).</p> <p>The global setup is done by adding a function <code>setupOnce(testData)</code> to the test file. Notice that this function gets <code>testData</code> as a parameter. This gives you the option to add your global data into the data structure for the testing (in contrast to cluttering the global matlab data). This function is called once at the start when calling <code>runtests</code>. It\u2019s counterpart <code>teardownOnce(testCase)</code> is called right before <code>runtests</code> end. This can be used for any cleanup if neccessary. Also note that <code>testData</code> will be deleted anyway. So if you had no variables outside <code>testData</code> you won\u2019t have to clear those.</p> <p>The local setup functions <code>setup(testData)</code> and <code>teardown(testCase)</code> do pretty much the same. But for each test case individually. That means <code>setup(testData)</code> is run right before each of the test functions and <code>teardown(testCase)</code> right after it. This can be useful if you need reset variables for each test.</p>"},{"location":"development/unit_tests/#processing-the-results","title":"Processing the Results","text":"<p>The function <code>runtests</code> returns a TestsResults object. Assuming you put the results of <code>runtests</code> into the variable <code>a</code> you can write the results as a json file like this:</p> <pre><code>a=runtests(myFunctionTests);\nfile=fopen('test_results.json','w');\nfwrite(file,jsonencode(a));\nfclose(file);\n</code></pre> <p>(see also mathworks\u2019 tutorial for unit tests)</p>"},{"location":"docs/","title":"Home","text":""},{"location":"docs/#hmri-toolbox-documentation","title":"hMRI Toolbox Documentation","text":"<p>The hMRI Toolbox is an easy-to-use open-source and flexible tool, for qMRI data handling and processing. It allows the estimation of high-quality multi-parameter qMRI maps (longitudinal and effective transverse relaxation rates R1 and R2*, proton density PD and magnetisation transfer MT saturation) (Weiskopf2008 and Weiskopf2013), followed by spatial registration in common space for statistical analysis (Draganski2011).</p> <p>Embedded in the Statistical Parametric Mapping (SPM) framework, it can be readily combined with existing SPM toolboxes for estimating diffusion MRI parameter maps, and it benefits from the extensive range of established SPM tools for high-accuracy spatial registration and statistical inferences.</p> <p>The qMRI maps generated by the toolbox can be used for quantitative parameter analysis and accurate delineation of subcortical brain structures. They are key input parameters for biophysical models designed to estimate tissue microstructure properties such as the MR g-ratio and to derive standard and novel MRI biomarkers (Mohammadi2015). The hMRI toolbox is therefore the first step towards in vivo histology using MRI (hMRI) and is being extended further in this direction.</p> <p>The flexible and modular nature of the toolbox makes it usable for a wide range of data types, from the full MPM protocol to subsets of it, including e.g. single contrast echo trains for mapping R2* or variable flip angle data for R1 and PD mapping using multi-echo or single-echo data. The spatial processing part of the toolbox can be applied to any set of rotationally-invariant qMRI maps, including diffusion MRI scalar parameter maps as well as the standard (R1, PD, MT and R2*) MPM maps.</p> <p>For a reference on the scientific background, methods and concepts please use the hMRI-toolbox paper and cite it when publishing results compiled with the hMRI-toolbox.</p>"},{"location":"docs/#about-the-documentation","title":"About the Documentation","text":"<p>These pages are a collection of documentation and information about using the hMRI-toolbox. It is an ongoing project that will be updated regularly.</p>"},{"location":"docs/BIDS/","title":"BIDS","text":""},{"location":"docs/BIDS/#bids-compatibility","title":"BIDS Compatibility","text":"<p>The Brain Imaging Data Structure (BIDS) is a set of standards for representing brain imaging data. The quantitative MRI (qMRI) BIDS extension describes how datasets should be arranged and which metadata must be provided in order for qMRI maps to be calculated from the data. The hMRI Toolbox predates the qMRI BIDS standards, and so the implementation of full BIDS compatibility is still under development. However, the toolbox can already read nearly all the necessary metadata from BIDS sidecar files (exceptions are listed below), and there are Matlab tools which can filter BIDS-arranged data to provide them as input to the toolbox and can move and rename the outputs to arrange them in a BIDS-compatible way.</p>"},{"location":"docs/BIDS/#tools","title":"Tools","text":"<p>The following tools can be used to parse BIDS datasets to feed them into the hMRI Toolbox, and then move and rename the hMRI Toolbox outputs into a BIDS-compatible structure:</p> <ul> <li>bids-matlab</li> <li>bids-processing-tools</li> <li>hmri-bids-pipeline</li> </ul>"},{"location":"docs/BIDS/#limitations","title":"Limitations","text":"<ul> <li>Output filenames are not qMRI-BIDS compatible; this means scripting must be used to rename the outputs (   see Tools).</li> <li>For reasons of maintaining backwards compatibility with old 3D-EPI SE/STE B1-mapping datasets where these parameters   were not set in a BIDS-compatible way, reading the <code>EchoTime</code> and <code>FlipAngle</code> metadata from 3D-EPI SE/STE B1-mapping   datasets must be enabled by the user; see here   or this example B1-defaults file for how to do this.</li> </ul>"},{"location":"docs/BIDS/#bids-ified-example-dataset","title":"BIDS-ified Example Dataset","text":"<p>A conversion of the hMRI Toolbox example dataset to a BIDS-compatible format can be found as <code>ds-mpm</code> here.</p>"},{"location":"docs/QUIQI/","title":"QUIQI","text":""},{"location":"docs/QUIQI/#quiqi","title":"QUIQI","text":"<p>QUIQI is a method that accounts for the degradation of data quality due to motion in the analysis of MRI data. This method is described Lutti2022. QUIQI was originally implemented using custom-made matlab scripts and functionalities provided by the SPM software (https://www.fil.ion.ucl.ac.uk/spm/). These scripts are available here: (https://github.com/LREN-physics/hMRI-toolbox/tree/quiqi_v1.0). A subset of the data analysed in the original article can be found here: doi:10.5281/zenodo.4647081. In order to help users implement this method for their own analysis, we provide here a GUI-based implementation of QUIQI built into the hMRI Toolbox, dedicated to the analysis of neuroimaging data.</p>"},{"location":"docs/QUIQI/#requirements","title":"Requirements","text":"<p>A running version of Matlab (https://mathworks.com/products/matlab.html) and SPM (https://www.fil.ion.ucl.ac.uk/spm/) are pre-requisites for running these analyses. Please refer to this page for help in installing and using the hMRI Toolbox.</p>"},{"location":"docs/QUIQI/#content","title":"Content","text":"<p>The implementation of QUIQI within the hMRI Toolbox is based on two modules: \u201cQUIQI BUILD\u201d and \u201cQUIQI CHECK\u201d.</p>"},{"location":"docs/QUIQI/#quiqi-build","title":"QUIQI BUILD","text":"<p>The \u201cQUIQI BUILD\u201d module lies between the usual \u2018Factorial design\u2019 and \u2018Model estimation\u2019 steps of an SPM image analysis (see screenshot below). The corresponding fields are:</p> <ul> <li>SPM.mat: SPM matrix associated with the analysis</li> <li>MDI powers: powers of the Motion Degradation Index used to compute the basis functions for the ReML estimation of the   noise covariance matrix.</li> <li>MDI type: type of the object that contains the values of the Motion Degradation Index. If \u2018MDI matrix\u2019 is selected,   the MDI values may be pasted into the GUI from e.g. an Matlab variable or a table. The MDI values can also be read-in   directly from a json file (\u2018MDIjsonfile).</li> </ul> <p></p>"},{"location":"docs/QUIQI/#quiqi-check","title":"QUIQI CHECK","text":"<p>QUIQI CHECK lies at the very end of image analysis (see below). While this module is not necessary to correct for motion degradation effects in the MRI data, it is useful to assess the degree of remaining motion degradation after correction. On the model of Lutti et al., this module plots a histogram of the distribution of the image residual samples against the results of fitting these residuals with a polynomial function of the MDI. A high R<sup>2</sup> value highlights heteroscedasticity of the noise distribution (see example below, with and without the use of QUIQI). Note that when multiple sets of MDI values are used for QUIQI (i.e. for the analysis of MRI data computed across multiple raw image volumes) all sets of MDI values are used for the polynomial fitting. Also, the maximum power of the polynomial fit can be set from the user interface (field \u2018Fit power\u2019).</p> <p></p> <p>Without QUIQI:</p> <p></p> <p>With QUIQI:</p> <p></p>"},{"location":"docs/autoReorient/","title":"Automatic Reorientation","text":"<p>The reorientation of the images towards the MNI space is a standard step in neuroimage processing. It increases the consistency in individual head positions prior to normalisation, and often is a prerequisite for successful segmentation. The Unified Segmentation (Ashburner2005) process is indeed rather sensitive to the initial orientation of the image. Auto-reorient provides you with a simple tool for reorientation of all images prior to any further processing including multiparameter map calculation.</p> <p>Reorientation is based on rigid-body coregistration of a reference image to the MNI space (i.e. mainly set the AC location and correct for head rotation) and application of the coregistration matrix to all images acquired during the same session (specified as \u201cother images\u201d). The code makes use of spm affreg and templates available in SPM12.</p> <p>The user must provide one reference image and a template for coregistration, and a series of other images that need to keep in alignment with the reference image (typically, all the images acquired during a given imaging session). The reference image is the one that will be coregistered to the template. It must have as good a signal-to-noise ratio (SNR) and a white matter/grey matter contrast-to-noise ratio (CNR) as possible to ensure a robust and reliable coregistration. The template can be choosen e.g. amongst SPM canonical templates (from the SPM/canonical directory) or any other userdefined template (e.g. atypical population-driven template), provided it is already oriented according to MNI. It is mandatory that the contrast of the reference image is close to the template image.</p> <p>The following list is provided as guidelines:</p> <pre><code>SOURCE IMAGE &gt; RECOMMENDED TEMPLATE    \nFirst T1w echo &gt; SPM/canonical/avg152T1.nii    \nFirst PDw echo &gt; SPM/canonical/avg152PD.nii    \nFirst MTw echo &gt; SPM/canonical/avg152PD.nii     \n</code></pre> <p>If no specific output directory is selected, then the original orientation of the images will be overwritten. If an output directory is selected then the images are copied to the ouput directory in a AutoReorient folder before being reoriented, therefore leaving the original data untouched.</p> <p>The reoriented images can be collected as dependencies for further processing, either all at once (Dependencies &gt; Grouped) or as individual output images (Dependencies &gt; Individual) which is more convenient to connect the Auto-reorient module to the next Create hMRI maps module.</p>"},{"location":"docs/debugMetadataAndLogFiles/","title":"Tips & tricks for Processing and Debugging","text":""},{"location":"docs/debugMetadataAndLogFiles/#tips-tricks-for-processing-and-debugging","title":"Tips &amp; Tricks for Processing and Debugging","text":"<p>Description of the tools available to automatise data processing and control results quality. Guidelines and good practices to make sure your data are processed as expected, with the help of information stored in the metadata associated to the images &amp; maps and in the parameters and messages log files.</p>"},{"location":"docs/debugMetadataAndLogFiles/#scripting-and-batching","title":"Scripting and Batching","text":"<p>General documentation about writing batch script in SPM can be found in the SPM documentation on the SPM Home page.</p> <p>The hMRI Toolbox benefits from the <code>matlabbatch</code> system integrated in SPM. A batch describes which modules should be run on what kind of data and how these modules depend on each other. This allows you to easily handle input data and define the desired processing steps. Compared to running each processing step interactively, batches have a number of advantages:</p> <ul> <li>Tracking: Each batch can be saved as a Matlab <code>*.mat</code> file or as a Matlab <code>*.m</code> script.   All parameters (including default settings) are included in this script.   Thus, a saved batch contains a full description of the sequence of processing steps and the parameter settings used.</li> <li>Reproducibility: Batches can be saved, even if not all parameters have been set.   For a multi-subject study, this allows you to create template batches.   These templates contain all settings which do not vary across subjects.   For each subject, they can be loaded and only subject-specific parts need to be completed.</li> <li>Dependencies: Instead of waiting for a processing step to complete before entering the   results in the next one, all processing steps can be run in the specified order without any   user interaction, retrieving output from one step to be fed into the next step using <code>Dependencies</code>.</li> <li>Scripting: Template batches can be edited to loop over a number of datasets automatically.</li> </ul> <p>When piloting the processing of your data, we recommend you to:</p> <ul> <li>define the processing steps using the SPM Batch GUI</li> <li>limit the processing to a single subject\u2019s data set</li> <li>systematically save the whole batch (including all steps for one subject) as a <code>*.mat</code> file (for every set of options   you may consider - if several)</li> <li>once the results have been evaluated and the processing steps are established, save the corresponding batch as   Matlab <code>*.m</code> script.</li> </ul> <p>To process multiple data sets (from multiple subjects and possibly multiple sessions), we recommend you to use the saved Matlab .m script as a template. Edit it to loop over subjects and save it with a meaningful name. Such a script will help you track the processing steps for later review, just as .mat batch files did for a single subject. It will also guarantee that all your data are processed in a consistent manner for every subject and every group of subjects. Finally, it also allows you to repeat the processing or extend it to more subjects or sessions, identically or with slightly different parameters, with as little additional user input as possible - which is likely to be an important source of error otherwise ;)!</p>"},{"location":"docs/debugMetadataAndLogFiles/#visual-inspection-of-the-created-maps","title":"Visual Inspection of the Created Maps","text":"<p>A simple visual inspection of the maps will help you to spot quickly a few basic problems:</p> <ul> <li>erroneous reorientation of the images (Auto-reorient module)</li> <li>excessive B0 field variation thresholding leading to holes in the images (3D EPI SE/STE B1 transmit bias correction)</li> <li>\u2026</li> </ul> <p>To visualise the maps, it is important to use appropriate windowing range. Typically, the following intensity ranges will provide good rendering:</p> <ul> <li>PD maps: <code>[50 120]</code> p.u.</li> <li>MT saturation maps: <code>[0 2]</code> p.u.</li> <li>R2* maps: <code>[0 70]</code> s-1</li> <li>R1 maps: <code>[0 1.4]</code> s-1</li> <li>B1 maps: <code>[75 125]</code> p.u.</li> <li>RF sensitivity maps: <code>[0 2]</code> a.u.</li> </ul> <p>The <code>Quality tools</code> module can be used for visual inspection of the results, as a first step. The selected images are displayed with predefined windowing and saved as PNG files for quick visual inspection. See the help available in the SPM Batch GUI of the <code>Quality tools</code> module.</p> <p>Warning</p> <p>The current version of the <code>Quality tools</code> is not meant to automatically flag anomalies. The assessment still relies on the expertise of the person visualizing the data! Moreover, the PNG files saved don\u2019t show everything, and anomalies can still remain unnoticed.</p> <p>The following example illustrates typical rendering of the maps (processed from the MPM example dataset, see tutorial for map creation) as rendered using SPM CheckReg and manual adjustment of the intensity ranges:</p> <p></p> Example display maps with appropriate scaling <p>The next example shows the same data displayed using the <code>Quality tools &gt; Visual check</code> module:</p> <p></p> Visual check of the results"},{"location":"docs/debugMetadataAndLogFiles/#metadata","title":"Metadata","text":"<p>If your images have been converted from DICOM to NIfTI using either the SPM12 <code>DICOM Import</code> tool with the <code>Export metadata</code> option enabled (available since SPM12.4 r7219) or the <code>DICOM Import</code> tool from the hMRI Toolbox, the whole DICOM header is stored as a JSON file along the nifti volume (same file name, <code>*.json</code> and <code>*.nii</code> extensions respectively). NOTE: the SPM12.4 implementation of the additional DICOM header storage to a JSON file is based on the hMRI Toolbox.</p> <p>Several tools and scripts are available to handle the metadata in order to set, get and search the parameters and information stored. Refer to the Metadata Library page for a full description of the metadata, and in particular to the section dedicated to metadata handling.</p> <p>The metadata can be used for several purposes. A few examples are given below, illustrating the usefulness of the metadata for a much broader use than the hMRI Toolbox alone:</p> <ul> <li>Protocol consistency: when reviewing the data before processing, check all data sets have been acquired with   consistent acquisition parameters (i.e. critical parameters are identical, while e.g. slice orientation and position   will differ from one subject to the next). No fully integrated tool is provided for that purpose (yet), but all   required tools are available in the metadata library for a user familiar with Matlab to do so.</li> <li>Batching and data processing: when preparing a batch to process your data, metadata can conveniently be retrieved   directly from the metadata (e.g. RepetitionTime, diffusion directions and b-values) rather than hard coded in the   script. Can be useful for standard SPM spatial processing, quality assurance, DWI processing and the hMRI Toolbox,   obviously\u2026</li> <li>In the hMRI Toolbox: metadata are used all along, from the DICOM header (to retrieve the appropriate acquisition   parameters required to process the data) to information logged into the JSON metadata file of the quantitative maps.   The metadata structure of the output maps and images generated by the hMRI Toolbox includes processing parameters,   dependencies of the result on other input images as well as a summary description of each output image (convenient if   you want to double-check e.g. what bias correction has been applied to generate a given map).</li> </ul> <p>Below we provide an example of metadata including a summary description of the R1 map output. The metadata structure is retrieved using the following SPM/Matlab command:</p> <pre><code>metadata = spm_jsonread(&lt;name of the JSON file&gt;);\n</code></pre> <p>Then the summary description can be displayed:</p> <pre><code>fprintf(1,'\\nSummary description of the output:\\n%s', metadata.history.output.imtype);\n</code></pre> <p>All three examples below correspond to R1 maps generated with per-contrast RF sensitivity bias correction and different B1 transmit bias corrections.</p> <p>Case 1: B1 transmit correction using 3D EPI SE/STE mapping:</p> <pre><code>R1 map [s-1]\n- B1+ bias correction using provided B1 map (i3D_EPI)\n- RF sensitivity bias correction based on a per-contrast sensitivity measurement\n</code></pre> <p>Case 2: B1 transmit correction using UNICORT:</p> <pre><code>R1 map [s-1]\n- B1+ bias correction using UNICORT\n- RF sensitivity bias correction based on a per-contrast sensitivity measurement\n</code></pre> <p>Case 3: no B1 transmit correction:</p> <pre><code>R1 map [s-1]\n- no B1+ bias correction applied\n- RF sensitivity bias correction based on a per-contrast sensitivity measurement\n</code></pre> <p>Note that the same information can be read directly from the JSON file using a text editor - easy :)!</p>"},{"location":"docs/debugMetadataAndLogFiles/#processing-parameter-log-files","title":"Processing Parameter Log Files","text":"<p>Several JSON files are logged during the <code>Create hMRI maps</code> module, containing mainly processing parameters. Below is the list of the files generated, stored in the <code>Results/Supplementary</code> directory. Depending on the processing options selected, some of them may not be generated.</p> <ul> <li><code>hMRI_map_creation_rfsens_params.json</code>: RF sensitivity bias correction parameters (measured sensitivity maps).</li> <li><code>hMRI_map_creation_b1map_params.json</code>: B1 transmit map estimation: acquisition and processing parameters.</li> <li><code>hMRI_map_creation_job_create_maps.json</code>: Create hMRI maps: acquisition and processing parameters.</li> <li><code>hMRI_map_creation_mpm_params.json</code>: Acquisition and processing parameters used for the current Create hMRI maps   job.</li> <li><code>hMRI_map_creation_quality_assessment.json</code>: Quality assessment results.</li> </ul> <p>Review these files (you can read them directly using a text editor, or retrieve the Matlab structure therein with the <code>spm_jsonread</code> function) to check the parameters used are as expected.</p>"},{"location":"docs/debugMetadataAndLogFiles/#processing-message-log-files","title":"Processing Message Log Files","text":"<p>Note</p> <p>The LogMsg option is available from version v0.1.2-beta2.</p>"},{"location":"docs/debugMetadataAndLogFiles/#general-purpose-and-default-settings","title":"General Purpose and Default Settings","text":"<p>In order to review and keep track of info, warnings and other messages coming up during data processing, all messages are logged using the <code>hmri_log.m</code> script.</p> <p>By default, all messages are logged both to the Matlab Command Window and into a <code>hMRI_LogFile.log</code> (saved in the current directory). The latter can be more specifically customized (see <code>help hmri_log</code>). During the <code>Create hMRI maps</code> module execution, messages are logged into a <code>hMRI_map_creation_logfile.log</code> file into the <code>Results/Supplementary</code> directory.</p> <p>Additionally, any information or warning considered potentially critical for the processing of your data will be displayed in a pop-up window, blocking the execution of the code. This is obviously rather annoying if you intend to process a bunch of data overnight ;)! It can be disabled (see the Batch option \u201cPop-up warnings\u201d) for that purpose.</p>"},{"location":"docs/debugMetadataAndLogFiles/#tips-tricks","title":"Tips &amp; Tricks","text":"<p>For piloting data processing though (e.g. processing a single-subject dataset to check everything is generated as expected), it is recommended to keep the pop-up option enabled, so you can read through and acknowledge every message and make sure everything is set up properly before running the processing on a whole group.</p> <p>Always carefully review the warning messages. Some of them may be expected. Others may be more relevant and point you towards some errors in the processing parameters used. For example, if no metadata are available, this will be flagged up as a warning. If this is the case, you\u2019d better check whether the processing parameters listed (either in the pop-up warning, processing message log files or processing parameter log files) correspond to the data and acquisition parameters given as input.</p>"},{"location":"docs/debugMetadataAndLogFiles/#list-of-messages","title":"List of messages","text":"<p>Warning messages are only meant to make you aware of some of the processing steps and parameters used to generate the maps. And to give you a chance to decide whether these processing steps and parameters are definitely the right ones for the data you have at hand. Most warning and information messages are listed below, with a description of potential implications and actions to be taken.</p> <pre><code>WARNING: the (strict) minimum number of echoes required \nto calculate R2\\* map is 2. The default value (...) has \nbeen modified and is now neco4R2sfit=2.\n</code></pre> <p>This warning is related to the minimum number of echoes required to calculate a R2s map. This number is set via the global parameter <code>hmri_def.neco4R2sfit</code>. Strictly speaking, the minimum is 2. If you accidentally changed it to anything &lt;2, it will be set back to 2 (although the default is 4). For a robust estimation, the minimum number of echoes required depends on many factors, amongst which:</p> <ul> <li>SNR/resolution</li> <li>distribution/spacing between TEs: note that early echoes are more affected by the specific contrast, violating the   assumption of a common decay between contrasts.</li> <li>number of contrasts available (fewer echoes per contrast required for 3 (PDw, T1w, MTw) contrasts as compared to 2 or   even 1)</li> </ul> <p>To be on the safe side, a minimum of 6 echoes is recommended (Weiskopf et al., 2014 paper). Further studies are required to come up with more detailed and informed guidelines.</p> <p>Warning</p> <p>Use fewer echoes at your own risk!</p> <pre><code>WARNING: UNICORT B1+ estimate (if available) will be \nused to correct the PD/MT map for B1 transmit bias. This method has \nnot been validated. Use with care!\n</code></pre> <p>This warning relates to the usage of the B1+ transmit field estimated using UNICORT and the apparent (biased) R1 map, to correct for B1 transmit inhomogeneities in PD and/or MT maps. The corresponding parameters are <code>hmri_def.UNICORT.PD</code> and <code>hmri_def.UNICORT.MT</code>. By default, these options are disabled. The UNICORT-estimated B1 maps usually agree with the measured B1 maps (see Weiskopf et al., 2011 paper), and could possibly be used when no B1 transmit field has been measured. However, the method has not been validated for PD and MT map calculation.</p> <pre><code>WARNING: no UNICORT B1 estimate available for PD/MT calculation.\nB1 bias correction must be defined as \"UNICORT\" (not the case).\nUNICORT.PD/MT is disabled!\n</code></pre> <p>Obviously, if no UNICORT-estimated B1 map is available, it cannot be used to correct PD and MT maps for B1 transmit biases! Again related to the global parameters <code>hmri_def.UNICORT.PD</code> and <code>hmri_def.UNICORT.MT</code>.</p> <pre><code>INFO: FLASH echoes loaded for each contrast are:\n- WARNING: no MT-weighted FLASH echoes available! / MT-weighted: ... echoes\n- WARNING: no PD-weighted FLASH echoes available! / PD-weighted: ... echoes\n- WARNING: no T1-weighted FLASH echoes available! / T1-weighted: ... echoes\n</code></pre> <p>This message is only confirming the number of echo(es) available for each contrast. You don\u2019t need multi-echo data for each contrast. The toolbox will generate the maps for which the required inputs are available only. For example, if only 8 echoes of PDw images are available, a R2s map alone will be generated. If only one echo is available for each contrast, the toolbox will generate PD, R1 and MT maps (provided B1+ bias correction is somehow enabled for R1 and PD calculation). Note that the efficiency and robustness of the various bias corrections will depend on the contrasts and number of echoes available.</p> <pre><code>WARNING: No TE/TR/FA values found for PDw/T1w/MTw \nimages. Fallback to defaults.\n</code></pre> <p>These parameters can be easily retrieved from the NIfTI description field and/or metadata when images have been imported from DICOM to NIfTI using the hMRI DICOM Import tool, or the standard SPM DICOM Import tool either with or without enabling metadata storage. This message is therefore more likely to come up if your data have been converted to NIfTI using another conversion tool. If so, you will have to define these parameters manually in your local default file and load them using the <code>Configure toolbox</code> module. The default parameters to be customised are stored in <code>hmri_def.MPMacq</code>.</p> <pre><code>ERROR: Echo times do not match between contrasts! Aborting.\n</code></pre> <p>When creating maps from multi-echo series, one can either average the images from a given contrast (e.g. average over all PDw echoes) or extrapolate the series of echoes to TE=0. In the former case, the processing assumes matching TEs for all contrasts, and the average will only consider the echoes common to every contrast (matching T2* weighting). For example, if 8 PDw echoes, 8 T1w echoes and 6 MTw echoes are available, with identical TEs except for the last two missing echoes in the MTw series, the average will be done over the first 6 echoes for each contrast. In the latter case (extrapolation to TE=0), the mismatch between TEs does not matter, since each extrapolated image is free of any T2* weighting. If you have multi-echo data with non-matching echoes between contrasts, it is therefore necessary to enable the TE=0 extrapolation. This is done by setting <code>hmri_def.fullOLS = true</code> (which is the default value).</p> <pre><code>INFO: averaged PDw/T1w/MTw will be calculated based on the first ... echoes.\n</code></pre> <p>This message is related to the previous ERROR message. It only applies when averaged rather than TE=0 extrapolated images are used. The number of echoes correspond to the maximum number of echoes available in every contrast, to ensure a uniform T2* weighting effect across the contrasts. Does not apply and can be entirely ignored for TE=0 extrapolation case (default <code>hmri_def.fullOLS = true</code> case).</p> <pre><code>INFO: MPM acquisition protocol = ...\nThe coefficients corresponding to this protocol will be applied\nto correct for imperfect spoiling. Please check carefully that\nthe protocol used is definitely the one for which the\ncoefficients have been calculated.\n</code></pre> <p>If imperfect spoiling correction is enabled (i.e. <code>hmri_def.spoilcorr.enabled = true</code> while default is <code>hmri_def.spoilcorr.enabled = false</code>), and if correction factors are available, the method from Preibisch et al., 2009 is applied to correct for deviations from the Ernst equation due to remaining transverse magnetisation at the end of each TR (imperfect spoiling). The correction coefficients must be calculated specifically (using simulations) for a given sequence, and depend on the RF spoiling phase increment, gradient spoiling moment, TR and FA. These coefficients have been calculated for a series of customized sequences (standard MPM protocols as used in e.g. Callaghan et al., 2014, Weiskopf et al., 2013, Draganski et al., 2011) only. Although some other sequences may use the same TRs and FAs, it is unlikely that the other parameters be identical, therefore the correction coefficients estimated for one protocol/sequence must not be used for any other protocol/sequence. If imperfect spoiling correction is enabled, you must therefore make sure that the coefficients used are the right ones for your protocol. To date, the code used to derive these coefficients is not made available. More work required\u2026</p> <pre><code>INFO (PD calculation):\n    mean White Matter intensity: ...\n    SD White Matter intensity ...\n\nWARNING: Error estimate is high (...%) for calculated PD map:\nError higher than 6% may indicate motion.\n</code></pre> <p>When a PD map is generated (requires PDw, T1w, B1 transmit and RF receive bias corrections of some sort, and calibration), the average and standard deviation of the values in the white matter before calibration is calculated. If the standard deviation is higher than 6% of the mean value, a warning is displayed. The cutoff threshold of 6% is a good motion indicator for standard MPM protocol with 1 mm isotropic resolution and RF sensitivity bias correction using the Unified Segmentation method. In other cases, and error higher than 6% may originate from various sources (including motion but not only), e.g. residual RF sensitivity modulation from the body coil when measure RF sensitivity maps have been used, residual T2*-weighting when not accounted for, low SNR due to lower number of echoes and/or higher spatial resolution. This warning is rather informative\u2026</p> <pre><code>WARNING: both RF sensitivity and B1 transmit bias corrections \nare required to generate a quantitative (calibrated) PD map.\nEither or both of these is missing. Therefore an amplitude \n\"A\" map will be output instead of a quantitative \nPD map. PD map calibration has been disabled.\n</code></pre> <p>Consistency check: <code>hmri_def.PDproc.calibr = 1</code> (calibration of white matter PD value to 69%) while either (or both) B1 transmit or RF sensitivity bias were disabled or unavailable. In that case, it does not make sense to calibrate the resulting biased A map. Therefore: <code>hmri_def.PDproc.calibr = 0</code>.</p> <pre><code>WARNING: if TE=0 fit is enabled (fullOLS option), \nno T2*-weighting bias correction is required. \nT2scorr option disabled.\n</code></pre> <p>The <code>hmri_def.T2scorr</code> option (correction of PD maps for T2*-weighting bias,  Balteau et al.) is enabled by default, to be applied if <code>hmri_def.fullOLS</code> (interpolation to TE=0) were disabled. By default, interpolation to TE=0 is applied preferentially (removes T2* weighting from all maps). If only single-echo data are available though, the warning will still be displayed although no TE=0 extrapolation nor T2* estimate for T2*-weighting bias correction can be derived. In that case, a residual T2*-weighting modulation will affect the PD map (small effect for short TE).</p> <pre><code>WARNING: both TE=0 fit (fullOLS option) and T2*-weighting \nbias correction (T2scorr option) are disabled. The T2* bias won't\nbe corrected for and impact the resulting PD map. It is strongly \nrecommended to have either of these options enabled!\nNOTE: this recommendation does not apply to single-echo datasets.\n</code></pre> <p>The message is self-explanatory (see Balteau et al., 2018) for details. In case of a single-echo dataset, the T2* bias will remain, as a small effect for small TEs.</p> <pre><code>WARNING: not enough echoes available (minimum is ...) to \ncalculate R2\\* map. No T2*-weighting bias correction can be \napplied (T2scorr option). T2scorr disabled.\n</code></pre> <p>The minimum of echoes required to estimate R2* is defined by <code>hmri_def.neco4R2sfit</code>. The default value is 4 (although a number of 6 has been used in the literature and considered as the only validated option to date). If no R2* map can be evaluated (number of available echoes &lt; neco4R2sfit for all contrasts), the correction implemented as \u201cT2*-weighting bias correction\u201d (enabled with parameter <code>hmri_def.T2scorr</code>) cannot be applied and the option is disabled.</p> <pre><code>WARNING: number of T1w echoes to be averaged for PD calculation (...)\nis bigger than the available number of echoes (...). Setting nr_echoes_forA' ...\nto ..., the maximum number of echoes available.\n</code></pre> <p>This messages only applies if <code>hmri_def.fullOLS = false</code> (i.e. no interpolation to TE=0). In that case, maps are calculated based on averaged echoes for each contrast. If no T2*-weighting bias correction is applied (<code>hmri_def.T2scorr = false</code>, not recommended), it is preferable to calculate the PD map (and preliminary A map) based on the first echo only (<code>hmri_def.PDproc.nr_echoes_forA = 1</code>) to reduce the impact of T2*-weighting bias. If <code>hmri_def.PDproc.T2scorr = true</code>, the average is calculated by default over the first 6 echoes (excluding the longer, lower-SNR echoes) or fewer if echo train shorter than 6. The message can be ignored if <code>hmri_def.fullOLS = true</code>.</p> <pre><code>-------- R2* map calculation (basic exponential decay) --------\nINFO: minimum number of echoes required for R2* map calculation is ...\nNumber of PDw echoes available: ...\n</code></pre> <p>Just FYI, related to the basic exponential fit on PDw echoes only. Based on the global value <code>hmri_def.neco4R2sfit</code> defining the number of echoes considered safe enough to derive R2* from the PDw echo train. Note that 6 is the current minimum published in various papers. If the number of echoes available is lower than the minimum required, the following message comes up:</p> <pre><code>No (basic) R2* map will be calculated.\n</code></pre> <p>If the number of echoes available is equal or higher than the minimum required, but is lower than 6, the following message comes up:</p> <pre><code>GENERAL WARNING: deriving R2* map from an echo train including \nfewer than 6 echoes has not been validated nor investigated. \nFor a robust estimation, the minimum number of echoes required \ndepends on many factors, amongst which: \n- SNR/resolution\n- distribution/spacing between TEs: note that early echoes are more\n  affected by the PDw contrast.\nInterpret results carefully, with in mind a possible lack of robustness\nand reliability in the R2* estimation.\n</code></pre> <pre><code>-------- OLS R2* map calculation (ESTATICS) --------\nINFO: minimum number of echoes required for R2* map calculation is ...\nNumber of echoes available:  MTw = ... PDw = ... T1w = ...\n</code></pre> <p>Just FYI, related to the R2* estimate based on the ESTATICS model (fit all echoes). Based on the global value <code>hmri_def.neco4R2sfit</code> defining the number of echoes considered safe enough to derive R2*. NOTE: 6 is the current minimum published in the ESTATICS paper. If the number of echoes available is lower than the minimum required for all contrasts, the following message comes up:</p> <pre><code>No R2* map will be calculated using the ESTATICS model.\n</code></pre> <p>If the number of echoes available is equal or higher than the minimum required at least one of the contrasts, but is lower than 6, the following message comes up:</p> <pre><code>GENERAL WARNING: deriving R2* map from an echo train including \nfewer than 6 echoes has not been validated nor investigated. \nFor a robust estimation, the minimum number of echoes required \ndepends on many factors, amongst which: \n- SNR/resolution\n- distribution/spacing between TEs: note that early echoes are more\n  affected by the specific contrast, violating the ESTATICS assumption \n  of a common decay between contrasts.\n- number of contrasts available (fewer echoes per contrast required \n  for 3 (PDw, T1w, MTw) contrasts as compared to 2 or even 1) \nInterpret results carefully, with in mind a possible lack of robustness \nand reliability in the R2* estimation.\n</code></pre> <pre><code>WARNING: ACPC Realign was enabled, but no MT map was available \nto proceed. ACPC realignment must be done separately, e.g. you can\nrun [hMRI tools &gt; Auto-reorient] before calculating the maps.\nNOTE: segmentation might crash if no initial reorientation.\n</code></pre> <p>An AC/PC realignment of all images can be applied during the <code>Create hMRI maps</code> module (<code>hmri_def.qMRI_maps.ACPCrealign = 1</code>). It is based on the already calculated MT map. If not available, the realignment cannot proceed. This option is kept for backward compatibility but is not recommended (<code>hmri_def.qMRI_maps.ACPCrealign = 0</code> by default). Realignement using the <code>Auto-reorient</code> module is preferred.</p>"},{"location":"docs/debugMetadataAndLogFiles/#known-issues","title":"Known issues","text":"<p>Below are listed common issues experienced by users when installing and first running the toolbox. If you face issues that are not listed here, please report it. About issue tracking and support, refer to the Develop and Contribute section.</p> <p>Invalid MEX file under macOS  The compiled <code>spm_jsonread.mexmaci64</code> file is unfortunately version-dependent (including Matlab, compiler and Mac OS versions)! Therefore, you might need to recompile the mex file before using it.    Here is how to proceed:</p> <ul> <li>in Matlab, change directory to <code>/hMRI-Toolbox/spm12/src</code></li> <li>run <code>mex spm_jsonread.c jsmn.c -DJSMN_PARENT_LINKS</code></li> <li>copy the created spm_jsonread.mexmaci64 file from <code>/hMRI-Toolbox/spm12/src</code> to <code>/hMRI-Toolbox/spm12</code> (   overwriting the existing one).</li> </ul>"},{"location":"docs/defaultsAndCustomization/","title":"Defaults and Customization","text":""},{"location":"docs/defaultsAndCustomization/#default-parameters-and-customization-of-the-hmri-toolbox","title":"Default Parameters and Customization of the hMRI Toolbox","text":"<p>The toolbox provides the user with a series of standard default acquisition and processing parameters. These parameters will allow the user to run the toolbox for the most standard acquisition protocols without any further customization. However, customization is possible and necessary to open the toolbox usability to a wide range of protocols. Therefore, the default parameters can be customised to match the user\u2019s own site- or protocol-specific setup. The parameters are described below and can be found in the <code>config</code> directory. Some parameters are meant to be easily and safely modified by any user, while others should only be modified by advanced users.</p>"},{"location":"docs/defaultsAndCustomization/#organization-of-the-defaults","title":"Organization of the Defaults","text":"<p>Defaults of the parameters that can be used to modify the behaviour of the toolbox are stored in the <code>config</code> (root) directory of the toolbox. These standard default parameters should never be modified. Customized default parameter files should be stored in the <code>config/local</code> directory. Template files to define these local default parameters can be found in <code>config/local</code>. These template files can be modified appropriately and saved under a meaningful name to be loaded in the <code>Configure toolbox</code> module and used in the <code>Create hMRI maps</code> and <code>Process hMRI maps</code> modules. Example files to turn on useful features of the toolbox can be found in the  <code>examples</code> directory.</p> <p>Unlike the processing parameters, the acquisition parameters are retrieved from the input images if metadata are available. Acquisition parameters specified in the defaults are only provided as a fallback solution when no metadata are available. Since acquisition parameters are likely to vary from protocol to protocol, the use of metadata is strongly recommended ( see JSON metadata and DICOM import). For some non-product sequences, though, metadata might not be retrievable and default acquisition parameters must be customized (see below).</p> <p>During data processing, default parameters are stored in a global variable <code>hmri_def</code> and default values can be retrieved using <code>hmri_get_defaults.m</code>.</p>"},{"location":"docs/defaultsAndCustomization/#customization-of-the-defaults","title":"Customization of the defaults","text":"<p>The default parameters can be customised to match the user\u2019s own site- or protocol-specific setup. Templates for customised default files are stored in the <code>config/local</code> directory and can be modified and saved with meaningful names by the user. Note that some parameters should only be modified by advanced users who are aware of the underlying theory and implementation of the toolbox. The user can refer to the <code>hmri_local_defaults.m</code> help where parameters are divided between basic parameters and advanced parameters, and to the list below.</p>"},{"location":"docs/defaultsAndCustomization/#customize-global-parameters","title":"Customize global parameters","text":"<p>The standard default parameters are defined in <code>config/hmri_defaults.m</code> and the corresponding template file for customization is <code>config/local/hmri_local_defaults.m</code>. Parameters defined in the template <code>config/local/hmri_local_defaults.m</code> are identical to the ones defined in <code>config/hmri_defaults.m</code>.</p> <p>Make a copy of the template with a suffix that is meaningful (e.g. <code>config/local/hmri_local_defaults_mystudy.m</code>) and modify it according to your needs and objectives. It is recommended to delete all unchanged entries and keep the modified parameters only, to improve readability (one can more easily see what parameters are specific to a given study or data processing).</p> <p>In the SPM Batch GUI, select the <code>Configure toolbox</code> module first. It must be in first position before any other module from the hMRI toolbox. Select your customised default file. Standard defaults from <code>hmri_defaults.m</code> will be used except for the ones you modified, which will overwrite the standard ones. Then select <code>Create hMRI maps</code> or <code>Process hMRI maps</code>. A different default file can be used for map creation and for map processing. The <code>Configure toolbox</code> module can be inserted both before the <code>Create hMRI maps</code> and <code>Process hMRI maps</code> modules, with a different customised default file for each module.</p>"},{"location":"docs/defaultsAndCustomization/#customize-b1-mapping-acquisition-and-processing-parameters","title":"Customize B1 mapping acquisition and processing parameters","text":"<p>Most of the time, no customization is required for B1 mapping parameters. However, when required, the customization comes handy e.g. to handle data without available metadata (this includes data from a B1 mapping protocol unknown from the toolbox). Such an example is provided at the bottom of this page.</p> <p>The standard default parameters for B1 mapping acquisition are defined in <code>config/hmri_b1_standard_defaults.m</code> and the corresponding template file for customization is <code>config/local/hmri_b1_local_defaults.m</code>. Parameters defined in the template <code>config/local/hmri_b1_local_defaults.m</code> are identical to the ones defined in <code>config/hmri_b1_standard_defaults.m</code>.</p> <p>Make a copy of the template with a suffix that is meaningful (e.g. <code>config/local/hmri_b1_local_defaults_myB1protocol.m</code>) and modify it according to your needs and objectives. It is recommended to delete all unchanged entries and keep the modified parameters only, to improve readability (one can more easily see what parameters are specific to the customized B1 protocol).</p> <p>In the <code>Create hMRI maps</code> module of the SPM Batch GUI, select the <code>B1 type</code>. If you choose 3D_AFI, 3D_EPI or UNICORT, you can additionally select a customised default file. Standard defaults from <code>hmri_b1_standard_defaults.m</code> will be used except for the ones you modified, which will overwrite the standard ones.</p>"},{"location":"docs/defaultsAndCustomization/#list-of-parameters","title":"List of parameters","text":"<p>All parameters are stored in a global variable <code>hmri_def</code> which is a structure containing the fields described below. Default values can easily be retrieved using <code>hmri_get_defaults.m</code>. Most fields are listed below as * name [ default value* ] - description.</p> <p>Global parameters B1 mapping processing parameters Create hMRI maps parameters Process hMRI maps parameters</p>"},{"location":"docs/defaultsAndCustomization/#global-parameters","title":"Global parameters","text":"<p>These parameters are generally used across all the hMRI modules.</p> <ul> <li> <p>centre [ centre ] - to specify the research centre - to be customized in the local configuration file. Not   mandatory but saved with the defaults used for a given data processing. Therefore comes handy to trace the origin of a   given set of generated maps.</p> </li> <li> <p>local_defaults [ hMRI/config/local/hmri_local_defaults.m ] - customised defaults file location. Not mandatory.</p> </li> <li> <p>cleanup [ true ] - clean up temporary directories created during processing (   e.g. <code>B1Calc</code>, <code>RFSens</code>, <code>MapCreation</code>) to keep the only <code>Results</code> directory and <code>Supplementary</code> subdirectory with   relevant results. Set it to false if you wish to inspect intermediate steps e.g. for debugging purpose or to track   unexpected results back to the original data.</p> </li> <li> <p>json - format for JSON metadata, defined as a structure:</p> <ul> <li><code>extended</code> [ false ]: true if metadata stored as extended header field in the nifti image.</li> <li><code>separate</code> [ true ]: true if metadata stored as separate JSON file with same name as corresponding nifti image</li> <li><code>anonym</code> [ basic ]: during DICOM to NIFTI conversion, patient ID (presumably not containing patient confidential   data), age (years at the time of the data acquisition), sex, size and weight are kept; patient name, date of birth   and DICOM filename (often containing the patient name) are removed (   see <code>anonymise_metadata.m</code> for details). *   IMPORTANT WARNING: EFFECTIVE ANONYMISATION IS NOT GUARANTEED !!! The anonymisation implemented depends on the   structure and content of the DICOM header and might not be effective in many cases.*</li> <li><code>overwrite</code> [ true ]: existing metadata will be overwritten (   see <code>set_metadata.m</code> for details).</li> <li><code>indent</code> [ \u2018\\t\u2019 ]: the way JSON text is formatted (tab separated)</li> </ul> </li> <li> <p>TPM [ hMRI/tpm/eTPM.nii ] - recommended set of Tissue Probability Maps for segmentation and spatial processing.</p> </li> <li> <p>autoreorient_template - default template for auto-reorientation.</p> </li> <li> <p>segment - default parameters for segmentation. This field is effectively the job to be handed to   spm_preproc_run.     By default, parameters are set to</p> <ul> <li>create tissue class images (<code>c*</code>) in the native space of the source image (<code>tissue(*).native = [1 0]</code>) for tissue   classes 1-5</li> <li>save both BiasField and BiasCorrected volumes (<code>channel.write = [1 1]</code>)</li> <li>recommended values from SPM12 (October 2017)</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#b1-mapping-processing-parameters","title":"B1 Mapping Processing Parameters","text":"<p>Relevant default parameters are listed below for each type of B1 mapping input. Please refer to <code>hMRI/config/hmri_b1_standard_defaults.m</code> for a complete list. See further below for examples of B1 local defaults customization based on the <code>hmri_b1_local_defaults.m</code> template.</p> <p>Note</p> <p>For acquisition parameters, default values are a fallback solution for B1 data processing when no metadata are available. Use of metadata is recommended to retrieve site- &amp; protocol-specific parameters and ensure appropriate data handling and processing.</p>"},{"location":"docs/defaultsAndCustomization/#i3d_epi","title":"i3D_EPI","text":"<p>Info</p> <p>EPI spin-echo (SE)/stimulated-echo (STE) method. Please see Lutti2010 and Lutti2012</p> <ul> <li> <p>B0 &amp; B1 processing parameters - hmri_def.b1map.i3D_EPI.b1proc</p> <ul> <li>T1 [ 1192 ]: average brain T1 (ms). Default value is strictly valid only for in vivo brain imaging at 3T.   The T1 value is used to account for T1 recovery during the mixing time between the SE and the STE.</li> <li>eps [ 0.0001 ]: regularisation value added to the denominator of the STE/SE ration to avoid division by   small numbers giving very large values.</li> <li>Nonominalvalues [ 5 ]: number of SE/STE pairs to used for parameter estimation. The <code>Nonominalvalues</code> number   of pairs giving the B1 estimate with the lowest standard deviation over the pairs will be used.</li> <li>nAmbiguousAngles [ 2 ]: how many <code>[90*(n-1),90+90*(n-1)]</code> degree ranges to test to overcome acos ambiguity.   Minimum of 2, more than 3 probably not needed for reasonable SE/STE flip angle pairs.</li> <li>HZTHRESH [ 110 ]: threshold in Hz. Areas of high potential distortions due to B0 field inhomogeneities are   masked out in the final B1 map, as strong B0 inhomogeneities can give rise to bias in the B1 map. The threshold   may need to be increased on scanners with reduced field homogeneity, but bear in mind that the larger the field   deviation, the larger the potential bias in the B1 map.</li> <li>SDTHRESH [ 5 ]: B1 is estimated by choosing the combination of angles which gives the smallest standard   deviation. This threshold masks out voxels where the optimal standard deviation over the angles is still large,   even for the optimal angles. The appropriate threshold will vary with <code>Nonominalvalues</code>.</li> <li>ERODEB1 [ 1 ]: the B1 mask is eroded to avoid edge artefacts and then padded to fill in holes and cover the   whole brain. This parameter gives the erosion kernel size.</li> <li>PADB1 [ 3 ]: padding kernel size.</li> <li>B1FWHM [ 8 ]: smoothing kernel size in mm.</li> <li>match_vdm [ 1 ]: whether to use the FieldMap toolbox to write the forward warped magnitude image (i.e.   magnitude image from fieldmap acquisition, coregistered &amp; resliced to anat image).</li> <li>b0maskbrain [ 1 ]: whether to generate a brain mask for distortion correction.</li> </ul> </li> <li> <p>B1 validation options for BIDS-input data - hmri_def.b1map.i3D_EPI.b1validation</p> <ul> <li>checkTEs [ false ]: whether to do input validation using image TEs. Assumes SE has shorter TE than STE in   metadata (qMRI-BIDS assumption).   Disabled by default as this assumption is not valid for the metadata in the DICOMs from some sequences.</li> <li>useBidsFlipAngleField [ false ]: read nominal flip angles from   qMRI-BIDS FlipAngle   metadata. Disabled by default as this metadata is often not set appropriately.</li> </ul> </li> <li> <p>B1 acquisition parameters - hmri_def.b1map.i3D_EPI.b1acq</p> <ul> <li>beta [ 115:-5:65 ]: (degrees) range of nominal flip angles used. Note: the SE/STE B1 mapping sequence uses   a set of RF pulses with nominal flip angles beta, 2 \u00d7 beta and beta to create pairs of spin echo and stimulated   echo images.</li> <li>TM [ 31.2 ]: mixing time (stimulated echo).</li> <li>tert [ 540e-3*24 ]: total EPI readout time (EchoSpacing \u00d7 numberPElines).</li> <li>blipDIR [ +1 ]: sign of blip-encoded k-space sampling (phase encoding direction).</li> </ul> </li> <li> <p>B0 acquisition parameters - hmri_def.b1map.i3D_EPI.b0acq</p> <ul> <li>shortTE [ 10 ]: shortest echo time in ms</li> <li>longTE [ 12.46 ]: longest echo time in ms</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#i3d_afi","title":"i3D_AFI","text":"<p>Info</p> <p>Actual flip angle imaging (AFI) method. Please see [Yarnykh2007]</p> <ul> <li> <p>Acquisition parameters hmri_def.b1map.i3D_AFI.b1acq</p> <ul> <li>TR2TR1ratio [ 0.2 ]: TR of second input volume divided by TR of first input volume (acquisition parameter).   This will be ignored if the two separate TRs are individually specified in the respective metadata field of each   volume or an <code>alTR</code> array of TR values is found in the metadata.</li> <li>alphanom [ 60 ]: (degrees) nominal flip angle (acquisition parameter). This is normally read from the   metadata.</li> </ul> </li> <li> <p>Masking parameters (disabled by default) hmri_def.b1map.i3D_AFI.b1mask</p> <ul> <li>domask [ false ]: whether to mask   using <code>hmri_create_pm_brain_mask</code></li> <li>fwhm [ 5 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>nerode [ 2 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>ndilate [ 4 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>thresh [ 0.5 ]: % option for <code>hmri_create_pm_brain_mask</code></li> </ul> </li> <li> <p>Smoothing parameters hmri_def.b1map.i3D_AFI.b1proc</p> <ul> <li>B1FWHM [ 8 ]: (mm) full-width half maximum of smoothing kernel for B1 map. Set to 0 to disable smoothing. If   domask is <code>true</code>, then smoothing will only be done within the mask.</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#dam","title":"DAM","text":"<p>Info</p> <p>Double angle mapping.</p> <ul> <li> <p>Acquisition parameters hmri_def.b1map.DAM.b1acq</p> <ul> <li>alphanom [ 60 ]: (degrees) nominal flip angle (acquisition parameter). This is normally read from the   metadata.</li> </ul> </li> <li> <p>Masking parameters (disabled by default) hmri_def.b1map.DAM.b1mask</p> <ul> <li>domask [ false ]: whether to mask   using <code>hmri_create_pm_brain_mask</code></li> <li>fwhm [ 5 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>nerode [ 2 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>ndilate [ 4 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>thresh [ 0.5 ]: % option for <code>hmri_create_pm_brain_mask</code></li> </ul> </li> <li> <p>Smoothing parameters hmri_def.b1map.DAM.b1proc</p> <ul> <li>B1FWHM [ 8 ]: (mm) full-width half maximum of smoothing kernel for B1 map. Set to 0 to disable smoothing. If   domask is <code>true</code>, then smoothing will only be done within the mask.</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#tfl_b1_map","title":"TFL_B1_MAP","text":"<p>Info</p> <p>Please see Chung2010.</p> <ul> <li> <p>Masking parameters (disabled by default) hmri_def.b1map.tfl_b1_map.b1mask</p> <ul> <li>domask [ false ]: whether to mask   using <code>hmri_create_pm_brain_mask</code></li> <li>fwhm [ 5 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>nerode [ 2 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>ndilate [ 4 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>thresh [ 0.5 ]: % option for <code>hmri_create_pm_brain_mask</code></li> </ul> </li> <li> <p>Smoothing parameters hmri_def.b1map.tfl_b1_map.b1proc</p> <ul> <li>B1FWHM [ 8 ]: (mm) full-width half maximum of smoothing kernel for B1 map. Set to 0 to disable smoothing. If   domask is <code>true</code>, then smoothing will only be done within the mask.</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#rf_map","title":"RF_MAP","text":"<p>Info</p> <p>SE/STE method from a service sequence by Siemens.</p> <ul> <li> <p>Masking parameters (disabled by default) hmri_def.b1map.rf_map.b1mask</p> <ul> <li>domask [ false ]: whether to mask   using <code>hmri_create_pm_brain_mask</code></li> <li>fwhm [ 5 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>nerode [ 2 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>ndilate [ 4 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>thresh [ 0.5 ]: % option for <code>hmri_create_pm_brain_mask</code></li> </ul> </li> <li> <p>Smoothing parameters hmri_def.b1map.rf_map.b1proc</p> <ul> <li>B1FWHM [ 8 ]: (mm) full-width half maximum of smoothing kernel for B1 map. Set to 0 to disable smoothing. If   domask is <code>true</code>, then smoothing will only be done within the mask.</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#unicort","title":"UNICORT","text":"<p>Info</p> <p>Please see Weiskopf2011.</p> <ul> <li>Processing parameters - hmri_def.b1map.UNICORT.procpar<ul> <li>reg = 10^-3</li> <li>FWHM = 60</li> <li>thr = 5</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#pre-processed-b1","title":"Pre-processed B1","text":"<ul> <li>Any B1 map pre-calculated using one of the above methods or another method can be used as pre-processed B1 input.</li> <li>A scaling factor can be entered in the batch to convert the pre-processed B1 map into appropriate units (the toolbox   expects B1 maps in [p.u.] of the nominal flip angle).</li> <li> <p>Masking can optionally be applied (disabled by default) hmri_def.b1map.pre_processed_B1.b1mask</p> <ul> <li>domask [ false ]: whether to mask   using <code>hmri_create_pm_brain_mask</code></li> <li>fwhm [ 5 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>nerode [ 2 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>ndilate [ 4 ]: option for <code>hmri_create_pm_brain_mask</code></li> <li>thresh [ 0.5 ]: % option for <code>hmri_create_pm_brain_mask</code></li> </ul> </li> <li> <p>Smoothing can optionally be performed (disabled by default) hmri_def.b1map.pre_processed_B1.b1proc</p> <ul> <li>B1FWHM [ 0 ]: (mm) full-width half maximum of smoothing kernel for B1 map. Set to 0 to disable smoothing. If   domask is <code>true</code>, then smoothing will only be done within the mask.</li> </ul> </li> </ul>"},{"location":"docs/defaultsAndCustomization/#no-b1-bias-correction","title":"No B1 Bias Correction","text":"<ul> <li>No parameters relevant for customization.</li> </ul>"},{"location":"docs/defaultsAndCustomization/#create-hmri-maps-parameters","title":"Create hMRI Maps Parameters","text":""},{"location":"docs/defaultsAndCustomization/#general-r1pdr2mt-map-creation-parameters","title":"General R1/PD/R2*/MT Map Creation Parameters","text":"<ul> <li> <p>small_angle_approx [ true ] - whether to use the small angle approximation when computing R1 and PD. <code>true</code>:   classic method from Helms2008a. <code>false</code>: method that is also valid for large flip angles   from Edwards2021. Note that if imperfect spoiling correction is used, then the correction   parameters must have been calculated using the same approximation level.</p> </li> <li> <p>R2sOLS [ true ] - create a combined R2* map using all the contrasts (ESTATICS; Weiskopf2014).</p> </li> <li> <p>R2s_fit_method [ \u2018OLS\u2019 ] - choose method of R2* fitting. This is a trade-off between speed and accuracy;   see Edwards2022 for more information. <code>'OLS'</code>: classic ESTATICS log-linear ordinary least   squares model; fast but not as accurate as WLS1. <code>'WLS1'</code>: log-linear weighted least squares ESTATICS with one   iteration; slower than OLS but significantly more accurate because it accounts for the heteroskedasticity induced by   the logarithm. Uses parallelization over voxels to speed up calculation. <code>'WLS2'</code> and <code>'WLS3'</code>: log-linear weighted   least squares ESTATICS with 2 or 3 iterations of the weight estimation (which should theoretically improve the   accuracy); did not show great improvement over WLS1 in test data. <code>'NLLS_OLS'</code> and <code>'NLLS_WLS1'</code>: nonlinear least   squares ESTATICS using either OLS or WLS1, respectively, to provide the initial parameter estimates. Not affected by   heteroskedasticity, but very slow, even with parallelization over voxels. <code>'OLS'</code> is default for backwards   compatibility with older versions of the toolbox, but we recommend trying <code>'WLS1'</code> when accuracy is important.</p> </li> <li> <p>neco4R2sfit [ 4 ] - minimum number of echoes to calculate R2* map. Strictly speaking, the minimum is 2. For a   robust estimation, the minimum number of echoes required depends on many factors, including:</p> <ul> <li>SNR/resolution</li> <li>distribution/spacing between TEs: note that early echoes are more affected by the specific contrast, violating the   assumption of a common decay between contrasts.</li> <li>number of contrasts available (fewer echoes per contrast required for 3 (PDw, T1w, MTw) contrasts as compared to 2   or even 1).</li> </ul> </li> </ul> <p>To be on the safe side, a minimum of 6 echoes is recommended (Weiskopf2014).   Further studies are required to come up with more detailed and informed guidelines. Use fewer echoes at your own risk\u2026!</p> <ul> <li> <p>fullOLS [ true ] - <code>true</code>: then ESTATICS fit at TE=0 is used for the further map calculation steps. This is the   recommended method to get rid of any R2* bias in the other quantitative maps. <code>false</code>: the average over echoes for   each contrast is used.</p> </li> <li> <p>interp [ 3 ] - define a coherent interpolation factor used all through the map creation process. Default is 3,   but if you want to keep SNR and resolution as close as possible to the original images, it is recommended to use sinc   interpolation (e.g. [ -7 ]).</p> </li> <li> <p>qMRI_maps.QA [ true ] - generate quality assurance evaluation data.</p> </li> <li> <p>qMRI_maps.ACPCrealign [ false ] - to realign qMRI maps to MNI. This parameter is kept for backward   compatibility. It corresponds to the realignment implemented as part of the map calculation (   see <code>hmri_create_MTProt.m</code>). It is recommended to rather reorient all images prior any processing using the   Auto-Reorient module provided with the toolbox (type <code>help hmri_autoreorient</code> for details or open the SPM &gt; Tools &gt;   hMRI Tools &gt; Auto-Reorient module in the Batch GUI).</p> </li> <li> <p>coreg2PDw [ true ] - whether to perform coregistration of T1w images, MTw images, and B1 bias map to the average   PDw image. The coregistration step can be disabled using this flag (not recommended, only useful for simulated data or   data that have already been coregistered by the user before being input into the toolbox). ADVANCED USER ONLY.</p> </li> <li> <p>coreg_flags - coregistration parameters for registering T1w and MTw weighted images to the average PDw image;   see <code>spm_coreg.m</code> in SPM for details.</p> <ul> <li>sep [ [4 2] ]: For high resolution (&lt; 0.8 mm) data, we have found that adding extra steps to the   registration can improve map quality, e.g. for 0.5 mm data we have found [4 2 1 0.5] to be needed to avoid   registration artefacts, but this comes at the expense of slowing down map creation.</li> <li>cost_fun [ \u2018nmi\u2019 ]</li> <li>fwhm [ [7 7] ]</li> </ul> </li> <li> <p>coreg_bias_flags - coregistration parameters for B1 bias maps to the average (or TE=0 fit) PDw image;   see <code>spm_coreg.m</code> in SPM for details.</p> <ul> <li>sep [ [4 2] ]</li> <li>cost_fun [ \u2018nmi\u2019 ]</li> <li>fwhm [ [7 7] ]</li> </ul> </li> <li> <p>UNICORT.PD [ false ] - if true, uses the UNICORT-derived B1 transmit field bias for PD map calculation.   ADVANCED USER ONLY. WARNING: this method has not been validated for PD calculation!</p> </li> <li>UNICORT.MT [ false ] - if true, uses the UNICORT-derived B1 transmit field bias for MT map calculation.   ADVANCED USER ONLY. WARNING: this method has not been validated for MT calculation!</li> </ul> <p>NOTE ON THE ABOVE UNICORT PARAMETERS: Unified Segmentation correction for transmit (UNICORT) and receive field   inhomogeneities is currently not applied cumulatively to correct for both sources of bias in the maps. In principle,   when no transmit nor receive fields are measured, the Unified Segmentation approach for RF sensitivity bias correction   could be combined with the UNICORT approach for B1 transmit bias estimation to generate the PD maps. This is currently   not made available by default in the toolbox by lack of a validation study assessing the performance of such an   approach. Based on the same idea, in the absence of a measured B1 transmit field, the B1 transmit bias field map   estimated from the R1 map using UNICORT could be used to remove the higher-order transmit field contribution in MT   maps. Again, without further methodological validation of these methods, it is not recommended to use the   lower-accuracy UNICORT-derived B1 maps (Weiskopf2011) for correction of the higher-order B1   transmit effects on MT saturation.</p>"},{"location":"docs/defaultsAndCustomization/#rf-sensitivity-bias-correction","title":"RF Sensitivity Bias Correction","text":"<ul> <li>RFsens.smooth_kernel [ 12 ] - smoothing kernel applied to the sensitivity maps used for RF sensitivity   correction (when RF sensitivity mapping data have been acquired).</li> </ul>"},{"location":"docs/defaultsAndCustomization/#threshold-values-for-qmri-maps","title":"Threshold Values for qMRI Maps","text":"<ul> <li>qMRI_maps_thresh.R1 [ 2000 ] - for R1 maps. NOTE: threshold given in s-1 \u00d71000 (i.e. 2 s-1 here).</li> <li>qMRI_maps_thresh.A [ 10^5 ] - for A maps, i.e. PD maps before BiasField correction and calibration. NOTE: this   value is acquisition-dependent. On different scanners, the threshold might need to be adapted. Values in A maps must   be properly thresholded for the map calculation to proceed reliably. As a rule of thumb, a value of 10\u00d7 the maximum   brain intensity in the A map can be used.</li> <li>qMRI_maps_thresh.R2s [ 10 ] - for R2* maps. NOTE: threshold given in s-1 /1000 (i.e. 10000 s-1 here).</li> <li>qMRI_maps_thresh.MTR [ 50 ] - for MTR maps.</li> <li>qMRI_maps_thresh.MTR_synt [ 50 ] - for MTR_synth maps.</li> <li>qMRI_maps_thresh.MT [ 5 ] - for MT maps in [p.u.].</li> </ul>"},{"location":"docs/defaultsAndCustomization/#pd-map-calculation","title":"PD Map Calculation","text":"<ul> <li>PDproc.calibr [ true ] - whether to calibrate the PD map based on PD(WM) = 69% [Tofts 2003]. Will be   automatically set to false if no B1 map is available</li> <li>PDproc.WBMaskTh [ 0.1 ] - threshold for calculation of whole-brain mask from TPMs. Used to correct for Receiving   B1 field inhomogeneities in PD maps.</li> <li>PDproc.WMMaskTh [ 0.95 ] - threshold for calculation of white matter mask from TPMs. Used to calibrate the PD   value within the white matter (69%).</li> <li>PDproc.biasreg [ 10^(-5) ] - segmentation parameter (see Unified Segmentation in SPM12)</li> <li>PDproc.biasfwhm [ 50 ] - segmentation parameter (see Unified Segmentation in SPM12)</li> <li>PDproc.nr_echoes_forA [ 6 ] - number of PD-weighted echoes to be used to calculate the PD map. In order to   minimize R2* bias on the PD estimates and gain in robustness for bias-field correction, the number of echoes should   be minimum (\u201caverage\u201d calculated over the first echo only) for PD calculation. However, with T2*-weighting bias   correction (see below), a higher number of echoes is preferred in order to provide good SNR Balteau2018].</li> <li>PDproc.T2scorr [ true ] - to correct the A map for T2*-weighting bias before PD map calculation. Not necessary   if the fullOLS option is enabled [Balteau2018].</li> </ul>"},{"location":"docs/defaultsAndCustomization/#imperfect-rf-spoiling-correction","title":"Imperfect RF Spoiling Correction","text":"<p>The correction parameters used in <code>hmri_create_MTProt.m</code> to correct for imperfect RF spoiling in R1 map calculation are based on [Preibisch2009]. The correction requires that a B1+ map be available (in addition to PD- and T1-weighted images). The correction parameters used in the hMRI toolbox can be calculated using a dedicated module in the toolbox. See Corbin2021 for guidance on calculation including the choice of T2 time and the moment of the spoiler gradients and the diffusion-spoiling effects of the readout.</p> <p>The correction values P2_a and P2_b given in this section have been pre-calculated for a range of acquisition parameters most commonly found in our MPM protocols (namely the Echo Times (TE), Repetition Times (TR) and Flip Angles ( FA) of the respective multi-echo FLASH acquisitions). In future versions, the calculation will be more generally extended to other sets of acquisition parameters as an additional module. Currently, no RF spoiling correction will be applied if no match is found between the MPM acquisition parameters and the parameters sets defined below. Please contact us if you wish to correct for imperfect spoiling effects and your acquisition parameters are not among the standard ones defined below.</p> <p>If the correction values were computed using the small angle approximation for R1 estimation, then they will need to be recomputed without the small angle approximation if they are to be applied to an R1 map computed without the small angle approximation.</p> <p>Given the possible confusion and resulting mistake (imperfect spoiling correction applied to the wrong sequence), when TR and FA values match one of the listed cases below, the option is disabled by default. When enabling the imperfect spoiling correction, make sure the coefficients retrieved were definitely calculated for the protocol used!</p> <ul> <li>imperfectSpoilCorr.enabled [ false ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#default-mpm-acquisition-parameters-v2k-protocol-prisma","title":"Default MPM Acquisition Parameters (v2k Protocol, Prisma)","text":"<p>These values are updated at runtime in <code>hmri_create_MTProt.m</code> in order to choose the right RF spoiling correction parameters. The acquisition parameters include the (first) Echo Times (TE) - assuming equidistant echoes in the multi-echo acquisition, Repetition Times (TR) and Flip Angles (FA) of the respective multi-echo FLASH acquisitions:</p> <ul> <li>MPMacq.TE_mtw [ 2.34 ] - in ms</li> <li>MPMacq.TE_t1w [ 2.34 ] - in ms</li> <li>MPMacq.TE_pdw [ 2.34 ] - in ms</li> <li>MPMacq.TR_mtw [ 24.5 ] - in ms</li> <li>MPMacq.TR_t1w [ 24.5 ] - in ms</li> <li>MPMacq.TR_pdw [ 24.5 ] - in ms</li> <li>MPMacq.fa_mtw [ 6 ] - in deg</li> <li>MPMacq.fa_t1w [ 21 ] - in deg</li> <li>MPMacq.fa_pdw [ 6 ] - in deg</li> <li>MPMacq.tag [ v2k ] - tag for the protocol (default is the v2k protocol)</li> </ul>"},{"location":"docs/defaultsAndCustomization/#protocol-tags-and-pre-calculated-correction-factors","title":"Protocol Tags and Pre-calculated Correction Factors","text":"<p>Below, for each quadruplet of [TR_pdw TR_t1w fa_pdw fa_t1w] values, a protocol tag is defined together with the pre-calculated P2_a and P2_b correction factors. NOTE: all tags MUST start with a letter and include only letters, numbers and underscores (NO space) since they are used to define a structure fieldname for RF spoiling correction.</p>"},{"location":"docs/defaultsAndCustomization/#1-classic-fil-protocol-weiskopf2011","title":"1. Classic FIL Protocol Weiskopf2011:","text":"<ul> <li>MPMacq_set.tags{1} [ ClassicFIL ]</li> <li>MPMacq_set.vals{1} [ 23.7 18.7 6 20 ] - [TR_pdw TR_t1w fa_pdw fa_t1w] values</li> <li>imperfectSpoilCorr.ClassicFIL.tag = \u2018Classic FIL protocol\u2019</li> <li>imperfectSpoilCorr.ClassicFIL.P2_a = [78.9228195006542,-101.113338489192,47.8783287525126];</li> <li>imperfectSpoilCorr.ClassicFIL.P2_b = [-0.147476233142129,0.126487385091045,0.956824374979504];</li> <li>imperfectSpoilCorr.ClassicFIL.small_angle_approx = <code>true</code>;</li> <li>imperfectSpoilCorr.ClassicFIL.enabled [ hmri_def.imperfectSpoilCorr.enabled ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#2-new-filhelms-protocol","title":"2. New FIL/Helms Protocol","text":"<ul> <li>MPMacq_set.tags{2} [ NewFILHelms ]</li> <li>MPMacq_set.vals{2} [ 24.5 24.5 5 29 ] - [TR_pdw TR_t1w fa_pdw fa_t1w] values</li> <li>imperfectSpoilCorr.NewFILHelms.tag = \u2018New FIL/Helms protocol\u2019;</li> <li>imperfectSpoilCorr.NewFILHelms.P2_a = [93.455034845930480,-120.5752858196904,55.911077913369060];</li> <li>imperfectSpoilCorr.NewFILHelms.P2_b = [-0.167301931434861,0.113507432776106,0.961765216743606];</li> <li>imperfectSpoilCorr.NewFILHelms.small_angle_approx = <code>true</code>;</li> <li>imperfectSpoilCorr.NewFILHelms.enabled [ hmri_def.imperfectSpoilCorr.enabled ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#3-siemens-product-sequence-protocol-used-in-lausanne-g-krueger","title":"3. Siemens Product Sequence Protocol used in Lausanne (G Krueger)","text":"<ul> <li>MPMacq_set.tags{3} [ SiemPrLausGK ]</li> <li>MPMacq_set.vals{3} [ 24.0 19.0 6 20 ] - [TR_pdw TR_t1w fa_pdw fa_t1w] values</li> <li>imperfectSpoilCorr.SiemPrLausGK.tag = \u2018Siemens product Lausanne (GK) protocol\u2019;</li> <li>imperfectSpoilCorr.SiemPrLausGK.P2_a = [67.023102027100880,-86.834117103841540,43.815818592349870];</li> <li>imperfectSpoilCorr.SiemPrLausGK.P2_b = [-0.130876849571103,0.117721807209409,0.959180058389875];</li> <li>imperfectSpoilCorr.SiemPrLausGK.small_angle_approx = <code>true</code>;</li> <li>imperfectSpoilCorr.SiemPrLausGK.enabled [ hmri_def.imperfectSpoilCorr.enabled ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#4-high-res-08mm-fil-protocol","title":"4. High-res (0.8mm) FIL Protocol","text":"<ul> <li>MPMacq_set.tags{4} [ HResFIL ]</li> <li>MPMacq_set.vals{4} [ 23.7 23.7 6 28 ] - [TR_pdw TR_t1w fa_pdw fa_t1w] values</li> <li>imperfectSpoilCorr.HResFIL.tag = \u2018High-res FIL protocol\u2019;</li> <li>imperfectSpoilCorr.HResFIL.P2_a = [1.317257319014170e+02,-1.699833074433892e+02,73.372595677371650];</li> <li>imperfectSpoilCorr.HResFIL.P2_b = [-0.218804328507184,0.178745853134922,0.939514554747592];</li> <li>imperfectSpoilCorr.HResFIL.small_angle_approx = <code>true</code>;</li> <li>imperfectSpoilCorr.HResFIL.enabled [ hmri_def.imperfectSpoilCorr.enabled ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#5-new-high-res-08mm-fil-protocol","title":"5. New  High-res (0.8mm) FIL Protocol","text":"<ul> <li>MPMacq_set.tags{5} [ NHResFIL ]</li> <li>MPMacq_set.vals{5} [ 25.25 25.25 5 29 ] - [TR_pdw TR_t1w fa_pdw fa_t1w] values</li> <li>imperfectSpoilCorr.NHResFIL.tag = \u2018New High-res FIL protocol\u2019;</li> <li>imperfectSpoilCorr.NHResFIL.P2_a = [88.8623036106612,-114.526218941363,53.8168602253166];</li> <li>imperfectSpoilCorr.NHResFIL.P2_b = [-0.132904017579521,0.113959390779008,0.960799295622202];</li> <li>imperfectSpoilCorr.NHResFIL.small_angle_approx = <code>true</code>;</li> <li>imperfectSpoilCorr.NHResFIL.enabled [ hmri_def.imperfectSpoilCorr.enabled ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#6-new-1mm-protocol-seq-version-v2k-default","title":"6. New  1mm Protocol - Seq Version v2k (default)","text":"<ul> <li>MPMacq_set.tags{6} [ v2k ]</li> <li>MPMacq_set.vals{6} [ 24.5 24.5 6 21 ] - [TR_pdw TR_t1w fa_pdw fa_t1w] values</li> <li>imperfectSpoilCorr.v2k.tag = \u2018v2k protocol\u2019;</li> <li>imperfectSpoilCorr.v2k.P2_a = [71.2817617982844,-92.2992876164017,45.8278193851731];</li> <li>imperfectSpoilCorr.v2k.P2_b = [-0.137859046784839,0.122423212397157,0.957642744668469];</li> <li>imperfectSpoilCorr.v2k.small_angle_approx = <code>true</code>;</li> <li>imperfectSpoilCorr.v2k.enabled [ hmri_def.imperfectSpoilCorr.enabled ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#7-800um-protocol-seq-version-v3-released-used-by-meg-group","title":"7. 800um Protocol - Seq Version v3* Released used by MEG Group","text":"<p>Note</p> <p>Correction parameters below were determined via Bloch-Torrey simulations but end result agrees well with EPG-derived correction for this RF spoiling increment of 137 degrees Callaghan2015a.</p> <ul> <li>MPMacq_set.tags{6} [ v3star ]</li> <li>MPMacq_set.vals{6} [ 25 25 6 21 ] - [TR_pdw TR_t1w fa_pdw fa_t1w] values</li> <li>imperfectSpoilCorr.v3star.tag = \u2018v3star protocol\u2019;</li> <li>imperfectSpoilCorr.v3star.P2_a = [57.427573706259864,-79.300742898810441,39.218584751863879];</li> <li>imperfectSpoilCorr.v3star.P2_b = [-0.121114060111119,0.121684347499374,0.955987357483519];</li> <li>imperfectSpoilCorr.v3star.small_angle_approx = <code>true</code>;</li> <li>imperfectSpoilCorr.v3star.enabled [ hmri_def.imperfectSpoilCorr.enabled ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#unknown-protocol","title":"Unknown Protocol","text":"<p>If the acquisition parameters are recognised as none of the above predefined sets, no RF spoiling correction will be applied.</p> <ul> <li>imperfectSpoilCorr.Unknown.tag = \u2018Unknown protocol. No spoiling correction defined.\u2019</li> <li>imperfectSpoilCorr.Unknown.enabled [ false ]</li> </ul>"},{"location":"docs/defaultsAndCustomization/#process-hmri-maps-parameters","title":"Process hMRI Maps Parameters","text":""},{"location":"docs/defaultsAndCustomization/#unified-segmentation-parameters","title":"Unified Segmentation Parameters","text":"<p>The recommended Tissue Probability Maps (TPM) for segmentation in the Process hMRI maps module are - by default - the same as the global ones, but one could (want to) use another set of TPM at some point. The map creation works with \u201d standard\u201d weighted-MR images to build the parametric maps. These parametric maps taken together for a multichannel-segmentation could show more details (for example subcortical nuclei) and would therefore require a specific TPM - still to be built\u2026</p> <ul> <li>proc.TPM [ hmri_def.TPM ] - recommended TPM</li> <li>proc.w_native = <code>[[1 1];[1 1];[1 1];[0 0];[0 0];[0 0]]</code>; - write native and native+dartelImp for GM/WM/CSF only (   tissue classes 1-3).</li> <li>proc.w_warped = <code>[[1 1];[1 1];[1 1];[0 0];[0 0];[0 0]]</code>; - write warped and mod+unmod for GM/WM/CSF only (tissue   classes 1-3).</li> <li>proc.nGauss = <code>[2 2 2 3 4 2]</code>; - Number of Gaussians per tissue class, originally <code>[1 1 2 3 4 2]</code> in SPM.</li> </ul>"},{"location":"docs/defaultsAndCustomization/#examples","title":"Examples","text":"<p>Below are provided examples illustrating how the toolbox can be customized, concretely. They are based on the hMRI sample dataset, available here. All examples provided in the Wiki are available in the <code>hMRI/examples</code> directory.</p>"},{"location":"docs/defaultsAndCustomization/#global-parameters-customization","title":"Global Parameters Customization","text":"<p>Global parameters, generally used across all the toolbox modules, allow you to select specific processing parameters and options. In general, standard default parameters are considered a reference and do not require any modification for the toolbox to run properly.</p> <p>In the following example, we show how some parameters from <code>config/local/hmri_local_defaults.m</code> can be customized and used during processing. The customized (and commented) <code>hmri_local_default_example_1.m</code> has been added to the <code>hMRI/examples</code> directory.</p> <p>The parameters in the example file can be modified and tried out together or separately. Comments in the example file will guide you to chose and compare the effect of various parameters. The following steps describe how to make the customized default values effective.</p> <ul> <li>in the SPM12 batch GUI, select SPM &gt; Tools &gt; hMRI Tools &gt; Configure toolbox.</li> <li>under <code>Defaults parameters</code>, select <code>Customised</code>.</li> <li>under <code>Customised</code>, select the example file (modified or not).</li> <li>select SPM &gt; Tools &gt; hMRI Tools &gt; Create hMRI maps.</li> <li>see the map creation step-by-step example to fill in the fields for this module.</li> <li>save and run the batch.</li> </ul> <p>For comparison, the same batch can be run:</p> <ul> <li>with modified default values in the customized local   file <code>hmri_local_default_example_1.m</code>;</li> <li>with <code>Standard</code> instead of <code>Customised</code> under <code>Defaults parameters</code> in the <code>Configure toolbox</code> module.</li> </ul>"},{"location":"docs/defaultsAndCustomization/#b1-mapping-parameters-customization","title":"B1 Mapping Parameters Customization","text":"<p>B1 mapping parameters, especially for the 3D-EPI SE/STE (Lutti2009, Lutti2012) and 3D-AFI  (Yarnykh2007) types of data acquisition, are more likely to require customization in order to account for local parameters and generate the B1 map output correctly. Many different sequences and protocols are available to generate such B1 mapping data, and acquisition parameters cannot be retrieved in a consistent way across sequences. As a result, even if metadata are available, the toolbox might not be able to retrieve the required parameters. In that case, as well as when no metadata are available at all, the map creation will rely on default parameters to process the data and a customised B1 mapping default file will be needed. If you are unsure of the rightness of the parameters used to process B1 mapping data, please refer to the history of messages and warnings output in the Matlab command window during processing. In particular, pay attention to messages warning you about \u201cparameters not found\u201d and the usage of default parameters instead.</p> <p>To illustrate such case, in this second example, we customize <code>config/local/hmri_b1_local_defaults.m</code> to match the acquisition parameters corresponding to the 3D-EPI SE/STE B1 mapping protocol used in the hMRI sample dataset. The customized (and commented) <code>hmri_b1_local_defaults_example_1.m</code> has been added to the <code>hMRI/examples</code> directory.</p> <p>To run the B1 customization example:</p> <ul> <li>Make a fresh copy of the hMRI sample dataset.</li> <li>Delete all the *.json files associated to the B1 and B0 mapping files (in   the <code>mfc_seste_b1map_v1e_0004</code>, <code>gre_field_mapping_1acq_rl_0005</code> and <code>gre_field_mapping_1acq_rl_0006</code> directories).   That way, no metadata are available to process B1 mapping data. Default values will be used.</li> <li>In the SPM12 batch GUI, select SPM &gt; Tools &gt; hMRI Tools &gt; Create hMRI maps.</li> <li>See the map creation step-by-step example to fill in the fields for this module.</li> <li>In <code>B1 bias correction</code> &gt; <code>Processing parameters</code>, select <code>Customised B1 default file</code>, then select the   customised <code>hmri_b1_local_defaults_example_1.m</code>.</li> <li>Save the batch and run the map creation module.</li> </ul> <p>For comparison, you can:</p> <ul> <li>variant 1: Run the same batch but change <code>B1 bias correction</code> &gt; <code>Processing parameters</code> back   to <code>Use metadata or standard defaults</code>.</li> <li>variant 2: Run <code>Create hMRI maps</code> exactly as described in   the map creation step-by-step example (including all metadata *.json files).</li> </ul> <p>Relevant aspects to compare:</p> <ul> <li>B1 processing parameters displayed in the Matlab command window (or in the   output <code>Results/Supplementary/MPM_map_creation_b1map_params.json</code> file). Parameters should be identical for variant   2 and for the above B1 customization example. For variant 1, parameters should differ. Moreover, warnings in   the Matlab command window tell you about the metadata not found for the B1 protocol and the fact that defaults will be   used. Since the standard defaults are use this time instead of the customised ones, incorrect parameters have been   used to generate the B1 map.</li> <li>B1 maps saved in <code>Results/Supplementary</code></li> <li>other quantitative maps (MT, PD, R1) will also slightly differ in variant 1 as compared to variant 2 and the *   B1 customization example*.</li> </ul>"},{"location":"docs/getStarted/","title":"Getting Started","text":""},{"location":"docs/getStarted/#getting-started","title":"Getting Started","text":"<p>To run the hMRI Toolbox, you will need Matlab and SPM. Matlab versions from release R2018a (MATLAB 9.4) and up have been used to develop and test the software. Some functionality may still work in earlier versions of Matlab, but this is not officially supported. Please note that a single Matlab version should be used to process all of a given dataset, as results can differ slightly between versions due to changes in Matlab\u2019s internal algorithms.</p>"},{"location":"docs/getStarted/#setting-up-the-hmri-toolbox","title":"Setting Up the hMRI Toolbox","text":""},{"location":"docs/getStarted/#spm","title":"SPM","text":"<p>The hMRI Toolbox relies on functionalities of the Statistical Parameter Mapping toolbox (SPM) and has been developed starting from SPM12 (version 12.3 - r6906). It is recommended to have the latest release of SPM12 at hand and to make sure you have added the SPM root directory to your Matlab Path.</p> <p>Download SPM</p>"},{"location":"docs/getStarted/#install-the-hmri-toolbox","title":"Install the hMRI Toolbox","text":"<p>For users of the hMRI Toolbox who do not plan to modify the code by themselves, it is recommended to download the latest release. After downloading and unzipping the compressed file, proceed with the installation instructions below.</p> <p>Download Latest Releases</p> <p>For information on the various releases and related changes, please refer to the Releases page.</p> <p>The installation procedure allows users to manage the hMRI Toolbox repository independently of their SPM installation, thanks to a redirection script. This is especially convenient when a version control system is used for SPM as well. The following steps describe how to get your own copy of the Toolbox in a directory of your choice and how to make it available as an SPM tool.</p>"},{"location":"docs/getStarted/#redirection-script","title":"Redirection script","text":"<p>The redirection script is a short script to be copied to your SPM/toolbox directory. It will point to the full implementation of the hMRI Toolbox, thus making it available as an SPM tool. The following steps describe how to proceed:</p> <ul> <li>Create (empty) directory <code>hMRI</code> into <code>&lt;path-to-your-spm&gt;/toolbox</code></li> <li>Copy <code>hMRI-Toolbox/install/tbx_cfg_hmri_redirect.m</code> into <code>&lt;path-to-your-spm&gt;/toolbox/hMRI</code></li> <li>Add the hMRI-Toolbox root directory (containing the unzipped release or your local repository including the full   implementation of the hMRI-Toolbox) to your Matlab Path. NOTE: in Matlab, choose the <code>Add Folder...</code> option. Don\u2019t use   the <code>Add with Subfolders...</code> option. The appropriate subfolders will be automatically added when starting the toolbox.</li> </ul>"},{"location":"docs/getStarted/#very-first-test","title":"Very first test","text":"<ul> <li>Start Matlab and the SPM (fMRI) user interface: <code>spm fmri</code>,</li> <li>Start the Batch GUI (Batch button in the SPM Menu).</li> <li>Check whether you can access the hMRI Toolbox: <code>SPM &gt; Tools &gt; hMRI Tools</code></li> </ul>"},{"location":"docs/getStarted/#download-demo-dataset-protocol-examples","title":"Download Demo Dataset &amp; Protocol Examples","text":"<p>A full dataset is available for download, as well as several protocols containing all acquisition parameters. The following section makes use of this dataset.</p>"},{"location":"docs/getStarted/#tutorials","title":"Tutorials","text":"<p>Examples and tutorials are based on the hMRI demo dataset available here. Examples can also be found in the <code>hMRI/examples</code> directory.</p>"},{"location":"docs/getStarted/#available-examples","title":"Available Examples:","text":"<ul> <li>Map creation step-by-step example</li> <li>Toolbox configuration and customization examples</li> </ul>"},{"location":"docs/getStarted/#unit-tests","title":"Unit tests","text":"<p>A number of unit tests are provided in <code>hMRI/hmri_code_tests</code>. To run these you must first ensure that the hMRI Toolbox is on your Matlab path, then navigate to that folder and run <code>runtests</code> in Matlab. Please note that some tests require data to be downloaded to the <code>hmri_code_tests</code> directory. If you have write access, then these data can be downloaded using <code>hMRI/hmri_code_tests/hmri_get_ut_data.m</code> to fix these errors.</p>"},{"location":"docs/getStarted/#for-developers-and-advanced-users","title":"For Developers and Advanced Users","text":"<p>For users who wish to keep their version of the hMRI Toolbox up-to-date with the repository, and developers who wish to contribute to the Toolbox development, it is necessary to have Git installed. You can download Git here. See the Git documentation pages to get started if you are new to Git.</p> <p>If you are an advanced user, you might want to clone the hMRI Toolbox repository and keep your version regularly up-to-date. The following Git command line will create a hMRI Toolbox directory in the current directory and clone the toolbox repository within that directory:</p> <pre><code>$ git clone https://github.com/hMRI-group/hMRI-toolbox.git\n</code></pre> <p>If you wish to further develop the toolbox, we recommend you fork the repository. For more details on forking and more development guidelines, please refer to the  Develop &amp; Contribute page.</p>"},{"location":"docs/getStarted/#help-and-resources","title":"Help and Resources","text":"<p>This webpage is the main source of information to learn about how to use the toolbox and how it works, together with the toolbox paper (pre-print).</p> <p>On top of this, help information can be found in the Help section of each matlab script (or by typing <code>help &lt;function&gt;</code> in Matlab) and in the SPM Batch GUI in the Help box at the bottom of the Batch window.</p> <p>If you cannot find an answer to your question or a solution to your issue, you can get in contact with other users through our public chat, the mailing list, or by opening a new issue on the bugtracker. All information on how to access these resources can be found on the Contact page.</p>"},{"location":"docs/getStarted/#note-on-runtimes","title":"Note on Runtimes","text":"<p>The runtime of the various processes depends of course on the available hardware. On a MacBookPro with i7 (2.9GHz) with 16GB RAM and macOS 10.13.6 (High Sierra) with Matlab 2017b the creation of qMRI maps with the toolbox using the example dataset takes approximately 11 minutes. This includes the transmit and receive bias correction. The spatial processing of multiple subjects relies on adjusted SPM functionalities. Thus, the runtime for this part of the toolbox is very similar to the runtime known for the corresponding processes in SPM.</p>"},{"location":"docs/helpScripts/","title":"Help Scripts","text":""},{"location":"docs/helpScripts/#help","title":"Help","text":"<p>On top of this Wiki, help information can be found in the Help section of each matlab script (or by typing <code>help &lt;function&gt;</code> in Matlab) and in the SPM Batch GUI in the Help box at the bottom of the Batch window. Both sources are collected here for convenience.</p> <p>Note</p> <p>The information below can already give you an overview of the toolbox but needs to be updated - version November 2017! Refer to the help available directly in the scripts and Batch GUI.</p>"},{"location":"docs/helpScripts/#help-on-individual-scripts","title":"Help on individual scripts","text":""},{"location":"docs/helpScripts/#hmri_autoreorientm","title":"hmri_autoreorient.m","text":"<pre><code> FORMAT out = hmri_autoreorient(ref, template, other) \n\n PURPOSE: Reorientation of the images towards the MNI space is a standard \n step in neuroimage processing, and often a prerequisite for successful \n segmentation. The Unified Segmentation process is indeed rather sensitive \n to the initial orientation of the image. We provide you with a simple \n tool for reorientation of all images prior to any further processing \n (including multiparameter map calculation).  \n\n METHODS: Reorientation is based on rigid-body coregistration of a \n suitable image (i.e. contrast must be well enough defined to allow for \n reliable coregistration) to the MNI space (i.e. mainly set the AC \n location and correct for head rotation) and application of the \n coregistration matrix to all images acquired during the same session \n (specified as \"other images\"). The code makes use of spm_affreg and \n templates available in SPM.  \n\n IN: \n - ref      : filename of the reference image to reorient, \n - template : a template image, already in the MNI space, to which the \n              reference image is reoriented, \n - other    : filenames of other images to be reoriented along with the \n              reference image. \n\n OUT: \n - out, a structure with fields: \n       - files  : the list (cell array of strings) of reoriented images  \n                  listed in the same order as the input (ref, then other). \n       - M      : the rigid-body transformation matrix  \n       - invM   : the rigid-body transformation matrix inverted \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_b1map_processm","title":"hmri_create_B1Map_process.m","text":"<pre><code> PURPOSE \n To mask, pad and smooth the unwrapped B1 map. \n Part of the hMRI toolbox, B1+ map calculation, EPI SE/STE protocol. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_b1map_unwarpm","title":"hmri_create_B1Map_unwarp.m","text":"<pre><code> PURPOSE \n For B0 undistortion of EPI-based B1 maps, part of the hMRI toolbox. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_fieldmapm","title":"hmri_create_FieldMap.m","text":"<pre><code> This is a fraction of the FieldMap script (case 'createfieldmap') \n rewritten for the hMRI toolbox in order to make use of the original \n SPM12's FieldMap script wherever no modification is required. The \n modification implies the use of new segmentation tools to create the \n brain mask for unwrapping. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_mtprotm","title":"hmri_create_MTProt.m","text":"<pre><code> This is hmri_create_MTProt, part of the hMRI-Toolbox. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_rfsensm","title":"hmri_create_RFsens.m","text":"<pre><code> RF sensitivity calculation as part of the hmri toolbox \n Based on a script by Daniel Papp \n Wellcome Trust Centre for Neuroimaging (WTCN), London, UK. \n daniel.papp.13@ucl.ac.uk \n Adapted by Dr. Tobias Leutritz \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_b1mapm","title":"hmri_create_b1map.m","text":"<pre><code> FORMAT P_trans = hmri_create_b1map(jobsubj) \n    jobsubj - are parameters for one subject out of the job list. \n    NB: ONE SINGLE DATA SET FROM ONE SINGLE SUBJECT IS PROCESSED HERE, \n    LOOP OVER SUBJECTS DONE AT HIGHER LEVEL. \n    P_trans - a vector of file names with P_trans(1,:) = anatomical volume \n        for coregistration and P_trans(2,:) = B1 map in percent units. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_comm_adjustm","title":"hmri_create_comm_adjust.m","text":"<pre><code> This function is a version of comm_adjust.m customized for T1 like \n images, i.e. MT images. Now it is necessary to define as input parameter \n the Template to be used for the commisure adjustment. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_pm_brain_maskm","title":"hmri_create_pm_brain_mask.m","text":"<pre><code> Calculate a brain mask in hMRI Toolbox \n This is pm_brain_mask (SPM12/toolbox/FieldMap) modified for the hMRI \n toolbox. Calls hmri_create_pm_segment instead of pm_segment. This is the \n only modification, syntax is unchanged otherwise. \n\n FORMAT bmask = hmri_create_pm_brain_mask(P,flags) \n\n P - is a single pointer to a single image \n\n flags - structure containing various options \n         template - which template for segmentation \n         fwhm     - fwhm of smoothing kernel for generating mask \n         nerode   - number of erosions \n         thresh   - threshold for smoothed mask  \n         ndilate  - number of dilations \n\n__________________________________________________________________________ \n\n Inputs \n A single *.img conforming to SPM data format (see 'Data Format'). \n\n Outputs \n Brain mask in a matrix \n__________________________________________________________________________ \n\n The brain mask is generated by segmenting the image into GM, WM and CSF,  \n adding these components together then thresholding above zero. \n A morphological opening is performed to get rid of stuff left outside of \n the brain. Any leftover holes are filled.  \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_pm_segmentm","title":"hmri_create_pm_segment.m","text":"<pre><code> To segment the brain and extract a brain mask in the hMRI Toolbox \n This function replaces pm_segment used in the FieldMap toolbox \n (SPM12/toolbox/FieldMap). Used in hmri_create_pm_brain_mask. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_create_unicortm","title":"hmri_create_unicort.m","text":"<pre><code> function P = hmri_create_unicort(P_PDw, P_R1, jobsubj) \n P_PDw: proton density weighted FLASH image (small flip angle image) for \n masking \n P_R1: R1 (=1/T1) map estimated from dual flip angle FLASH experiment \n</code></pre>"},{"location":"docs/helpScripts/#hmri_get_defaultsm","title":"hmri_get_defaults.m","text":"<pre><code> Get/set the defaults values associated with an identifier \n FORMAT defaults = hmri_get_defaults \n Return the global \"defaults\" variable defined in hmri_defaults.m. \n\n FORMAT defval = hmri_get_defaults(defstr) \n Return the defaults value associated with identifier \"defstr\". \n Currently, this is a '.' subscript reference into the global \n \"hmri_def\" variable defined in hmri_defaults.m. \n\n FORMAT hmri_get_defaults(defstr, defval) \n Sets the defaults value associated with identifier \"defstr\". The new \n defaults value applies immediately to: \n * new modules in batch jobs \n * modules in batch jobs that have not been saved yet \n This value will not be saved for future sessions of hMRI. To make \n persistent changes, edit hmri_defaults.m. \n\n NOTE, specific to hMRI tool (might become obsolete in future versions): \n In order to allow centre specific defaults, *without* editing/commenting \n the default file itself, these centre specific values are placed in a \n centre specific substructure, named with 'fil', 'lren' or 'crc'(see the  \n hmri_defaults.m file). \n Then if the required field is not found in the standard default  \n structure, the centre specific field, e.g. 'fil', 'lren' or crc', is  \n included *automatically* in the call. Therefore you can access a centre \n specific parameter by specifying the centre properly in the defaults \n file AND calling for the parameter. \n\n Example: \n -------- \n Definition of hmri_def \n hmri_def.centre = 'crc' ;  \n hmri_def.param1 = 123 ; \n hmri_def.crc.TR  = 3;  % in sec \n hmri_def.fil.TR  = 2;  % in sec \n hmri_def.lren.TR  = 2.5;  % in sec \n\n v = hmri_get_defaults('param1') \n returns the value 123 into v \n v = hmri_get_defaults('TR') \n returns the value 3 into v \n If you edit the file and set hmri_def.centre = 'fil' ; \n then v = hmri_get_defaults('TR') \n returns the value 2 into v \n\n A few constraints for this trick to work: \n - the default structure has a field called 'centre' defining the current \n   centre values to use ('fil', crc', 'lren' to begin with) \n - all centre substructures should have the same organisation! \n - centre specific fields and global fields should have *different* names, \n   e.g. do NOT define \"def.TE = 20\" and \"def.fil.TE = 30\" fields as the  \n   latter would NEVER be used. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_get_versionm","title":"hmri_get_version.m","text":"<pre><code> To retrieve the SHA1, author, date and message of the last commit of the \n current branch of the repository and return the information as a string. \n This script MUST be located in the root directory of the repository. \n If the Toolbox has been copied whitout version tracking, the version can \n only be retrieved if a version.txt file is already present in the root \n directory of the Toolbox. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_proc_mpmsmoothm","title":"hmri_proc_MPMsmooth.m","text":"<pre><code> Applying tissue specific smoothing, aka. weighted averaging, in order to  \n limit partial volume effect.  \n\n FORMAT \n   fn_out = hmri_proc_MPMsmooth(fn_wMPM, fn_mwTC, fn_TPM, fwhm) \n\n INPUT \n - fn_wMPM : filenames (char array) of the warped MPM, i.e. the \n             w*MT/R1/R2s/A.nii files \n - fn_mwTC : filenames (char array) of the modulated warped tissue \n             classes, i.e. the mwc1/2*.nii files \n - fn_TPM  : filenames (char array) of the a priori tissue probability  \n             maps to use, matching those in fn_mwTC \n - fwhm    : width of smoothing kernel in mm [6 by def.] \n - l_TC    : explicit list of tissue classes used [1:nTC by def.] \n\n OUTPUT \n - fn_out  : cell array (one cell per MPM) of filenames (char array) of  \n             the \"smoothed tissue specific MPMs\". \n\n REFERENCE \n Draganski et al, 2011, doi:10.1016/j.neuroimage.2011.01.052 \n</code></pre>"},{"location":"docs/helpScripts/#hmri_run_createm","title":"hmri_run_create.m","text":"<pre><code> PURPOSE \n Calculation of multiparameter maps using B1 maps for B1 bias correction. \n If no B1 maps available, one can choose not to correct for B1 bias or \n apply UNICORT. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_run_proc_usm","title":"hmri_run_proc_US.m","text":"<pre><code> Deal with the spatial preprocessing, 1 subject at a time: segmentation of \n the MT and T1 images \n</code></pre>"},{"location":"docs/helpScripts/#hmri_run_proc_dartel_normm","title":"hmri_run_proc_dartel_norm.m","text":"<pre><code> function out = hmri_run_proc_dartel_norm(job) \n derived from spm_dartel_norm_fun_local \n\n It applies the \"Dartel - Normalize to MNI\" onto the tissue classes and \n parametric maps, from the job created in the batch. \n</code></pre>"},{"location":"docs/helpScripts/#hmri_run_proc_pipelinem","title":"hmri_run_proc_pipeline.m","text":"<pre><code> Deal with the preprocessing pipelines. There are 2 options \n 1/ US+Smooth \n 2/ US+Dartel+Smooth \n\n Input include only some parametric maps, the structural maps (for \n segmentation), the required smoothing and which pipeline to use. All \n other options are hard-coded! \n By default, these pipelines focus only on the first 2 tissue classes, \n i.e. GM and WM only. \n\n For more flexibility, individual modules can be combined. :-) \n</code></pre>"},{"location":"docs/helpScripts/#hmri_run_proc_smoothm","title":"hmri_run_proc_smooth.m","text":"<pre><code> Function to run the smoothing/weighted averaging over a bunch of \n subjects, as defined in the batch interface. \n Data are selected in a 'many subject' style, i.e. all the images of one \n type are selected from many subjects at once! \n\n The 'out' structure is organized as a structure out.tc where \n - tc is a cell-array of size {n_TCs x n_pams} \n - each element tc{ii,jj} is a cell array {n_subj x 1} with each subject's \n   smoothed data for the ii^th TC and jj^th MPM \n</code></pre>"},{"location":"docs/helpScripts/#confighmri_b1_standard_defaultsm","title":"config\\hmri_b1_standard_defaults.m","text":"<pre><code> Sets the defaults for B1 bias correction, part of the hMRI toolbox. \n</code></pre>"},{"location":"docs/helpScripts/#confighmri_defaultsm","title":"config\\hmri_defaults.m","text":"<pre><code> Sets the defaults parameters which are used by the hMRI toolbox. \n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! \n DON'T MODIFY THIS FILE, IT CONTAINS THE REFERENCE DEFAULTS PARAMETERS. \n Please refer to hMRI-Toolbox\\config\\local\\hmri_local_defaults.m to \n customise defaults parameters.   \n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! \n\n FORMAT hmri_defaults \n__________________________________________________________________________ \n\n THIS FILE SHOULD NOT BE MODIFIED.  \n To customize the hMRI-Toolbox defaults parameters so they match your own \n site- or protocol-specific setup, please refer to the defaults files in \n hMRI-Toolbox\\config\\local. In particular, use \"hmri_local_defaults.m\". \n Make a copy with meaningful name, modify as desired and select as general \n defaults file in the \"Configure toolbox\" branch of the hMRI-Toolbox. \n\n The structure and content of this file are largely inspired by the \n equivalent file in SPM. \n</code></pre>"},{"location":"docs/helpScripts/#configlocalhmri_b1_local_defaultsm","title":"config\\local\\hmri_b1_local_defaults.m","text":"<pre><code> Sets the defaults for B1 bias correction, part of the hMRI toolbox. \n Consider this file as a template for local settings specifications.  \n Please read below for details. \n</code></pre>"},{"location":"docs/helpScripts/#configlocalhmri_local_defaultsm","title":"config\\local\\hmri_local_defaults.m","text":"<pre><code> PURPOSE \n To set user-defined (site- or protocol-specific) defaults parameters \n which are used by the hMRI toolbox. Customized processing parameters can \n be defined, overwriting defaults from hmri_defaults. Acquisition \n protocols can be specified here as a fallback solution when no metadata \n are available. Note that the use of metadata is strongly recommended.  \n</code></pre>"},{"location":"docs/helpScripts/#spm12spm_dicom_convertm","title":"spm12\\spm_dicom_convert.m","text":"<pre><code> Convert DICOM images into something that SPM can use (e.g. NIfTI) \n FORMAT spm_dicom_convert(hdr,opts,root_dir,format,out_dir) \n Inputs: \n hdr      - a cell array of DICOM headers from spm_dicom_headers \n opts     - options: \n              'all'      - all DICOM files [default] \n              'mosaic'   - the mosaic images \n              'standard' - standard DICOM files \n              'spect'    - SIEMENS Spectroscopy DICOMs (some formats only) \n                           This will write out a 5D NIFTI containing real \n                           and imaginary part of the spectroscopy time  \n                           points at the position of spectroscopy voxel(s). \n              'raw'      - convert raw FIDs (not implemented) \n root_dir - 'flat'       - do not produce file tree [default] \n              With all other options, files will be sorted into \n              directories according to their sequence/protocol names: \n            'date_time'  - Place files under ./&lt;StudyDate-StudyTime&gt; \n            'patid'      - Place files under ./&lt;PatID&gt; \n            'patid_date' - Place files under ./&lt;PatID-StudyDate&gt; \n            'patname'    - Place files under ./&lt;PatName&gt; \n            'series'     - Place files in series folders, without \n                           creating patient folders \n format   - output format: \n              'nii'      - Single file NIfTI format [default] \n              'img'      - Two file (hdr+img) NIfTI format \n            All images will contain a single 3D dataset, 4D images will \n            not be created. \n out_dir  - output directory name. \n\n json     - a structure with fields:  \n               extended -&gt; metadata stored as extended nii header included \n                           in the nii image [default: false] \n               separate -&gt; metadata stored in separate json file [default: \n                           false] \n               Note: extended and separate fields can be simultaneously  \n                           true or false. \n               anonym   -&gt; 'basic' (default), 'full', 'none'  \n               Important note: anonymisation depends on input headers and \n                           cannot be guaranteed. \n\n Output: \n out      - a struct with a single field .files. out.files contains a \n            cellstring with filenames of created files. If no files are \n            created, a cell with an empty string {''} is returned. \n</code></pre>"},{"location":"docs/helpScripts/#spm12spm_jsonwritem","title":"spm12\\spm_jsonwrite.m","text":"<pre><code> Serialize a JSON (JavaScript Object Notation) structure \n FORMAT spm_jsonwrite(filename,json) \n filename - JSON filename \n json     - JSON structure \n\n FORMAT S = spm_jsonwrite(json) \n json     - JSON structure \n S        - serialized JSON structure (string) \n\n FORMAT [...] = spm_jsonwrite(...,opts) \n opts     - structure of optional parameters: \n              indent: string to use for indentation [Default: ''] \n              replacementStyle: string to control how non-alphanumeric \n                characters are replaced [Default: 'underscore'] \n\n References: \n   JSON Standard: http://www.json.org/ \n</code></pre>"},{"location":"docs/helpScripts/#spm12configspm_cfg_dicomm","title":"spm12\\config\\spm_cfg_dicom.m","text":"<pre><code> SPM Configuration file for DICOM Import \n</code></pre>"},{"location":"docs/helpScripts/#spm12configspm_run_dicomm","title":"spm12\\config\\spm_run_dicom.m","text":"<pre><code> SPM job execution function \n takes a harvested job data structure and call SPM functions to perform \n computations on the data. \n Input: \n job    - harvested job data structure (see matlabbatch help) \n Output: \n out    - computation results, usually a struct variable. \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadataanonymise_metadatam","title":"spm12\\metadata\\anonymise_metadata.m","text":"<pre><code> USAGE: hdrout = anonymise_metadata(hdr, opts) \n hdr is a DICOM header read with spm_dicom_header \n opts are anonymisation options: \n       opts.anonym = 'none': no anonymisation, all patient data kept in \n                       the metadata. \n                     'full': no patient information is kept at all \n                     'basic': patient ID (presumably not containing his \n                       name), age (years at the time of the data \n                       acquisition), sex, size and weight are kept, \n                       patient name, date of birth and DICOM filename \n                       (often containing the patient name) are removed. \n\n !!! IMPORTANT WARNING: EFFEVTIVE ANONYMISATION IS NOT GUARANTEED !!! \n The anonymisation implemented here depends on the structure and content \n of the DICOM header and might not be effective in many cases.  \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadatafind_field_namem","title":"spm12\\metadata\\find_field_name.m","text":"<pre><code> PURPOSE \n To search a structure recursively to retrieve fields with a \n specific name (or part of that name). Returns the number of fields found \n with that name (nFieldFound) and a cell array containing the path of \n each occurrence of that name (each line in fieldList gives the list of \n nested fields down to the expected one, e.g. \n inStruct.(fieldList{1,1}).(fieldList{1,2}). ... \n .(fieldList{1,last-non-empty-one})). If unsuccessful, the  \n search returns [0,{}].   \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadataget_jhdr_and_offsetm","title":"spm12\\metadata\\get_jhdr_and_offset.m","text":"<pre><code> FORMAT \n [jhdr, offset] = get_jhdr_and_offset(hdr) \n hdr       a Matlab structure \n jhdr      the JSONified Matlab structure \n offset    the offset at which image data start in the nifti file \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadataget_metadatam","title":"spm12\\metadata\\get_metadata.m","text":"<pre><code> PURPOSE \n To retrieve JSON-encoded metadata from extended nifti images or \n associated JSON file. \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadataget_metadata_valm","title":"spm12\\metadata\\get_metadata_val.m","text":"<pre><code> This is get_metadata_val, part of the metadata library \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadatahas_extended_headerm","title":"spm12\\metadata\\has_extended_header.m","text":"<pre><code> Must strip the ',1' (at the end of the file extension '.nii,1')  \n if the name has been collected using e.g. spm_select: \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadatainit_metadatam","title":"spm12\\metadata\\init_metadata.m","text":"<pre><code> To create JSON-encoded metadata during DICOM to nifti conversion, \n including all acquisition parameters. The metadata can either (or both) \n be stored in the extended header of the nifti image or saved as a \n separate file. This function is called by spm_dicom_convert. In case of \n an extended nii header, the size of the JSON header is used to define a \n new offset (N.dat.offset) for the image data in the nifti file and the \n JSON header is written into the nifti file. The modified nifti object N \n is returned so the data can be written in it according to the new offset \n (in spm_dicom_convert). In case of a separate JSON file, N is returned \n unchanged and the JSON metadata are written in a separate file (same file \n name as the nifti image, with .json extension). \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadatainit_output_metadata_structurem","title":"spm12\\metadata\\init_output_metadata_structure.m","text":"<pre><code> PURPOSE: To create a metadata structure to be used for newly created \n output images. \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadataread_asciim","title":"spm12\\metadata\\read_ASCII.m","text":"<pre><code> function ascout = read_ASCII(ascin) \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadatareformat_spm_dicom_headerm","title":"spm12\\metadata\\reformat_spm_dicom_header.m","text":"<pre><code> To tidy up and rearrange CSA fields in the header, including formatting \n the ASCII part into a proper Matlab structure (Note: this is specific to \n Siemens DICOM format but could be extended to other cases where needed)  \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadataset_metadatam","title":"spm12\\metadata\\set_metadata.m","text":"<pre><code> To insert or update JSON-encoded metadata into nifti images (for extended \n nifti format) or JSON files associated to standard nifti format.  \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadatatidy_csam","title":"spm12\\metadata\\tidy_CSA.m","text":"<pre><code> function tdycsa = tidy_CSA(csahdr) \n DESCRIPTION: \n To rearrange CSAImageHeaderInfo, CSASeriesHeaderInfo, ... structures \n and make it a simplified, easier to browse structure (Siemens specific). \n USAGE: \n tdycsa = tidy_CSA(csahdr) \n where csahdr is a structure, content of the CSA field. \n WRITTEN BY: Evelyne Balteau - Cyclotron Research Centre \n</code></pre>"},{"location":"docs/helpScripts/#spm12metadatawrite_extended_headerm","title":"spm12\\metadata\\write_extended_header.m","text":"<pre><code> FORMAT \n write_extended_header(fnam, jsonhdr) \n fnam      the name of a nifti file \n jsonhdr   the JSONified Matlab structure to be written as extended header \n</code></pre>"},{"location":"docs/helpScripts/#help-for-the-batch-options","title":"Help for the BATCH options","text":""},{"location":"docs/helpScripts/#configure-toolbox","title":"Configure toolbox","text":"<p>Customised default parameters can be set here by selecting a customised [hmri_local_defaults_*.m] file. Type [help hmri_local_defaults] for more details.</p> <ul> <li> <p>Defaults parameters    You can either stick with standard defaults parameters from [hmri_defaults.m] or select your own customised defaults   file.</p> <ul> <li>Standard</li> </ul> </li> <li> <p>Customised    Select the [hmri_local_defaults_*.m] file containing the specific defaults to process your data. Note that all other   defaults values will be reinitialised to their standard values.</p> </li> </ul>"},{"location":"docs/helpScripts/#dicom-import","title":"DICOM Import","text":"<p>DICOM Conversion. Most scanners produce data in DICOM format. This routine attempts to convert DICOM files into SPM compatible image volumes, which are written into the current directory by default. Note that not all flavours of DICOM can be handled, as DICOM is a very complicated format, and some scanner manufacturers use their own fields, which are not in the official documentation at http://medical.nema.org/</p> <ul> <li> <p>DICOM files    Select the DICOM files to convert.</p> </li> <li> <p>Directory structure for converted files    Choose root directory of converted file tree. The options are:</p> <ul> <li>Output directory: ./StudyDate-StudyTime/ProtocolName</li> <li>Output directory: ./PatientID/ProtocolName</li> <li>Output directory: ./PatientID/StudyDate-StudyTime/ProtocolName</li> <li>Output directory: ./ProtocolName</li> <li>No directory hierarchy: Convert all files into the output directory, without sequence/series subdirectories</li> </ul> </li> <li> <p>Output directory    Select a directory where files are written.</p> </li> <li> <p>Protocol name filter    A regular expression to filter protocol names. DICOM images whose protocol names do not match this filter will not be   converted.</p> </li> <li> <p>Conversion options</p> </li> <li> <p>Output image format    DICOM conversion can create separate img and hdr files or combine them in one file. The single file option will help   you save space on your hard disk, but may be incompatible with programs that are not NIfTI-aware.   In any case, only 3D image files will be produced.</p> </li> <li> <p>Use ICEDims in filename    If image sorting fails, one can try using the additional SIEMENS ICEDims information to create unique filenames. Use   this only if there would be multiple volumes with exactly the same file names.</p> </li> <li> <p>JSON metadata</p> <ul> <li>JSON metadata format    Metadata (acquisition parameters, processing steps, \u2026)    can be stored using JSON format. The JSON metadata can    either (or both) be stored as a separate JSON file    or as an extended header (included in the image file,    for nii output format only).</li> </ul> </li> </ul>"},{"location":"docs/helpScripts/#auto-reorient","title":"Auto-Reorient","text":"<p>Function to automatically (but approximately) rigid-body reorient a T1 image (or any other usual image modality) in the MNI space, i.e. mainly set the AC location and correct for head rotation, in order to further proceed with the segmentation/normalisation of the image. This is useful since the Unified Segmentation process is rather sensitive to the initial orientation of the image.</p> <p>A set of other images can be reoriented along the 1st one. They should be specified as \u201cOther Images\u201d.</p> <p>The following outputs are available as dependencies for further processing:</p> <ul> <li>reoriented images (provided as individual images or as a group of images),</li> <li>transformation matrix M (if needed to be applied to other images at a later stage using SPM &gt; Util &gt; Reorient Images),</li> <li>inverted transformation matrix M (to go back to the initial orientation using SPM &gt; Util &gt; Reorient Images).</li> </ul> <p>NOTE: the job structure and the output structure are saved as JSON data along with the reoriented images.</p> <ul> <li> <p>Image    Select the image that is best suited for rigid-body coregistration to MNI space. Ideally, the GM/WM contrast in that   image should be well defined.</p> </li> <li> <p>Template    Auto-Reorient needs to know which modality of image is selected and which template to use for the rigid-body   coregistration.   You can select the template image from SPM12/canonical, SPM12/toolbox/OldNorm or any suitable source of your choice.   By defaults, SPM12/canonical/avg152T1.nii is used.   NOTE: The template must already be in the MNI orientation to make the reorientation effective!</p> </li> <li> <p>Other Images    Select all the other images that need to remain in alignment with the reference image that is reoriented. Typically,   all the images acquired during a single MRI session should be reoriented together. For convenience, select all these   images here, including the reference image.</p> </li> <li> <p>Output choice    Output directory can be the same as the input directory or user selected.</p> <ul> <li> <p>Input directory    Auto-reorientation is applied to the input files directly.</p> </li> <li> <p>Output directory    Input files are first copied to the selected directory before auto-reorientation.</p> </li> </ul> </li> <li> <p>Dependencies    Dependencies can be made available as individual output files or as a group of images, as is most convenient for the   next processing steps\u2026</p> </li> </ul>"},{"location":"docs/helpScripts/#create-hmri-maps","title":"Create hMRI maps","text":"<p>hMRI map creation based on multi-echo FLASH sequences including optional receive/transmit bias correction.</p> <ul> <li> <p>Few Subjects    Specify the number of subjects.</p> <ul> <li> <p>Subject    Specify a subject for maps calculation.</p> <ul> <li> <p>Output choice    Output directory can be the same as the input directory for each input file or user selected</p> <ul> <li> <p>Input directory    Output files will be written to the same folder as each corresponding input file.</p> </li> <li> <p>Output directory    Select a directory where output files will be written to.</p> </li> </ul> </li> <li> <p>RF sensitivity bias correction    Specify whether RF sensitivity maps have been acquired. You can select either:</p> <ul> <li>None: no RF sensitivity map has been acquired,</li> <li>Single: single set of RF sensitivity maps acquired for all contrasts,</li> <li> <p>Per contrast: one set of RF sensitivity maps acquired for each contrast.</p> </li> <li> <p>None    No RF sensitivity map was acquired.</p> </li> <li> <p>Single    Single set of RF sensitivity maps acquired for all contrasts.   Select low resolution RF sensitivity maps acquired with the head and body coils respectively, in that   order.</p> </li> <li> <p>Per contrast    One set of RF sensitivity maps is acquired for each contrast i.e. for each of the PD-, T1- and MT-weighted   multi-echo FLASH acquisitions.</p> <ul> <li> <p>RF sensitivity maps for MTw images    Select low resolution RF sensitivity maps acquired with the head and body coils respectively, in that   order.</p> </li> <li> <p>RF sensitivity maps for PDw images    Select low resolution RF sensitivity maps acquired with the head and body coils respectively, in that   order.</p> </li> <li> <p>RF sensitivity maps for T1w images    Select low resolution RF sensitivity maps acquired with the head and body coils respectively, in that   order.</p> </li> </ul> </li> </ul> </li> <li> <p>B1 bias correction    Choose the methods for B1 bias correction.   Various types of B1 mapping protocols can be handled by the hMRI toolbox when creating the multiparameter   maps. See list below for a brief description of each type. Note that all types may not be available at your   site.</p> <ul> <li>3D EPI: B1map obtained from spin echo (SE) and stimulated echo (STE) images recorded with a 3D EPI   scheme [Lutti A et al., PLoS One 2012;7(3):e32379].</li> <li>3D AFI: 3D actual flip angle imaging (AFI) method based on [Yarnykh VL, Magn Reson Med 2007;57:192-200].</li> <li>tfl_b1_map: Siemens product sequence for B1 mapping based on turbo FLASH.</li> <li>rf_map: Siemens product sequence for B1 mapping based on SE/STE.</li> <li>no B1 correction: if selected no B1 bias correction will be applied.</li> <li>pre-processed B1: B1 map pre-calculated outside the hMRI toolbox, must be expressed in percent units of   the nominal flip angle value (percent bias).</li> <li> <p>UNICORT: Use this option when B1 maps not available. Bias field estimation and correction will be   performed using the approach described in [Weiskopf et al., NeuroImage 2011; 54:2116-2124]. WARNING: the   correction only applies to R1 maps.</p> </li> <li> <p>3D EPI    Input B0/B1 data for 3D EPI protocol   As B1 input, please select all pairs of SE/STE 3D EPI images.   For this EPI protocol, it is recommended to acquire B0 field map data for distortion correction. If no B0   map available, the script will proceed with distorted images.   Please enter the two magnitude images and the presubtracted phase image from the B0 mapping acquisition,   in that order.   Regarding processing parameters, you can either stick with metadata and standard defaults parameters (   recommended) or select your own [hmri_b1_local_defaults_*.m] customised defaults file (fallback for   situations where no metadata are available).</p> <ul> <li> <p>B1 input    Select B1 input images according to the type of B1 bias correction.</p> </li> <li> <p>B0 input    Select B0 field map input images.   Only required for distortion correction of EPI-based B1 maps.   Select both magnitude images and the presubtracted phase image, in that order.</p> </li> <li> <p>Processing parameters    You can either stick with metadata and standard defaults parameters (recommended) or select your own   customised defaults file (fallback for situations where no metadata are available).</p> <ul> <li>Use metadata or standard defaults</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Customised B1 defaults file      Select the [hmri_b1_local_defaults_.m] file containing the parameters to process the B1 map data. By default, parameters will be collected from metadata when available. Defaults parameters are provided as fallback solution when metadata are not available and/or uncomplete.     Please make sure that the parameters defined in the defaults file are correct for your data. To create your own customised defaults file, edit the distributed version and save it with a meaningful name such as [hmri_b1_local_defaults_myprotocol*.m].</p> </li> </ul> </li> <li> <p>3D AFI      3D Actual Flip Angle Imaging (AFI) protocol.     As B1 input, please select a TR2/TR1 pair of magnitude images.     Regarding processing parameters, you can either stick with metadata and standard defaults parameters (recommended) or select your own [hmri_b1_local_defaults_*.m] customised defaults file (fallback for situations where no metadata are available).</p> <ul> <li> <p>B1 input    Select B1 input images according to the type of B1 bias correction.</p> </li> <li> <p>Processing parameters    You can either stick with metadata and standard defaults parameters (recommended) or select your own customised defaults file (fallback for situations where no metadata are available).</p> </li> <li> <p>Use metadata or standard defaults </p> </li> <li> <p>Customised B1 defaults file      Select the [hmri_b1_local_defaults_.m] file containing the parameters to process the B1 map data. By default, parameters will be collected from metadata when available. Defaults parameters are provided as fallback solution when metadata are not available and/or uncomplete.     Please make sure that the parameters defined in the defaults file are correct for your data. To create your own customised defaults file, edit the distributed version and save it with a meaningful name such as [hmri_b1_local_defaults_myprotocol*.m].</p> </li> </ul> </li> <li> <p>tfl_b1_map      Input B1 images for TFL B1 map protocol.     As B1 input, please select the pair of anatomical and precalculated B1 map, in that order.</p> <ul> <li>B1 input    Select B1 input images according to the type of B1 bias correction.</li> </ul> </li> <li> <p>rf_map      Input B1 images for rf_map B1 map protocol.     As B1 input, please select the pair of anatomical and precalculated B1 map, in that order.</p> <ul> <li>B1 input    Select B1 input images according to the type of B1 bias correction.</li> </ul> </li> <li> <p>pre-processed B1      Input pre-calculated B1 bias map.     Please select one unprocessed magnitude image from the B1map data set (for coregistration with the multiparameter maps) and the preprocessed B1map (in percent units), in that order.</p> <ul> <li>B1 input    Select B1 input images according to the type of B1 bias correction.</li> </ul> </li> <li> <p>UNICORT      UNICORT will be applied for B1 bias correction.     No B1 input data required.     Customized processing parameters may be introduced by loading customized defaults from a selected [hmri_b1_local_defaults_*.m] file.</p> <ul> <li> <p>Processing parameters    You can either stick with metadata and standard defaults parameters (recommended) or select your own customised defaults file (fallback for situations where no metadata are available).</p> </li> <li> <p>Use metadata or standard defaults </p> </li> <li> <p>Customised B1 defaults file      Select the [hmri_b1_local_defaults_.m] file containing the parameters to process the B1 map data. By default, parameters will be collected from metadata when available. Defaults parameters are provided as fallback solution when metadata are not available and/or uncomplete.     Please make sure that the parameters defined in the defaults file are correct for your data. To create your own customised defaults file, edit the distributed version and save it with a meaningful name such as [hmri_b1_local_defaults_myprotocol*.m].</p> </li> </ul> </li> <li> <p>no B1 correction      No B1 bias correction will be applied.     NOTE: when no B1 map is available, UNICORT might be a better solution than no B1 bias correction at all.</p> </li> <li> <p>Multiparameter input images    Input all the MT/PD/T1-weighted images.</p> </li> <li> <p>MT images      Input MT-weighted images.</p> </li> <li> <p>PD images      Input PD-weighted images.</p> </li> <li> <p>T1 images      Input T1-weighted images.</p> </li> </ul> </li> </ul>"},{"location":"docs/helpScripts/#process-hmri-maps","title":"Process hMRI maps","text":"<p>Parameter maps are spatially processed and brought into standard spacefor furhter statistical analysis. This include 3 main processing steps:</p> <ul> <li>Unified Segmentation (US) - produces individual tissue maps+ warping into MNI space</li> <li>DARTEL - improves the warping into a common space of multiplesubjects, based on their tissue maps</li> <li>Smoothing - tissue specific weighted averaging</li> </ul> <p>For simplicity, 2 standard pipelines are also set up:</p> <ul> <li> <p>US+Smooth - applies US, warps into MNI, then smoothes (weighted-average)   US+Dartel+Smooth - applies US, builds Dartel template and warpsinto MNI, then smoothes (weighted-average)</p> </li> <li> <p>Proc. hMRI -&gt; Pipelines    Parameter maps are spatially processed and brought into standard spacefor furhter statistical analysis.</p> </li> </ul> <p>For simplicity, 2 standard pipelines are also set up:     - US+Smooth - applies US, warps into MNI, then smoothes (weighted-average)       US+Dartel+Smooth - applies US, builds Dartel template and warpsinto MNI, then smoothes (weighted-average)</p> <pre><code>- **Structural images (T1w or MT) for segmentation**    \n  Select structural images, i.e. T1w or MT, for \"unified segmentation\". They are used to create the individuam\n  tissue class maps, e.g. GM and WM posterior probability maps\n\n- **Parametric maps**    \n  Select whole brain parameter maps (e.g. MT, R2\\*, FA, etc.) from all subjects for processing, one type at a time.\n\n    - **Parametric maps (single type)**    \n      Select whole brain parameter maps (e.g. MT, R2\\*, FA, etc.) from all subjects for processing.\n\n- **Gaussian FWHM**    \n  Specify the full-width at half maximum (FWHM) of the Gaussian blurring kernel in mm. Three values should be\n  entereddenoting the FWHM in the x, y and z directions.\n\n- **Pipeline**    \n  Chose the predefined pipeline that you prefer:\n    - US+Smooth - applies US, warps into MNI, then smoothes (weighted-average)\n    - US+Dartel+Smooth - applies US, builds Dartel template and warps intoMNI, then smoothes (weighted-average)\n</code></pre> <ul> <li> <p>Proc. hMRI -&gt; Individual modules    Parameter maps are spatially processed and brought into standard spacefor furhter statistical analysis.   This include 3 main processing steps:</p> <ul> <li>Unified Segmentation (US) - produces individual tissue maps+ warping into MNI space</li> <li>DARTEL - improves the warping into a common space of multiplesubjects, based on their tissue maps</li> <li> <p>Smoothing - tissue specific weighted averaging</p> </li> <li> <p>Proc. hMRI -&gt; Segmentation    Segmentation, bias correction and spatially normalisation - all in the same model.</p> </li> </ul> <p>This procedure is an extension of the old unified segmentation algorithm (and was known as \u201cNew Segment\u201d in SPM8).   The algorithm is essentially the same as that described in the Unified Segmentation paper / \\cite{ashburner05}/,   except for (i) a slightly different treatment of the mixing proportions, (ii) the use of an improved registration   model, (iii) the ability to use multi-spectral data, (iv) an extended set of tissue probability maps, which allows   a different treatment of voxels outside the brain. Some of the options in the toolbox do not yet work, and it has   not yet been seamlessly integrated into the SPM8 software. Also, the extended tissue probability maps need further   refinement. The current versions were crudely generated (by JA) using data that was kindly provided by Cynthia   Jongen of the Imaging Sciences Institute at Utrecht, NL.</p> <p>This function segments, bias corrects and spatially normalises - all in the same model/ \\cite{ashburner05}/.   Many investigators use tools within older versions of SPM for a technique that has become known as \u201coptimised\u201d   voxel-based morphometry (VBM). VBM performs region-wise volumetric comparisons among populations of subjects. It   requires the images to be spatially normalised, segmented into different tissue classes, and smoothed, prior to   performing statistical tests/ \\cite{wright_vbm,am_vbmreview,ashburner00b,john_should}/. The \u201coptimised\u201d   pre-processing strategy involved spatially normalising subjects\u201d brain images to a standard space, by matching   grey matter in these images, to a grey matter reference. The historical motivation behind this approach was to   reduce the confounding effects of non-brain (e.g. scalp) structural variability on the registration. Tissue   classification in older versions of SPM required the images to be registered with tissue probability maps. After   registration, these maps represented the prior probability of different tissue classes being found at each   location in an image. Bayes rule can then be used to combine these priors with tissue type probabilities derived   from voxel intensities, to provide the posterior probability.</p> <p>This procedure was inherently circular, because the registration required an initial tissue classification, and   the tissue classification requires an initial registration. This circularity is resolved here by combining both   components into a single generative model. This model also includes parameters that account for image intensity   non-uniformity. Estimating the model parameters (for a maximum a posteriori solution) involves alternating among   classification, bias correction and registration steps. This approach provides better results than simple serial   applications of each component.</p> <pre><code>- **Data &amp; options**    \n  Specify images for many subjects\n\n    - **Output choice**    \n      Output directory can be the same as the input directory for each input file or user selected\n\n        - **Input directory**    \n          Output files will be written to the same folder as each corresponding input file.\n\n        - **Output directory**    \n          Select a directory where output files will be written to.\n\n    - **Parametric maps**    \n      Select whole brain parameter maps (e.g. MT, R2\\*, FA, etc.) from all subjects for processing, one type at\n      a time.\n\n        - **Parametric maps**    \n          Select whole brain parameter maps (e.g. MT, R2\\*, FA, etc.) from all subjects for processing.\n\n    - **Ref. structurals**    \n      Specify a channel for processing.\n      If multiple channels are used (eg PD &amp; T2), then the same order of subjects must be specified for each\n      channel and they must be in register (same position, size, voxel dims etc..). The different channels can\n      be treated differently in terms of inhomogeneity correction etc. You may wish to correct some channels and\n      save the corrected images, whereas you may wish not to do this for other channels.\n\n        - **Structural images (T1w or MT) for segmentation**    \n          Select structural images, i.e. T1w or MT, for \"unified segmentation\". They are used to create the\n          individuam tissue class maps, e.g. GM and WM posterior probability maps\n\n        - **Bias regularisation**    \n          MR images are usually corrupted by a smooth, spatially varying artifact that modulates the intensity\n          of the image (bias). These artifacts, although not usually a problem for visual inspection, can impede\n          automated processing of the images.\n\n          An important issue relates to the distinction between intensity variations that arise because of bias\n          artifact due to the physics of MR scanning, and those that arise due to different tissue properties.\n          The objective is to model the latter by different tissue classes, while modelling the former with a\n          bias field. We know a priori that intensity variations due to MR physics tend to be spatially smooth,\n          whereas those due to different tissue types tend to contain more high frequency information. A more\n          accurate estimate of a bias field can be obtained by including prior knowledge about the distribution\n          of the fields likely to be encountered by the correction algorithm. For example, if it is known that\n          there is little or no intensity non-uniformity, then it would be wise to penalise large values for the\n          intensity non-uniformity parameters. This regularisation can be placed within a Bayesian context,\n          whereby the penalty incurred is the negative logarithm of a prior probability for any particular\n          pattern of non-uniformity.\n          Knowing what works best should be a matter of empirical exploration. For example, if your data has\n          very little intensity non-uniformity artifact, then the bias regularisation should be increased. This\n          effectively tells the algorithm that there is very little bias in your data, so it does not try to\n          model it.\n\n        - **Bias FWHM**    \n          FWHM of Gaussian smoothness of bias.\n          If your intensity non-uniformity is very smooth, then choose a large FWHM. This will prevent the\n          algorithm from trying to model out intensity variation due to different tissue types. The model for\n          intensity non-uniformity is one of i.i.d. Gaussian noise that has been smoothed by some amount, before\n          taking the exponential. Note also that smoother bias fields need fewer parameters to describe them.\n          This means that the algorithm is faster for smoother intensity non-uniformities.\n\n        - **Save Bias Corrected**    \n          Option to save a bias corrected version of your images from this channel, or/and the estimated bias\n          field.\n          MR images are usually corrupted by a smooth, spatially varying artifact that modulates the intensity\n          of the image (bias). These artifacts, although not usually a problem for visual inspection, can impede\n          automated processing of the images. The bias corrected version should have more uniform intensities\n          within the different types of tissues.\n\n- **Tissues**    \n  The data for each subject are classified into a number of different tissue types. The tissue types are defined\n  according to tissue probability maps, which define the prior probability of finding a tissue type at a\n  particular location. Typically, the order of tissues is grey matter, white matter, CSF, bone, soft tissue and\n  air/background (if using tpm/TPM.nii).\n\n    - **Tissue**    \n      A number of options are available for each of the tissues. You may wish to save images of some tissues,\n      but not others. If planning to use Dartel, then make sure you generate \"imported\"\" tissue class images of\n      grey and white matter (and possibly others). Different numbers of Gaussians may be needed to model the\n      intensity distributions of the various tissues.\n\n        - **Tissue probability map**    \n          Select the tissue probability image for this class.\n          These should be maps of eg grey matter, white matter or cerebro-spinal fluid probability. A nonlinear\n          deformation field is estimated that best overlays the tissue probability maps on the individual\n          subjects\" image.\n\n          Rather than assuming stationary prior probabilities based upon mixing proportions, additional\n          information is used, based on other subjects\" brain images. Priors are usually generated by\n          registering a large number of subjects together, assigning voxels to different tissue types and\n          averaging tissue classes over subjects. Three tissue classes are used: grey matter, white matter and\n          cerebro-spinal fluid. A fourth class is also used, which is simply one minus the sum of the first\n          three. These maps give the prior probability of any voxel in a registered image being of any of the\n          tissue classes - irrespective of its intensity.\n\n          The model is refined further by allowing the tissue probability maps to be deformed according to a set\n          of estimated parameters. This allows spatial normalisation and segmentation to be combined into the\n          same model.\n\n        - **Num. Gaussians**    \n          The number of Gaussians used to represent the intensity distribution for each tissue class can be\n          greater than one.\n          In other words, a tissue probability map may be shared by several clusters. The assumption of a single\n          Gaussian distribution for each class does not hold for a number of reasons. In particular, a voxel may\n          not be purely of one tissue type, and instead contain signal from a number of different tissues (\n          partial volume effects). Some partial volume voxels could fall at the interface between different\n          classes, or they may fall in the middle of structures such as the thalamus, which may be considered as\n          being either grey or white matter. Various other image segmentation approaches use additional clusters\n          to model such partial volume effects. These generally assume that a pure tissue class has a Gaussian\n          intensity distribution, whereas intensity distributions for partial volume voxels are broader, falling\n          between the intensities of the pure classes. Unlike these partial volume segmentation approaches, the\n          model adopted here simply assumes that the intensity distribution of each class may not be Gaussian,\n          and assigns belonging probabilities according to these non-Gaussian distributions. Typical numbers of\n          Gaussians could be two for grey matter, two for white matter, two for CSF, three for bone, four for\n          other soft tissues and two for air (background).\n          Note that if any of the Num. Gaussians is set to non-parametric, then a non-parametric approach will\n          be used to model the tissue intensities. This may work for some images (eg CT), but not others - and\n          it has not been optimised for multi-channel data. Note that it is likely to be especially problematic\n          for images with poorly behaved intensity histograms due to aliasing effects that arise from having\n          discrete values on the images.\n\n        - **Native Tissue**    \n          The native space option allows you to produce a tissue class image (c*) that is in alignment with the\n          original/* (see Figure \\ref{seg1})*/. It can also be used for \"importing\"\" into a form that can be\n          used with the Dartel toolbox (rc*).\n\n        - **Warped Tissue**    \n          You can produce spatially normalised versions of the tissue class - both with (mwc*) and without (wc*)\n          modulation (see below). These can be used for voxel-based morphometry. All you need to do is smooth\n          them and do the stats.\n\n          \"Modulation\"\" is to compensate for the effect of spatial normalisation. When warping a series of\n          images to match a template, it is inevitable that volumetric differences will be introduced into the\n          warped images. For example, if one subject\"s temporal lobe has half the volume of that of the\n          template, then its volume will be doubled during spatial normalisation. This will also result in a\n          doubling of the voxels labelled grey matter. In order to remove this confound, the spatially\n          normalised grey matter (or other tissue class) is adjusted by multiplying by its relative volume\n          before and after warping. If warping results in a region doubling its volume, then the correction will\n          halve the intensity of the tissue label. This whole procedure has the effect of preserving the total\n          amount of grey matter signal in the normalised partitions. Actually, in this version of SPM the warped\n          data are not scaled by the Jacobian determinants when generating the \"modulated\" data. Instead, the\n          original voxels are projected into their new location in the warped images. This exactly preserves the\n          tissue count, but has the effect of introducing aliasing artifacts - especially if the original data\n          are at a lower resolution than the warped images. Smoothing should reduce this artifact though.\n          Note also that the \"unmodulated\" data are generated slightly differently in this version of SPM. In\n          this version, the projected data are corrected using a kind of smoothing procedure. This is not done\n          exactly as it should be done (to save computational time), but it does a reasonable job. It also has\n          the effect of extrapolating the warped tissue class images beyond the range of the original data. This\n          extrapolation is not perfect, as it is only an estimate, but it may still be a good thing to do.\n\n- **Warping &amp; MRF**    \n  A number of warping options.\n  The main one that you could consider changing is the one for specifying whether deformation fields or inverse\n  deformation fields should be generated.\n\n    - **MRF Parameter**    \n      When tissue class images are written out, a few iterations of a simple Markov Random Field (MRF) cleanup\n      procedure are run. This parameter controls the strength of the MRF. Setting the value to zero will disable\n      the cleanup.\n\n    - **Clean Up**    \n      This uses a crude routine for extracting the brain from segmented images.\n      It begins by taking the white matter, and eroding it a couple of times to get rid of any odd voxels. The\n      algorithm continues on to do conditional dilations for several iterations, where the condition is based\n      upon gray or white matter being present.This identified region is then used to clean up the grey and white\n      matter partitions. Note that the fluid class will also be cleaned, such that aqueous and vitreous humour\n      in the eyeballs, as well as other assorted fluid regions (except CSF) will be removed.\n\n      If you find pieces of brain being chopped out in your data, then you may wish to disable or tone down the\n      cleanup procedure. Note that the procedure uses a number of assumptions about what each tissue class\n      refers to. If a different set of tissue priors are used, then this routine should be disabled.\n\n    - **Warping Regularisation**    \n      Registration involves simultaneously minimising two terms. One of these is a measure of similarity between\n      the images (mean-squared difference in the current situation), whereas the other is a measure of the\n      roughness of the deformations. This measure of roughness involves the sum of the following terms:\n        * Absolute displacements need to be penalised by a tiny amount. The first element encodes the amount of\n          penalty on these. Ideally, absolute displacements should not be penalised, but it is necessary for\n          technical reasons.\n        * The `membrane energy\" of the deformation is penalised (2nd element), usually by a relatively small\n          amount. This penalises the sum of squares of the derivatives of the velocity field (ie the sum of\n          squares of the elements of the Jacobian tensors).\n        * The `bending energy\" is penalised (3rd element). This penalises the sum of squares of the 2nd\n          derivatives of the velocity.\n        * Linear elasticity regularisation is also included (4th and 5th elements). The first parameter (mu) is\n          similar to that for linear elasticity, except it penalises the sum of squares of the Jacobian tensors\n          after they have been made symmetric (by averaging with the transpose). This term essentially penalises\n          length changes, without penalising rotations.\n        * The final term also relates to linear elasticity, and is the weight that denotes how much to penalise\n          changes to the divergence of the velocities (lambda). This divergence is a measure of the rate of\n          volumetric expansion or contraction.\n          The amount of regularisation determines the tradeoff between the terms. More regularisation gives\n          smoother deformations, where the smoothness measure is determined by the bending energy of the\n          deformations.\n\n    - **Affine Regularisation**    \n      The procedure is a local optimisation, so it needs reasonable initial starting estimates. Images should be\n      placed in approximate alignment using the Display function of SPM before beginning. A Mutual Information\n      affine registration with the tissue probability maps (D\"Agostino et al, 2004) is used to achieve\n      approximate alignment. Note that this step does not include any model for intensity non-uniformity. This\n      means that if the procedure is to be initialised with the affine registration, then the data should not be\n      too corrupted with this artifact.If there is a lot of intensity non-uniformity, then manually position\n      your image in order to achieve closer starting estimates, and turn off the affine registration.\n\n      Affine registration into a standard space can be made more robust by regularisation (penalising excessive\n      stretching or shrinking). The best solutions can be obtained by knowing the approximate amount of\n      stretching that is needed (e.g. ICBM templates are slightly bigger than typical brains, so greater zooms\n      are likely to be needed). For example, if registering to an image in ICBM/MNI space, then choose this\n      option. If registering to a template that is close in size, then select the appropriate option for this.\n\n    - **Smoothness**    \n      This is used to derive a fudge factor to account for correlations between neighbouring voxels.\n      Smoother data have more spatial correlations, rendering the assumptions of the model inaccurate.\n      For PET or SPECT, set this value to about 5 mm, or more if the images have smoother noise. For MRI, you\n      can usually use a value of 0 mm.\n\n    - **Sampling distance**    \n      This encodes the approximate distance between sampled points when estimating the model parameters.\n      Smaller values use more of the data, but the procedure is slower and needs more memory. Determining the \"\n      best\"\" setting involves a compromise between speed and accuracy.\n\n    - **Deformation Fields**    \n      Deformation fields can be saved to disk, and used by the Deformations Utility.\n      For spatially normalising images to MNI space, you will need the forward deformation, whereas for\n      spatially normalising (eg) GIFTI surface files, you\"ll need the inverse. It is also possible to transform\n      data in MNI space on to the individual subject, which also requires the inverse transform. Deformations\n      are saved as .nii files, which contain three volumes to encode the x, y and z coordinates.\n</code></pre> <ul> <li>Proc. hMRI -&gt; Dartel    This toolbox is based around the \u201cA Fast Diffeomorphic Registration Algorithm\u201d\u201d paper/ \\cite{ashburner07} /. The   idea is to register images by computing a \u201cflow field\u201d\u201c, which can then be \u201cexponentiated\u201d\u201d to generate both   forward and backward deformations. Currently, the software only works with images that have isotropic voxels,   identical dimensions and which are in approximate alignment with each other. One of the reasons for this is that   the approach assumes circulant boundary conditions, which makes modelling global rotations impossible. Another   reason why the images should be approximately aligned is because there are interactions among the transformations   that are minimised by beginning with images that are already almost in register. This problem could be alleviated   by a time varying flow field, but this is currently computationally impractical.   Because of these limitations, images should first be imported. This involves taking the \u201c*_seg_sn.mat\u201d\u201d files   produced by the segmentation code of SPM12, and writing out rigidly transformed versions of the tissue class   images, such that they are in as close alignment as possible with the tissue probability maps. Rigidly transformed   original images can also be generated, with the option to have skull-stripped versions.   The next step is the registration itself. This can involve matching single images together, or it can involve the   simultaneous registration of e.g. GM with GM, WM with WM and 1-(GM+WM) with 1-(GM+WM) (when needed, the 1-(GM+WM)   class is generated implicitly, so there is no need to include this class yourself). This procedure begins by   creating a mean of all the images, which is used as an initial template. Deformations from this template to each   of the individual images are computed, and the template is then re-generated by applying the inverses of the   deformations to the images and averaging. This procedure is repeated a number of times.Finally, warped versions of   the images (or other images that are in alignment with them) can be generated.</li> </ul> <p>This toolbox is not yet seamlessly integrated into the SPM package. Eventually, the plan is to use many of the   ideas here as the default strategy for spatial normalisation. The toolbox may change with future updates. There   will also be a number of other (as yet unspecified) extensions, which may include a variable velocity version (   related to LDDMM). Note that the Fast Diffeomorphism paper only describes a sum of squares objective function. The   multinomial objective function is an extension, based on a more appropriate model for aligning binary data to a   template.</p> <pre><code>- **Run Dartel (create Templates)**    \n  Run the Dartel nonlinear image registration procedure. This involves iteratively matching all the selected\n  images to a template generated from their own mean. A series of Template*.nii files are generated, which\n  become increasingly crisp as the registration proceeds.\n\n    - **Images**    \n      Select the images to be warped together. Multiple sets of images can be simultaneously registered. For\n      example, the first set may be a bunch of grey matter images, and the second set may be the white matter\n      images of the same subjects.\n\n        - **Images**    \n          Select a set of imported images of the same type to be registered by minimising a measure of\n          difference from the template.\n\n    - **Settings**    \n      Various settings for the optimisation. The default values should work reasonably well for aligning tissue\n      class images together.\n\n        - **Template basename**    \n          Enter the base for the template name. Templates generated at each outer iteration of the procedure\n          will be basename_1.nii, basename_2.nii etc. If empty, then no template will be saved. Similarly, the\n          estimated flow-fields will have the basename appended to them.\n\n        - **Regularisation Form**    \n          The registration is penalised by some \"energy\"\" term. Here, the form of this energy term is specified.\n          Three different forms of regularisation can currently be used.\n\n        - **Outer Iterations**    \n          The images are averaged, and each individual image is warped to match this average. This is repeated a\n          number of times.\n\n            - **Outer Iteration**    \n              Different parameters can be specified for each outer iteration. Each of them warps the images to\n              the template, and then regenerates the template from the average of the warped images. Multiple\n              outer iterations should be used for more accurate results, beginning with a more coarse\n              registration (more regularisation) then ending with the more detailed registration (less\n              regularisation).\n\n                - **Inner Iterations**    \n                  The number of Gauss-Newton iterations to be done within this outer iteration. After this, new\n                  average(s) are created, which the individual images are warped to match.\n\n                - **Reg params**    \n                  For linear elasticity, the parameters are mu, lambda and id. For membrane energy, the\n                  parameters are lambda, unused and id.id is a term for penalising absolute displacements, and\n                  should therefore be small. For bending energy, the parameters are lambda, id1 and id2, and the\n                  regularisation is by (-lambda*Laplacian + id1)^2 + id2.\n                  Use more regularisation for the early iterations so that the deformations are smooth, and then\n                  use less for the later ones so that the details can be better matched.\n\n                - **Time Steps**    \n                  The number of time points used for solving the partial differential equations. A single time\n                  point would be equivalent to a small deformation model. Smaller values allow faster\n                  computations, but are less accurate in terms of inverse consistency and may result in the\n                  one-to-one mapping breaking down. Earlier iteration could use fewer time points, but later\n                  ones should use about 64 (or fewer if the deformations are very smooth).\n\n                - **Smoothing Parameter**    \n                  A LogOdds parameterisation of the template is smoothed using a multi-grid scheme. The amount\n                  of smoothing is determined by this parameter.\n\n        - **Optimisation Settings**    \n          Settings for the optimisation. If you are unsure about them, then leave them at the default values.\n          Optimisation is by repeating a number of Levenberg-Marquardt iterations, in which the equations are\n          solved using a full multi-grid (FMG) scheme. FMG and Levenberg-Marquardt are both described in\n          Numerical Recipes (2nd edition).\n\n            - **LM Regularisation**    \n              Levenberg-Marquardt regularisation. Larger values increase the the stability of the optimisation,\n              but slow it down. A value of zero results in a Gauss-Newton strategy, but this is not recommended\n              as it may result in instabilities in the FMG.\n\n            - **Cycles**    \n              Number of cycles used by the full multi-grid matrix solver. More cycles result in higher accuracy,\n              but slow down the algorithm. See Numerical Recipes for more information on multi-grid methods.\n\n            - **Iterations**    \n              Number of relaxation iterations performed in each multi-grid cycle. More iterations are needed if\n              using \"bending energy\"\" regularisation, because the relaxation scheme only runs very slowly. See\n              the chapter on solving partial differential equations in Numerical Recipes for more information\n              about relaxation methods.\n\n- **Run Dartel (existing Templates)**    \n  Run the Dartel nonlinear image registration procedure to match individual images to pre-existing template\n  data. Start out with smooth templates, and select crisp templates for the later iterations.\n\n    - **Images**    \n      Select the images to be warped together. Multiple sets of images can be simultaneously registered. For\n      example, the first set may be a bunch of grey matter images, and the second set may be the white matter\n      images of the same subjects.\n\n        - **Images**    \n          Select a set of imported images of the same type to be registered by minimising a measure of\n          difference from the template.\n\n    - **Settings**    \n      Various settings for the optimisation. The default values should work reasonably well for aligning tissue\n      class images together.\n\n        - **Regularisation Form**    \n          The registration is penalised by some \"energy\"\" term. Here, the form of this energy term is specified.\n          Three different forms of regularisation can currently be used.\n\n        - **Outer Iterations**    \n          The images are warped to match a sequence of templates. Early iterations should ideally use smoother\n          templates and more regularisation than later iterations.\n\n            - **Outer Iteration**    \n              Different parameters and templates can be specified for each outer iteration.\n\n                - **Inner Iterations**    \n                  The number of Gauss-Newton iterations to be done within this outer iteration.\n\n                - **Reg params**    \n                  For linear elasticity, the parameters are mu, lambda and id. For membrane energy, the\n                  parameters are lambda, unused and id.id is a term for penalising absolute displacements, and\n                  should therefore be small. For bending energy, the parameters are lambda, id1 and id2, and the\n                  regularisation is by (-lambda*Laplacian + id1)^2 + id2.\n                  Use more regularisation for the early iterations so that the deformations are smooth, and then\n                  use less for the later ones so that the details can be better matched.\n\n                - **Time Steps**    \n                  The number of time points used for solving the partial differential equations. A single time\n                  point would be equivalent to a small deformation model. Smaller values allow faster\n                  computations, but are less accurate in terms of inverse consistency and may result in the\n                  one-to-one mapping breaking down. Earlier iteration could use fewer time points, but later\n                  ones should use about 64 (or fewer if the deformations are very smooth).\n\n                - **Template**    \n                  Select template. Smoother templates should be used for the early iterations. Note that the\n                  template should be a 4D file, with the 4th dimension equal to the number of sets of images.\n\n        - **Optimisation Settings**    \n          Settings for the optimisation. If you are unsure about them, then leave them at the default values.\n          Optimisation is by repeating a number of Levenberg-Marquardt iterations, in which the equations are\n          solved using a full multi-grid (FMG) scheme. FMG and Levenberg-Marquardt are both described in\n          Numerical Recipes (2nd edition).\n\n            - **LM Regularisation**    \n              Levenberg-Marquardt regularisation. Larger values increase the the stability of the optimisation,\n              but slow it down. A value of zero results in a Gauss-Newton strategy, but this is not recommended\n              as it may result in instabilities in the FMG.\n\n            - **Cycles**    \n              Number of cycles used by the full multi-grid matrix solver. More cycles result in higher accuracy,\n              but slow down the algorithm. See Numerical Recipes for more information on multi-grid methods.\n\n            - **Iterations**    \n              Number of relaxation iterations performed in each multi-grid cycle. More iterations are needed if\n              using \"bending energy\"\" regularisation, because the relaxation scheme only runs very slowly. See\n              the chapter on solving partial differential equations in Numerical Recipes for more information\n              about relaxation methods.\n\n- **Normalise to MNI Space**    \n  Normally, Dartel generates warped images that align with the average-shaped template. This routine includes an\n  initial affine regisration of the template (the final one generated by Dartel), with the TPM data released\n  with SPM.\n  \"Smoothed\"\" (blurred) spatially normalised images are generated in such a way that the original signal is\n  preserved. Normalised images are generated by a \"pushing\"\" rather than a \"pulling\"\" (the usual) procedure.\n  Note that a procedure related to trilinear interpolation is used, and no masking is done. It is therefore\n  recommended that the images are realigned and resliced before they are spatially normalised, in order to\n  benefit from motion correction using higher order interpolation. Alternatively, contrast images generated from\n  unsmoothed native-space fMRI/PET data can be spatially normalised for a 2nd level analysis.\n  Two \"preserve\"\" options are provided. One of them should do the equavalent of generating smoothed \"modulated\"\"\n  spatially normalised images. The other does the equivalent of smoothing the modulated normalised fMRI/PET, and\n  dividing by the smoothed Jacobian determinants.\n\n    - **Dartel Template**    \n      Select the final Template file generated by Dartel. This will be affine registered with a TPM file, such\n      that the resulting spatially normalised images are closer aligned to MNI space. Leave empty if you do not\n      wish to incorporate a transform to MNI space (ie just click \"done\" on the file selector, without selecting\n      any images).\n\n    - **Data**\n\n        - **Segemented tissue class**    \n          Select the tissue class (TC) imagesof interest from all subjects. This should typically be the c1* and\n          c2* images for GM and WM.\n\n            - **c* images**    \n              Select the tissue classes images (c*)\n\n        - **Parameter maps**    \n          Select whole brain parameter maps (e.g. MT, R2\\*, FA etc).\n\n            - **Volumes**    \n              Select whole brain parameter maps (e.g. MT, R2\\*, FA etc).\n\n        - **Flow fields**    \n          Flow fields.\n\n    - **Voxel sizes**    \n      Specify the voxel sizes of the deformation field to be produced. Non-finite values will default to the\n      voxel sizes of the template imagethat was originally used to estimate the deformation.\n\n    - **Bounding box**    \n      Specify the bounding box of the deformation field to be produced. Non-finite values will default to the\n      bounding box of the template imagethat was originally used to estimate the deformation.\n</code></pre> <ul> <li> <p>Proc. hMRI -&gt; Smoothing    Applying tissue specific smoothing, aka. weighted averaging,   in order to limit partial volume effect.</p> <ul> <li> <p>Warped parameter maps    Select whole brain parameter maps (e.g. MT, R2*, FA etc) warped into MNI space.</p> <ul> <li>Volumes    Select whole brain parameter maps (e.g. MT, R2*, FA etc) warped into MNI space.</li> </ul> </li> <li> <p>Modulated warped tissue class    Select the modulated warped tissue classes (TC) of interest from all subjects. This ould typically be the   mwc1 and mwc2 images for GM and WM.</p> <ul> <li>mwTC images    Select the modulated warped tissue classes (mwc*)</li> </ul> </li> <li> <p>Tissue probability maps    Select the TPM used for the segmentation.</p> </li> <li> <p>Gaussian FWHM    Specify the full-width at half maximum (FWHM) of the Gaussian blurring kernel in mm. Three values should be   entered denoting the FWHM in the x, y and z directions.</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"docs/hmriDemoDataset/","title":"hMRI Demo Dataset","text":""},{"location":"docs/hmriDemoDataset/#hmri-toolbox-demo-dataset","title":"hMRI Toolbox Demo Dataset","text":"<p>The hMRI demo dataset is used and referred to across the whole toolbox, for tutorial and illustration purposes. A description of the data, acquisition parameters and experiment is provided below and in the Data in Brief article: Callaghan2019.</p>"},{"location":"docs/hmriDemoDataset/#download","title":"Download","text":"<p>Note</p> <p>The dataset and protocol examples (detailed list of sequences and acquisition parameters) are currently available from the hMRI Toolbox home page, section \u201chMRI Example Data and MRI Protocols\u201d.</p> <ul> <li>Demo dataset (ZIP archive).</li> <li>Corresponding protocol <code>hmri_sample_dataset_protocol_800um_64ch.pdf</code> (PDF printout)</li> <li>Other MPM protocol examples, including Siemens and Philips scanners.</li> </ul>"},{"location":"docs/hmriDemoDataset/#description-of-the-experiment","title":"Description of the Experiment","text":"<p>An example multiparameter mapping (MPM) dataset was acquired on a whole body 3T Prisma system (Siemens Healthcare, Erlangen, Germany) to illustrate the hMRI Toolbox features and provide the users with a full MPM dataset used in the tutorial and examples (see for example the step-by-step tutorial for map creation and the toolbox customization examples). The study was approved by the local ethics committee and informed written consent was obtained from the participant prior to scanning.</p> <p>Rapid calibration data were acquired at the outset of each session to map and consequently correct for inhomogeneities in the B1 transmit field (Lutti2010, Lutti2012). Eleven spin-echo and stimulated-echo pairs were acquired with the nominal flip angles varying from 115\u00b0 to 65\u00b0 in 5\u00b0 decrements.</p> <p>These were followed by acquisition of 3D multi-echo RF-spoiled gradient echo acquisitions with predominantly PD, T1 or MT weighting similar to the MPM protocol described in Weiskopf2013. The flip angle was 6\u00b0 for the PDw and MTw images and 21\u00b0 for the T1w images. MT-weighting was achieved through the application of a Gaussian RF pulse 2 kHz off-resonance with 4 ms duration and a nominal flip angle of 220\u00b0. The data were acquired with whole-brain coverage at an isotropic resolution of 800 \u00b5m using a FoV of 256 mm head-foot, 224 mm anterior-posterior (AP) and 179 mm right-left (RL). Gradient echoes were acquired with alternating readout gradient polarity at eight equidistant echo times ranging from 2.30 to 18.40 ms in steps of 2.30 ms using a readout bandwidth of 488Hz/pixel. Only six echoes were acquired for the MTw acquisition in order to maintain a TR of 25 ms for all RF-spoiled gradient echo volumes. To accelerate the data acquisition, partially parallel imaging using the GRAPPA algorithm was employed in each phase-encoded direction (AP and RL) with forty reference lines and a speed-up factor of two. The acquisition time for each RF-spoiled gradient echo volume was 7\u201808\u2019\u2018. The data were acquired using the body coil for signal transmission and a 64 channel head and neck array for signal reception. Each dataset was acquired with a 30\u00b0 rotation of the sagittal plane so that any eye-related motion artifact propagated to the neck/inferior cerebellum rather than the cortex.</p> <p>Prior to the acquisition of each RF-spoiled gradient echo volume, two additional 3D rapid, unaccelerated, low resolution (8 mm isotropic, same FoV) volumes were acquired one with the 64 channel head and neck array coil and the other with the body coil. A single echo, with a TE of 2.20 ms, was acquired in each case using a 6\u00b0 flip angle and a TR of 6.00 ms. The acquisition time for each of these calibration volumes was 5.90 s.</p> <p>These data were used to correct for the position-specific sensitivity modulation of the array coil by approximately removing the receive field sensitivity bias. To test the performance of this correction, the participant performed a yaw rotation (i.e. about the z-axis) within the confines of the 64 channel coil prior to the acquisition of the MT-weighted dataset before returning to the original position centered within the head coil for the PD-weighted and T1-weighted acquisitions.</p>"},{"location":"docs/hmriDemoDataset/#acquisition-parameters","title":"Acquisition Parameters","text":"<p>The ZIP archive contains the following data:</p> <ul> <li><code>mfc_seste_b1map_v1e_0004</code>: B1 mapping data (3D EPI SE/SESTE protocol)</li> <li><code>gre_field_mapping_1acq_rl_0005</code>: B0 mapping data (2 magnitude images with different TE)</li> <li><code>gre_field_mapping_1acq_rl_0006</code>: B0 mapping data (presubtracted phase image)</li> <li><code>mfc_smaps_v1a_Array_0007</code>: RF sensitivity mapping data (64 channel head coil)</li> <li><code>mfc_smaps_v1a_QBC_0008</code>: RF sensitivity mapping data (body coil)</li> <li><code>pdw_mfc_3dflash_v1i_R4_0009</code>: 8 echoes with PD-weighting</li> </ul> <p>Large yaw rotation of the volunteer\u2019s head (i.e. about the z-axis) within the confines of the 64 channel coil.</p> <ul> <li><code>mfc_smaps_v1a_Array_0010</code>: RF sensitivity mapping data (64 channel head coil)</li> <li><code>mfc_smaps_v1a_QBC_0011</code>: RF sensitivity mapping data (body coil)</li> <li><code>mtw_mfc_3dflash_v1i_R4_0012</code>: 6 echoes with MT-weighting</li> </ul> <p>Back to initial (straight) position.</p> <ul> <li><code>mfc_smaps_v1a_Array_0013</code>: RF sensitivity mapping data (64 channel head coil)</li> <li><code>mfc_smaps_v1a_QBC_0014</code>: RF sensitivity mapping data (body coil)</li> <li><code>t1w_mfc_3dflash_v1i_R4_0015</code>: 8 echoes with T1-weighting</li> </ul> <p>The full protocol is available and can be downloaded as a PDF printout.</p>"},{"location":"docs/mapCreation/","title":"Quantitative Map Creation","text":""},{"location":"docs/mapCreation/#quantitative-map-creation","title":"Quantitative Map Creation","text":"<p>The <code>Create hMRI maps</code> module computes quantitative as well as semi-quantitative estimates of R2*, R1, PD and MT from unprocessed multi-echo T1-, PD- and MT-weighted RF-spoiled gradient echo acquisitions (Helms2008b; Helms2008a; Weiskopf2013; Weiskopf2014). The Map creation module corrects the qMRI estimates for spatial receive and transmit field inhomogeneities based on additional reference data, if available (Lutti2010; Lutti2012; Papp2016) or using image processing methods (Weiskopf2013; Weiskopf2011).</p>"},{"location":"docs/mapCreation/#b1-transmit-bias-correction","title":"B1+ (Transmit) Bias Correction","text":"<p>The map creation module includes the determination of B1 transmit bias field maps (fT expressed in p.u. of the nominal flip angle) for transmit bias correction of the quantitative data. Several methods are implemented. Depending on the choice of the specific method the GUI requires the user to provide adequate input files, which are described below. For details of the implemented methods we refer the reader to the respective original publications.</p>"},{"location":"docs/mapCreation/#1-3d_epi","title":"1. 3D_EPI","text":"<p>Info</p> <p>EPI spin-echo (SE)/stimulated-echo (STE) method (Lutti2010, Lutti2012).</p> <p>All consecutive pairs of SE/STE images corresponding to the different flip angle nominal values of the SE/STE RF pulses must be loaded as B1 input. B0 field mapping images must also be provided for the correction of distortions in the EPI images. Both magnitude images and the pre-subtracted phase image must be selected, in that order, as B0 input.</p>"},{"location":"docs/mapCreation/#2-3d_afi","title":"2. 3D_AFI","text":"<p>Info</p> <p>Actual Flip Angle Imaging (AFI) method (Yarnykh2007).</p> <p>A pair of magnitude images acquired with two different repetition times (TR) must be loaded as B1 input. The hMRI Toolbox then calculates the B1 transmit bias field map as described in Yarnykh2007.</p>"},{"location":"docs/mapCreation/#3-tfl_b1_map","title":"3. tfl_b1_map","text":"<p>Info</p> <p>TFL B1 mapping (Chung2010).</p> <p>For this method, the batch interface requires a pair of images (one anatomical image and one flip angle map, in that order) from a service sequence by Siemens (version available from VE11 on) based on a turbo flash (TFL) sequence with and without a pre-saturation pulse (Chung2010). The flip angle map used as input contains the measured flip angle multiplied by 10. After rescaling (p.u.) and smoothing, the output fT map is ready to be used for B1 transmit bias correction.</p>"},{"location":"docs/mapCreation/#4-rf_map","title":"4. rf_map","text":"<p>The batch interface requires a pair of images output from a service sequence by Siemens (Erlangen, Germany; one anatomical image and one pre-processed B1 map, in that order) based on the acquisition of a spin-echo/stimulated echo as used for the 3D_EPI method above (Lutti2010). Rescaling to an fT map (p.u.) suitable for B1 transmit bias correction from the signal intensity of the preprocessed map from the scanner, S, using the nominal flip angle alpha is performed in the toolbox according to the following formula: fT = ((S - 2048) \u00d7 180 \u00d7 100)/(2048 \u00d7 alpha) (source: Siemens Customer Services Knowledge Base, ID: 15480, \u201cEvaluation of RF field (B1) Inhomogeneity with service sequence RF_map\u201d).</p>"},{"location":"docs/mapCreation/#5-dam_b1_map","title":"5. DAM_b1_map","text":"<p>Info</p> <p>Double Angle Mapping B1 map.</p> <p>The batch interface requires a pair of images, the first with flip angle 2*alpha and the second with flip angle alpha (e.g. 120\u00b0/60\u00b0). This method can also be used for Saturated Double Angle Mapping (SDAM) data.</p>"},{"location":"docs/mapCreation/#6-pre-processed-b1","title":"6. pre-processed B1","text":"<p>Any B1 transmit bias field map precalculated using one of the above methods or another method can be used as pre-processed B1 input. The user must select one anatomical reference (for registration) and one B1 map, in that order. The anatomical reference is typically a magnitude image from the B1 mapping dataset, and must be in the same space as the B1 transmit bias field map. If the B1 map is not expressed in percent units (p.u.) of the nominal flip angle, a scaling factor can be introduced to bring it to the right units. NOTE: BIDS-compatible B1 maps have a \u201cB1\u201d value of 1 where the nominal flip angle is achieved. For such B1 map, a scaling factor of 100 will be needed.</p>"},{"location":"docs/mapCreation/#7-unicort","title":"7. UNICORT","text":"<p>Info</p> <p>Data driven estimation of the B1 transmit bias field map using the UNICORT approach (Weiskopf2011).</p> <p>If none of the above-mentioned methods applies because no appropriate B1 transmit bias field mapping data were acquired, the UNICORT option is recommended to remove the transmit field bias in the R1 map and estimate the B1 transmit bias field map from the qMRI data. UNICORT parameters may need tuning to the specific RF transmit coil used as it was developed and optimised for Siemens Trio.   Most importantly, the regularisation parameters must be adapted. The settings will depend on how much non-uniformity there is in the data. If there is no non-uniformity, then the regularisation should be high. If there is lots, then there should be less regularisation.</p>"},{"location":"docs/mapCreation/#8-no_b1_correction","title":"8. no_B1_correction","text":"<p>With this option, no correction for transmit inhomogeneities is applied, i.e., fT = 1.</p>"},{"location":"docs/mapCreation/#conclusion","title":"Conclusion","text":"<p>For each B1 mapping protocol (1-6), one <code>*_B1map</code> (in p.u.) and one <code>*_B1ref</code> (for anatomical reference) file is created and saved in the <code>Results/Supplementary</code> directory. The output images are associated with JSON metadata including the type of B1 map processed and the processing parameters. For UNICORT, only the <code>*_B1map</code> in p.u. is created (in the same space as the qMRI maps) with no anatomical reference. Default acquisition and processing parameters for the UNICORT, 3D_EPI and 3D_AFI methods can be customised at this point by providing the module with a customised configuration file (see section Default parameters and customization of the toolbox for examples and guidelines).</p> <p>Except for UNICORT, where the B1 transmit bias field directly derived from the qMRI data, and the <code>no_B1_correction</code> option, where no anatomical reference is needed, the hMRI Toolbox co-registers the anatomical image with the multi-echo RF-spoiled gradient echo data before applying the B1 transmit bias correction.</p>"},{"location":"docs/mapCreation/#rf-sensitivity-bias-correction","title":"RF Sensitivity Bias Correction","text":"<p>Four options are available to address RF sensitivity bias within the <code>Create hMRI maps</code> module: (1) no correction, (2) Unified Segmentation (US), (3) use one measured RF sensitivity map, (4) use three measured RF sensitivity maps, one per contrast. While options (2) and (3) assume that the sensitivity profile is consistent between contrasts (i.e. small inter-contrast subject movement), option (4) accounts for inter-contrast variation in RF sensitivity profile due to larger subject motion (Papp2016,Balbastre2022). Measured RF sensitivity maps methods (options 3,4) are preferred over data-driven US methods (option 2) for bias correction. The option of using no RF sensitivity bias correction (option 1) is not recommended.</p>"},{"location":"docs/mapCreation/#receive-field-sensitivity-measurements","title":"Receive Field Sensitivity Measurements","text":""},{"location":"docs/mapCreation/#body-and-head-coil-measurements","title":"Body and Head Coil Measurements","text":"<p>Info</p> <p>Please see Papp2016.</p> <p>The underlying assumption of this method is that the receive field sensitivity of the body coil is much flatter than that of an array head coil. Thus, if the anatomy is imaged with the head coil and the body coil sequentially, using the same acquisition parameters and assuming no motion, then the ratio of these two scans is the net head coil receive sensitivity field fR divided by a sensitivity field close to a constant.</p> <p>If receive field sensitivity measurements are available for each imaging contrast (one receive sensitivity field acquired either before or after each of the PDw, T1w and MTw contrasts), inter-scan variation of the sensitivity modulation can be accounted for and used to optimally correct for the combined inter-scan motion and sensitivity modulation effects in the quantitative maps. Therefore, the implemented RF sensitivity correction method (<code>Per contrast</code> option) combines the correction for motion-related relative receive sensitivity variations with rigid body realignment.</p> <p>The low resolution measurements from the head and body coils (in this order) for each T1w, PDw and MTw acquisition are expected as inputs to the RF sensitivity bias correction. A receive field sensitivity map is calculated for each contrast, and applied to the corresponding contrast to correct for any coil sensitivity driven signal intensity modulation.</p> <p>If RF sensitivity measurements are missing for some of the contrasts, or if only one single measurement is available, the same RF sensitivity bias correction can still be applied to all contrasts by choosing the corresponding <code>Single</code> option in the GUI. Only one pair of head coil and body coil images is then required. Receiver field inhomogeneities will be corrected for although not accounting for inter-scan motion.</p> <p>Note that the measured RF sensitivity maps will still suffer from residual variations associated with the field-inhomogeneities of the body coil. Because of this, this method is followed by an application of the Unified Segmentation approach to minimise the residual modulation due to the body coil RF sensitivity field.</p>"},{"location":"docs/mapCreation/#only-head-coil-measurements","title":"Only Head Coil Measurements","text":"<p>Info</p> <p>Please see Balbastre2022.</p> <p>In cases where body coil images are not available or cannot be measured (e.g. at 7T where many scanners do not have a body coil), it is still possible to correct for the inter-scan variation of the sensitivity modulation. This is achieved by measuring a low resolution image with the same acquisition parameters before each contrast. After choosing the <code>Per contrast</code> option, each \u201chead coil\u201d image should be the per-contrast low resolution image, and the \u201cbody coil\u201d images should all be the low resolution image measured before the PDw acquisition.</p> <p>As in the previous case, the measured RF sensitivity maps will suffer from residual variations associated with the field-inhomogeneities of the head coil. Because of this, this method is followed by an application of the Unified Segmentation approach to minimise the residual modulation due to the body coil RF sensitivity field.</p>"},{"location":"docs/mapCreation/#data-driven-receive-field-estimation","title":"Data Driven Receive Field Estimation.","text":"<p>If no receive field sensitivity map has been acquired, the <code>Unified Segmentation</code> option can be selected in the GUI. The receive field bias is then estimated from the calculated A map using the Unified Segmentation approach (Ashburner2005). Accurate bias field estimation requires the use of a brain mask combining the white and grey matter probability maps. The latter are derived by segmentation of the calculated MT map (because of its higher contrast in the basal ganglia (Helms2009) or alternatively (if no MTw images are available), by segmentation of the calculated R1 map. The method may require tuning for the specific head RF receive coil and its sensitivity profile.</p>"},{"location":"docs/mapCreation/#imperfect-spoiling-correction","title":"Imperfect Spoiling Correction","text":"<p>The proposed MPM protocol uses RF and gradient spoiling to destroy unwanted transverse magnetisation. Imperfect spoiling can leave residual bias in the apparent R1 map if no further correction is used (Preibisch and Deichmann 2009). For specific MPM protocols using the customised sequences, the hMRI Toolbox provides spoiling correction coefficients to account for deviation from the Ernst equation. The coefficients are sequence-specific and can be determined by simulation (Preibisch and Deichmann 2009). Further refinements of this correction include diffusion effects on signal spoiling  (Yarnykh2007,  Lutti2012,  Callaghan2015b). By default, this correction is disabled but can be enabled through the toolbox customisation.</p> <p>A module that efficiently calculates the protocol-specific correction parameters required to account for imperfect spoiling may be found within the toolbox. See Corbin2021 for guidance on calculation including the choice of T2 time and the moment of the spoiler gradients and the diffusion-spoiling effects of the readout.</p>"},{"location":"docs/mapCreation/#mpm-model-to-estimate-r2-pd-r1-mt-maps","title":"MPM Model to Estimate R2*, PD, R1 &amp; MT Maps","text":"<p>The signal from the multi-echo PDw, T1w and MTw echoes is modelled by the Ernst equation (Ernst1966, Helms2008a, Helms2008b) with an exponential decay with echo time (TE).</p> <p>The effective transverse relaxation rate R2* is derived from the exponential TE dependence of the signal. The unified description of the multi-echo data from two or more contrasts into a single signal model, denoted as ESTATICS (Weiskopf2014), provides a more robust estimation of R2* with a higher signal-to-noise ratio ( SNR). The toolbox provides several estimation methods including log-linear ordinary least squares (OLS; the original ESTATICS method), log-linear weighted least squares (WLS; a little slower than ordinary least squares but accounts for the heteroskedasticity induced by the logarithm) and nonlinear least squares (NLLS; very slow but homoskedastic). For backwards compatibility OLS is used by default, but this can be changed in the toolbox defaults file.</p> <p>Using approximations of the signal equations for small repetition time (TR), the longitudinal relaxation rate (R1) and the A map (proportional to the proton density PD) can be efficiently estimated from the PDw and T1w data (Helms2008a,Edwards2021). Using the additional assumption of a small excitation flip angle for the MTw data, the magnetisation transfer (MT) saturation can be estimated from the R1 and A maps and the MTw data (Helms2008b). By default, the small angle approximation is also assumed when computing R1 and A maps, but this can be changed in the toolbox defaults file.</p> <p>The toolbox provides flexible correction methods for transmit (fT) and receive (fR) bias fields based on specific B1 transmit and receive fields measurements or image processing methods. While fT influences the local apparent flip angle and hence all three (R1, A, MT) maps, the RF sensitivity bias field fR only influences the A map. Rescaling of the A map to a PD map (with mean white matter PD of 69%) is performed when sufficient data are available to account for R2* decay (Balteau2018) and fT and fR biases.</p> <p>The toolbox can also handle the situation where only a subset of data is available. For example, R2*, R1 and PD can still be estimated when no MTw data are available, and R2* alone can be estimated when no MTw nor T1w echoes are available (i.e. only multi-echo PDw data are available).</p>"},{"location":"docs/mapCreation/#output-files","title":"Output Files","text":"<p>By default, the estimated quantitative maps are output into a <code>Results</code> subdirectory within the folder of the first PD-weighted echo. Alternatively, a user-defined folder for the output of the toolbox can be selected where the <code>Results</code> directory will be created. The main estimated qMRI maps are saved in the specified output directory while supplementary files are output in the <code>Results/Supplementary</code> subfolder. The basename for all qMRI maps is derived from the first echo of the PD-weighted image series, see below for a brief description. If the data are reprocessed, a new sub-folder is created.</p>"},{"location":"docs/mapCreation/#cleanup-options-and-temporary-directories","title":"Cleanup Options and Temporary Directories","text":"<p>During data processing, many files are created that are of no interest for the end-user. Only maps, images and log files of interest for further statistical analysis and quality control are stored in the <code>Results</code> directory and subdirectory. The temporary files can be of great value for piloting and debugging purposes though. They\u2019re convenient if one desires have a closer look at the intermediate processing steps to e.g. spot the origin of an artefact.</p> <p>The temporary folders are created at the same location as the <code>Results</code> directory. They include:</p> <ul> <li>RFsensCalc: to process (measured) RF sensitivity data and   apply RF sensitivity bias correction to the original images.</li> <li>B1mapCalc: to process B1 mapping data for B1 transmit bias correction.</li> <li>MPMCalc: to generate the quantitative maps R1, R2*, PD and MT (or part of them, depending on the input).</li> </ul> <p>The default parameter <code>hmri_def.cleanup</code> can be customized. By default, it is set to <code>false</code>. All temporary directories will be deleted when the Create hMRI maps module has completed (recommended to save disk space). </p> <p>Warning</p> <p>Reminder for toolbox customization: never modify the defaults files located at the root of the <code>config</code> directory. Instead, use one of the template defaults files from <code>config/local</code> and save it under a meaningful name.</p>"},{"location":"docs/mapCreation/#example-outputs-from-the-create-hmri-maps-module","title":"Example Outputs from the Create hMRI maps Module","text":"<p>Output files from the Create hMRI maps module using the SE/STE B1 mapping and per-contrast RF sensitivity bias correction.</p>"},{"location":"docs/mapCreation/#results-directory-description","title":"<code>Results directory</code> &gt; Description","text":"<ul> <li><code>&lt;firstPDfileName&gt;_MT.[nii|json]</code> &gt; Estimated magnetisation transfer map in p.u.</li> <li><code>&lt;firstPDfileName&gt;_PD.[nii|json]</code> &gt; Estimated proton density PD map in p.u.</li> <li><code>&lt;firstPDfileName&gt;_R1.[nii|json]</code> &gt; Estimated longitudinal relaxation rate R1 map in s^-1</li> <li><code>&lt;firstPDfileName&gt;_R2s_&lt;R2sMethod&gt;.[nii|json]</code> &gt; Estimated transversal relaxation rate R2* map in s^-1 (ESTATICS),   where <code>&lt;R2sMethod&gt;</code> is the R2* fitting method (e.g. <code>OLS</code> or <code>WLS1</code>;   see Create hMRI maps parameters).</li> </ul>"},{"location":"docs/mapCreation/#resultssupplementary-directory-description","title":"<code>Results/Supplementary directory</code> &gt; Description","text":"<ul> <li><code>hMRI_map_creation_rfsens_params.json</code> &gt; RF sensitivity bias correction parameters (measured sensitivity maps)</li> <li><code>hMRI_map_creation_b1map_params.json</code> &gt; B1 transmit map estimation: acquisition and processing parameters</li> <li><code>hMRI_map_creation_job_create_maps.json</code> &gt; Create hMRI maps: acquisition and processing parameters</li> <li><code>hMRI_map_creation_mpm_params.json</code> &gt; Acquisition and processing parameters used for the current job</li> <li><code>hMRI_map_creation_quality_assessment.json</code> &gt; Quality assessment results</li> <li><code>&lt;firstSESTEfileName&gt;_B1map.[nii|json]</code> &gt; Estimated B1 bias field fT map (p.u.)</li> <li><code>&lt;firstSESTEfileName&gt;_B1ref.[nii|json]</code> &gt; Anatomical reference for B1 bias field correction</li> <li><code>&lt;firstPDfileName&gt;_MTw_&lt;R2sMethod&gt;fit_TEzero.[nii|json]</code> &gt; MTw echoes extrapolated to TE=0, where <code>&lt;R2sMethod&gt;</code> is the   R2* fitting method</li> <li><code>&lt;firstPDfileName&gt;_PDw_&lt;R2sMethod&gt;fit_TEzero.[nii|json]</code> &gt; PDw echoes extrapolated to TE=0, where <code>&lt;R2sMethod&gt;</code> is the   R2* fitting method</li> <li><code>&lt;firstPDfileName&gt;_R2s.[nii|json]</code> &gt; Estimated R2* map from simple exponential fit (PDw echoes)</li> <li><code>&lt;firstPDfileName&gt;_T1w_&lt;R2sMethod&gt;fit_TEzero.[nii|json]</code> &gt; T1w echoes extrapolated to TE=0, where <code>&lt;R2sMethod&gt;</code> is the   R2* fitting method</li> </ul>"},{"location":"docs/mapCreation/#batch-options","title":"Batch Options","text":"<p>Help on batch options is automatically generated from the toolbox config files. The information is collected in the Help section.</p>"},{"location":"docs/mapCreation/#setting-up-local-defaults","title":"Setting up local defaults","text":"<p>Since acquisition parameters as well as processing parameters can be site- and scanner-dependent, the defaults must be customizable. This topic is extensively described in section \u201cDefault parameters and customization of the toolbox\u201d.</p>"},{"location":"docs/mapCreation/#example","title":"Example","text":"<p>This example will take you step-by-step through the processing (map creation part) of the hMRI demo dataset available here. Unless specified, default settings should be left unchanged. See the Debug tips &amp; tricks section for tips about displaying the created maps for visual inspection.</p>"},{"location":"docs/mapCreation/#set-up-and-run-the-map-creation-module","title":"Set up and Run the Map Creation Module","text":"<ol> <li>Download and unzip the hMRI demo dataset within a <code>data</code> directory on your hard drive.</li> <li>Create a <code>derivative</code> directory to store processing results.</li> <li>Start SPM (<code>spm fmri</code>) and open the Batch GUI (<code>Batch</code> button in the SPM Menu window).</li> <li>Go to <code>SPM</code> &gt; <code>Tools</code> &gt; <code>hMRI Tools</code> &gt; <code>Create hMRI maps</code> (Batch GUI).</li> <li>In <code>Output choice</code>, select <code>Output directory</code> and specify the newly created <code>derivative</code> directory as output    directory.</li> <li>In <code>B1 bias correction</code> &gt; <code>B1 input</code>, select all the volumes found in <code>mfc_seste_b1map_v1e_0004</code> (keep alphabetical    order).</li> <li>In <code>B1 bias correction</code> &gt; <code>B0 input</code>, select all the volumes found in <code>gre_field_mapping_1acq_rl_0005</code>    and <code>gre_field_mapping_1acq_rl_0006</code> (in that order).</li> <li>In <code>Multiparameter input images</code> &gt; <code>MT images</code>, select all the volumes found in <code>mtw_mfc_3dflash_v1i_R4_0012</code> (keep    alphabetical order).</li> <li>In <code>Multiparameter input images</code> &gt; <code>PD images</code>, select all the volumes found in <code>pdw_mfc_3dflash_v1i_R4_0009</code> (keep    alphabetical order).</li> <li>In <code>Multiparameter input images</code> &gt; <code>T1 images</code>, select all the volumes found in <code>t1w_mfc_3dflash_v1i_R4_0015</code> (keep     alphabetical order).</li> <li>Save and run the batch.</li> </ol>"},{"location":"docs/mapCreation/#note-on-pop-up-messages-and-warnings","title":"Note on Pop-up Messages and Warnings","text":"<p>By default, any information or warning considered potentially critical for the processing of your data will be displayed in a pop-up window, blocking the execution of the code. This is obviously rather annoying if you intend to process a bunch of data over night ;)! It can be disabled (see the Batch option \u201cPop-up warnings\u201d) for that purpose. For piloting data processing though (e.g. processing a single-subject dataset to check everything is generated as expected), it is recommended to keep the pop-up option enabled, so you can read through and acknowledge every message and make sure everything is set up properly before running the processing on a whole group.</p> <p>Warning messages are only meant to make you aware of some of the processing steps and parameters used to generate the maps. And to give you a chance to decide whether these processing steps and parameters are definitely the right ones for the data you have at hand. Most warning and information messages are listed in the Debug tips &amp; tricks section, with a description of potential implications and actions to be taken.</p>"},{"location":"docs/mapCreation/#results-description","title":"Results Description","text":"<p>The four maps generated (MT, PT, R2s and R1) will be found in <code>derivative/Results</code>. These maps are the relevant ones for statistical analysis (see section on Map Processing). In <code>derivative/Results/Supplementary</code> are stored the processing parameters and various additional images. Given the strong inter-scan motion factor in the dataset (affecting the MTw data, see details here), the MT map is strongly affected by artefacts. The R2* map is not affected by such inter-scan motion, although including data input from all three contrasts (PDw, T1w and MTw). The PD and R1 maps do not rely on the MTw data and do not suffer from the same inhomogeneity. In addition, the PD map is corrected for RF sensitivity bias by applying the US algorithm.</p> <p></p>"},{"location":"docs/mapCreation/#alternative-processing-more-robust-rf-sensitivity-bias-correction","title":"Alternative Processing - More Robust RF Sensitivity Bias Correction","text":"<p>By default, (as used in the above step-by-step description), when no RF sensitivity data are available, Unified Segmentation is used to estimate the Bias Field related to the receiver field profile. If RF sensitivity data are available (as is the case in the hMRI demo dataset), a more robust and especially more motion-insensitive correction can be applied. The following steps are to be taken in addition to the ones described above:</p> <ul> <li>In <code>RF sensitivity bias correction</code>, select <code>Per contrast</code>. This indicates that one RF sensitivity dataset has been   acquired per contrast, i.e. for each of the MTw, PDw and T1w series. One separate RF sensitivity dataset will be   required for each contrast. With such data, the corresponding RF sensitivity data will better account for inter-scan   movements of the subject, making the RF sensitivity bias correction more robust to such movements.</li> <li>In <code>RF sensitivity bias correction</code> &gt; <code>Per contrast</code> &gt; <code>RF sensitivity maps for MTw images</code>, select the volumes found   in <code>mfc_smaps_v1a_Array_0010</code> and <code>mfc_smaps_v1a_QBC_0011</code> (in that order).</li> <li>In <code>RF sensitivity bias correction</code> &gt; <code>Per contrast</code> &gt; <code>RF sensitivity maps for PDw images</code>, select the volumes found   in <code>mfc_smaps_v1a_Array_0007</code> and <code>mfc_smaps_v1a_QBC_0008</code> (in that order).</li> <li>In <code>RF sensitivity bias correction</code> &gt; <code>Per contrast</code> &gt; <code>RF sensitivity maps for T1w images</code>, select the volumes found   in <code>mfc_smaps_v1a_Array_0013</code> and <code>mfc_smaps_v1a_QBC_0014</code> (in that order).</li> <li>Save and run the batch.</li> </ul>"},{"location":"docs/mapCreation/#better-results-description","title":"Better Results Description","text":"<p>Thanks to the per-contrast RF sensitivity maps used for RF sensitivity bias correction, motion artefacts observed previously are strongly reduced (see MT map in particular). However, the RF sensitivity maps are not fully bias-free themselves! The RF sensitivity maps are calculated assuming that the body coil sensitivity profile in homogeneous, which is usually not the case on modern 2-channel body coils. Therefore, the calculated RF sensitivity maps are modulated by the body coil RF sensitivity profile, which will be visible on the calculated PD maps in particular. Overall, the improvement in terms of scan-rescan reproducibility and inter-scan motion insensitivity observed with the <code>Per contrast</code> option is still worth the hassle of acquiring and using such data.</p> <p></p>"},{"location":"docs/metadataLibrary/","title":"JSON Metadata and DICOM to NIfTI Conversion","text":""},{"location":"docs/metadataLibrary/#json-metadata-and-dicom-to-nifti-conversion","title":"JSON Metadata and DICOM to NIfTI Conversion","text":""},{"location":"docs/metadataLibrary/#introduction","title":"Introduction","text":"<p>To support the flexibility of the hMRI Toolbox processing pipeline and the traceability of the data at every step, number of parameters from acquisition to statistical results must be retrieved and stored.</p> <p>Therefore, DICOM import and JSON metadata handling functionalities have been implemented with the following objectives:</p> <ol> <li>Retrieving the full DICOM header as a readable and searchable Matlab structure (metadata)</li> <li>During DICOM to NIfTI conversion, storing the metadata structure as separate JSON file    (alongside the NIfTI image file) and/or as extended header into the NIfTI image file</li> <li>Handling metadata in order to set, get and search parameters</li> </ol> <p>With the current implementation, these objectives are achieved: the hMRI Toolbox handles and stores data acquisition and processing parameters as JSON-encoded metadata alongside brain imaging data sets. Outside the hMRI Toolbox, metadata can prove useful for many purposes. For quality control, metadata can help checking for protocol consistency by comparing essential parameters across sessions, subjects and sites. When processing data acquired with several protocols on several scanners from different vendors (multicentric studies), metadata provide the information to automatically extract acquisition parameters to be used as regressors of no interest in a statistical analysis. Metadata also facilitate the sorting of the data between different data types (e.g. functional MRI, structural MRI, diffusion images, etc.) together with retrieving BIDS essential parameters (e.g. session and series numbers), therefore providing all the information required to make the data archiving and storage fully BIDS-compatible (Gorgolewski2016).</p> <p>A BIDS extension proposal (BEP) is currently under development, that will define the structure and parameters necessary to describe structural acquisitions with multiple contrasts and more generally the multiparameter mapping protocols. With such BIDS extension, the hMRI Toolbox will be adapted and made fully BIDS-compliant, including the structure of the JSON-stored metadata and the structure of the output data. The required adaptation will be achieved smoothly thanks to the metadata handling functionalities, without affecting the processing part of the hMRI-toolbox.</p> <p>In the next sections, detailed syntax and many examples using the <code>metadata library</code> are provided. Good housekeeping suggestions are provided to make use of the metadata structure to track acquisition and processing steps, including processing parameters, tools and software versions.</p> <p>The current implementation rests on the SPM12 implementation of DICOM tools (<code>spm_dicom_header(s)</code>, <code>spm_dicom_essentials</code>, <code>spm_dicom_convert</code>) and relies on <code>spm_jsonread</code> and <code>spm_jsonwrite</code> for handling JSON-encoded metadata.</p> <p>From SPM12 version r7219 (released 16 November 2017) and in later versions, functionalities described in points 1. and 2. above (excluding the extended header option though) have been integrated to the DICOM import module in SPM12 ( implementation from the hMRI Toolbox).</p>"},{"location":"docs/metadataLibrary/#dicom-headers-spm_dicom_header","title":"DICOM Headers \u2013 <code>spm_dicom_header</code>","text":"<p>The following scripts are used, unchanged from the SPM12 implementation: <code>spm_dicom_header</code>, <code>spm_dicom_headers</code> and <code>spm_dicom_essentials</code>.</p>"},{"location":"docs/metadataLibrary/#dicom-to-nifti-conversion-spm_dicom_convert","title":"DICOM to NIfTI Conversion \u2013 <code>spm_dicom_convert</code>","text":"<p>An additional input argument has been added to <code>spm_dicom_convert</code> to deal with the new JSON metadata options. If JSON metadata storage is enabled, DICOM header information is stored as a JSON-formatted structure either as a separate JSON file or as extended NIfTI header (or both). If omitted or disabled, the DICOM to NIfTI conversion proceeds using exactly the same implementation as before. The output NIfTI images, extended or not, have a valid NIfTI-1 format compatible with standard NIfTI readers (MRICron, SPM, FreeSurfer, MRtrix). Note that in FSL version 5.0.9 and older, the offset defining the size of the NIfTI header (extended or not) is not read, and default (352 bytes) offset is assumed. As a result, NIfTI files containing extended headers are misread in FSL 5.0.9, and separate JSON metadata files are recommended if you plan to process your data with that version. With FSL 5.0.10, extended NIfTI files are read properly :).</p>"},{"location":"docs/metadataLibrary/#usage-and-examples-hmri-toolbox","title":"Usage and Examples - [hMRI toolbox]","text":"<p>Warning</p> <p>The usage and examples given below relate to the hMRI implementation of <code>spm_dicom_convert</code>. For usage and examples for the current SPM12 implementation (SPM12.4 - r7219), either refer to the SPM12 documentation, or to the usage and examples given a bit further below. The two implementations should merge at some point but are kept side-by-side for now.</p> <p>USAGE:</p> <pre><code>spm_dicom_convert(hdr, opts, root_dir, format, out_dir, json) Inputs are as in SPM12 except for the last json input: json - a structure with fields: extended -&gt; metadata stored as extended nii header included in the nii image [default: false] separate -&gt; metadata stored in separate json file [default: false]  anonym -&gt; 'basic' [default], 'full', 'none' (see anonymise_metadata.m)\n</code></pre> <p>EXAMPLES:</p> <pre><code>files2convert = spm_select(Inf,'^*.IMA'); outpth = spm_select(1,'dir','Select output directory'); hdr = spm_dicom_headers(files2convert); % for conversion output identical to previous SPM12 versions (no \n% metadata stored during conversion): \nfiles_converted = spm_dicom_convert(hdr,'all','flat','nii',outpth); % for conversion with creation of a separate JSON metadata file: \njson = struct('extended',false,'separate',true); files_converted = spm_dicom_convert(hdr,'all','flat','nii',outpth,json); % for conversion with insertion of the JSON metadata as NIfTI \n% extended header: \njson = struct('extended',true,'separate',false); files_converted = spm_dicom_convert(hdr,'all','flat','nii',outpth,json); % metadata can be stored simultaneously as a separate JSON file and \n% extended NIfTI header: \njson = struct('extended',true,'separate',true); files_converted = spm_dicom_convert(hdr,'all','flat','nii',outpth,json); </code></pre>"},{"location":"docs/metadataLibrary/#usage-and-examples-spm124-r7219","title":"Usage and Examples - [SPM12.4 - r7219]","text":"<p>The SPM12 implementation is limited to the usage of a separate JSON file to store the metadata. The extra argument in <code>spm_dicom_convert</code> is therefore a simple binary flag enabling (<code>meta = true</code>) or disabling (<code>meta = false</code>) the storage of the metadata.</p> <p>USAGE:    Type <code>help spm_dicom_convert</code> for a detailed description of every parameter.</p> <pre><code>spm_dicom_convert(hdr, opts, root_dir, format, out_dir, meta) meta - save metadata as sidecar JSON file [default: false]\n</code></pre> <p>EXAMPLES:</p> <pre><code>files2convert = spm_select(Inf,'^*.IMA'); outpth = spm_select(1,'dir','Select output directory'); hdr = spm_dicom_headers(files2convert); % for conversion output identical to previous SPM12 versions (no \n% metadata stored during conversion): \nfiles_converted = spm_dicom_convert(hdr,'all','flat','nii',outpth); % for conversion with creation of a separate JSON metadata file: \nmeta = true;\nfiles_converted = spm_dicom_convert(hdr,'all','flat','nii',outpth,meta); </code></pre>"},{"location":"docs/metadataLibrary/#dicom-to-nifti-conversion-spm-batch","title":"DICOM to NIfTI conversion \u2013 SPM Batch","text":"<p>The above modifications have been reflected in the SPM Batch GUI (Batch &gt; SPM &gt; Tools &gt; DICOM Import, or directly from the DICOM Import button) by adding the following option:</p> <p>JSON metadata format</p> <p>Metadata (acquisition parameters, processing steps, \u2026) can be stored in JSON format. The metadata can be stored as a separate JSON file and/or as an extended header (included in the image file, for nii output format only).</p> <p>One of the following options must be selected:</p> <pre><code>    - None - Separate JSON file - Extended nii header - Both </code></pre>"},{"location":"docs/metadataLibrary/#the-metadata-structure","title":"The Metadata Structure","text":"<p>FORMAT OF THE METADATA STRUCTURE</p> <ul> <li>Metadata are stored as simple Matlab structures \u2013 hence quite flexible and modular.</li> <li>The Matlab structure is converted into JSON (a text format transcription of the Matlab structure) to be stored in the   NIfTI header or as a separate JSON file.</li> <li>The JSON transcription is easily readable and searchable by opening the NIfTI or JSON file with a text editor.</li> <li>JSON string &lt;&gt; Matlab structure conversion easily done using <code>spm_jsonread/write</code>.</li> <li>NIfTI files with extended headers can be read without any trouble with SPM and MRIcron (existing bug with FSL though).</li> </ul> <p>CONTENT AND STRUCTURE OF THE METADATA</p> <p>The structure of the metadata is divided into the following two main fields:</p> <ul> <li> <p>Acquisition parameters (<code>hdr.acqpar</code>): this field contains the original DICOM header. It is created during   DICOM to NIfTI conversion and may be dropped if the processed image relies on several input images (e.g. when creating   a map from mtflash and b1mapping acquisitions). Note that the patient name, date of birth and DICOM file name (often   containing the patient name) fields do not appear in the metadata, while patient age (in years), sex, size and weight   are kept. Confidentiality is not guaranteed though, since confidential data may have been encoded in other fields.</p> </li> <li> <p>History (<code>hdr.history</code>): is a nested structure containing</p> <ul> <li> <p><code>procstep</code>: a structure describing the current processing step and containing</p> <ul> <li><code>descrip</code>: a brief description of the processing applied (e.g. DICOM to NIfTI conversion, realign, create   map, \u2026)</li> <li><code>version</code>: version number of the processing applied (traceability!)</li> <li><code>procpar</code>: processing parameters (relevant parameters used to process the data \u2013 e.g. for fieldmap-based   EPI undistortion: EPI readout duration, TEs of the field mapping acquisition, \u2026). Basically all the   parameters included into the matlab batch \u201cjob\u201d except for the input images.</li> </ul> </li> <li> <p><code>input</code>: an array listing the input images used for the processing. Each input (hdr.history.input(i)) is a   structure containing</p> <ul> <li><code>filename</code>: the filename of the input image</li> <li><code>history</code>: the history structure from the input image</li> </ul> </li> <li> <p><code>output</code>: a structure containing</p> <ul> <li><code>imtype</code>: image type of the current output (e.g. R1, FA, MT, ADC, \u2026)</li> <li><code>units</code>: either physical units (sec, 1/sec, \u2026), standardized units (e.g. percent units = p.u.) or   arbitrary units (a.u.)\u2026</li> </ul> </li> </ul> </li> </ul>"},{"location":"docs/metadataLibrary/#metadata-handling","title":"Metadata Handling","text":"<p>The JSON transcription of the Matlab structure is easily readable and searchable by opening the extended NIfTI or separate JSON file with a text editor. Furthermore, metadata set, get and search tools have been implemented. These tools have been added into the <code>spm12/metadata</code>directory. Type <code>help &lt;function&gt;</code> in Matlab for detailed syntax and help.</p> <p>Here is the list of most useful scripts and their summary descriptions:</p> <ul> <li>[<code>get_metadata</code>]: returns the Matlab structure described above.</li> <li>[<code>set_metadata</code>]: to write (insert, modify, overwrite) metadata in JSON files and extended NIfTI headers. In   general, metadata are initialized during the DICOM to NIfTI conversion and further modified as the processing   progresses. See also [<code>init_output_metadata_structure</code>].</li> <li>[<code>init_output_metadata_structure</code>]: to create a metadata structure to be used for newly created output images.</li> <li>[<code>get_metadata_val</code>]: returns pairs of structure fields and values agreeing with search criteria.</li> <li>[<code>find_field_name</code>]: recursively searches a Matlab structure for a specific field name according to search   criteria. Can be applied to any Matlab structure - not only the hMRI metadata!</li> </ul> <p>Note</p> <p>Note that other scripts in <code>spm12/metadata</code> are private scripts, called from other functions withing the metadata &amp; dicom import library and are not expected to be used otherwise.</p> <p>EXAMPLE 1: modify existing metadata    NB: a very basic example (NIfTI file with extended header, no JSON file associated), not the most common usage of <code>set_metadata</code>, but should help getting familiar with handling the metadata\u2026</p> <pre><code>% select nii file with extended header \nniifile = spm_select(1,'^*.nii'); % read the extended header \nhdr = get_metadata(niifile);\n% define json format (since working with NIfTI file, we can choose \n% to limit set_metadata to updating the extended header without \n% caring about updating the JSON file associated). \njson = struct('extended',true,'separate',false,'overwrite',true);\n% modify the header of the existing nii file \nmodif_hdr = hdr{1}; modif_hdr.history.procstep.descrip = 'original file with modified header'; modif_hdr.history.procstep.version = 'v0.1.2'; modif_hdr.history.procstep.procpar = []; modif_hdr.history.input(1).filename = niifile; modif_hdr.history.input(1).history = hdr{1}.history; modif_hdr.history.output.imtype = hdr{1}.history.output.imtype; modif_hdr.history.output.units = hdr{1}.history.output.units; % write the modified metadata \nset_metadata(niifile, modif_hdr, json);\n</code></pre> <p>EXAMPLE 2: save a newly computed R1 map with extended header     NB: for the example, we simply read an existing NIfTI volume and copy it into another NIfTI file to which we add an extended header.</p> <pre><code>% Select nifti file to copy \nP = spm_select(1,'^*.nii'); V = spm_vol(P); Y = spm_read_vols(V);\n% initialize new nifti object \nN = nifti; % fill up the fields and data section of the nifti object as usual... \nN.dat  = V(1).private.dat; N.dat  = file_array('R1map.nii',V.dim,V.dt,0,V.pinfo(1),V.pinfo(2)); N.mat  = V.mat; N.mat0 = V.mat; N.mat_intent  = 'Scanner'; N.mat0_intent = 'Scanner'; N.descrip = 'test creating a new NIfTI file with extended JSON header'; create(N); % write the data N.dat(:,:,:) = Y;    \n% create a new structure for the extended header \nouthdr = struct('history', struct('procstep',[],'input',[],'output',[])); % NB: since it is no longer an original image from the scanner, the field 'acqpar' is dropped. Input \n% files can be retrieved with their full acquisition parameters from the history.input field. \nouthdr.history.procstep.descrip = 'map creation'; outhdr.history.procstep.version = hmri_get_version; % insert job parameters here: \nouthdr.history.procstep.procpar = struct('par1',[1 2],'par2','test'); outhdr.history.input{1}.filename = V.fname; inhdr = get_metadata(V.fname); if ~isempty(inhdr)    outhdr.history.input{1}.history = inhdr{1}.history; else\nouthdr.history.input{1}.history = 'No history available'; end outhdr.history.output.imtype = 'R1 map';\nouthdr.history.output.units = '1/sec'; % Write the metadata as both extended NIfTI header and separate JSON file \n% NB: if no json structure provided, set_metadata will check for existing \n% JSON and NIfTI files and update the existing ones. \njson = struct('extended',true,'separate',true,'overwrite',true); set_metadata('R1map.nii', outhdr, json);\n</code></pre> <p>For an easier setting of the metadata, it is recommended to use <code>init_output_metadata_structure</code>:</p> <pre><code>input_files = {V.fname};\nproc.descrip = 'map creation';\nproc.version = hmri_get_version;\nproc.params = struct('par1',[1 2],'par2','test');\noutput.imtype = 'R1 map';\noutput.units = '1/sec';\nouthdr = init_output_metadata_structure(input_files, proc, output);\njson = struct('extended',true,'separate',true,'overwrite',true); set_metadata('R1map.nii', outhdr, json);\n</code></pre>"},{"location":"docs/metadataLibrary/#how-to-retrieve-specific-parameters-from-the-json-metadata","title":"How to Retrieve Specific Parameters from the JSON Metadata","text":"<p>This section deals mainly with the <code>acqpar</code> subfield of the JSON metadata, i.e. the parameters retrieved from the DICOM header, but the tools implemented to search the metadata structure can be used more generally to search any Matlab structure.</p> <p>Since metadata are stored as a Matlab structure, searching for a specific parameter is often equivalent to searching for the corresponding field name. For that reason, the function <code>find_field_name</code> has been implemented to recursively search for a specific field name (exact or partial match, case-sensitive or not). The <code>get_metadata_val</code> script makes use of <code>find_field_name</code> to sort out the parameters and return the desired value. More refined versions of <code>get_metadata_val</code> will be developed with time to deal with hardware/software/sequences variations. However, the front end of <code>get_metadata_val</code> should stay unchanged for backwards compatibility.</p> <p>Below are listed a series of common parameters and how they can be retrieved from the JSON metadata. If these examples don\u2019t work with your own version of MRI hardware, software and sequences, please report it as an issue on the hMRI-Toolbox repository. Other arbitrary parameters can easily be searched using the same <code>get_metadata_val</code> script. See the examples at the end of this section.</p> <ul> <li>Retrieve the whole header (type <code>help get_metadata</code> for details on the syntax and input files)   <pre><code>hdr = get_metadata('my_extended_nifti_file.nii'); </code></pre></li> <li>Excitation flip angle [deg]   <pre><code>fa = get_metadata_val(hdr{1},'FlipAngle');\n</code></pre></li> <li>Repetition time(s) [ms]   <pre><code>TR = get_metadata_val(hdr{1},'RepetitionTime'); % the repetition time of the image\nTR = get_metadata_val(hdr{1},'RepetitionTimes'); % an array of TRs if multi-TR sequence (Siemens-specific)\n</code></pre></li> <li>Echo time(s) [ms]   <pre><code>TE = get_metadata_val(hdr{1},'EchoTime'); % the echo time of the image\nTE = get_metadata_val(hdr{1},'EchoTimes'); % an array of TEs if multi-echo sequence (Siemens-specific)\n</code></pre></li> <li>Magnetization transfer (MT) pulse [1/0 according to pulse switched on/off]   <pre><code>MT = get_metadata_val(hdr{1},'MT'); </code></pre></li> <li>Field strength B0 [T]   <pre><code>B0 = get_metadata_val(hdr{1},'FieldStrength'); </code></pre></li> <li>Center frequency [Hz]   <pre><code>freq = get_metadata_val(hdr{1},'Frequency');\n</code></pre></li> <li>Protocol Name   <pre><code>ProtName = get_metadata_val(hdr{1},'ProtocolName'); </code></pre></li> <li>Sequence Name   <pre><code>SeqName = get_metadata_val(hdr{1},'SequenceName'); </code></pre></li> <li>RF spoiling phase increment (warning: sequence dependent, see comments in the code)   <pre><code>RFSpoilIncr = get_metadata_val(hdr{1},'RFSpoilingPhaseIncrement'); </code></pre></li> <li>Bandwidth per pixel (in the RO direction) in Hz/Px   <pre><code>BWPPRO = get_metadata_val(hdr{1},'BandwidthPerPixelRO'); </code></pre></li> <li>Bandwidth per pixel (in the PE direction) in Hz/Px   <pre><code>BWPPPE = get_metadata_val(hdr{1},'BandwidthPerPixelPE'); </code></pre></li> <li>PAT acceleration (structure containing all parameters)   <pre><code>PAT = get_metadata_val(hdr{1},'PATparameters'); </code></pre></li> <li>PAT acceleration factor in PE direction (in-plane)   <pre><code>RPE = get_metadata_val(hdr{1},'AccelFactorPE'); </code></pre></li> <li>PAT acceleration factor in 3D direction (through-slice direction for 3D acquisitions)   <pre><code>R3D = get_metadata_val(hdr{1},'AccelFactor3D'); </code></pre></li> <li>All WIP parameters (Siemens ASCII field: returns a structure with two fields alFree and adFree containing arrays of   long and double values respectively)   <pre><code>WIP = get_metadata_val(hdr{1},'WipParameters'); </code></pre></li> <li> <p>EPI parameters (including distortion correction)</p> <ul> <li>Short and long echo times from dual-echo field mapping:   <pre><code>TEshort = get_metadata_val(hdr_gre_field_mapping_magn{1},'EchoTime'); TElong = get_metadata_val(hdr_gre_field_mapping_magn{2},'EchoTime'); </code></pre></li> <li>EPI phase encoding direction (ROW/COL)   <pre><code>PEDir = get_metadata_val(hdr_epi{1},'PhaseEncodingDirection'); </code></pre></li> <li>EPI phase encoding direction positive (e.g. A&gt;&gt;P is positive (1), P&gt;&gt;A is negative (-1))   <pre><code>PEDirPos =get_metadata_val(hdr_epi{1},'PhaseEncodingDirectionSign');\n</code></pre></li> <li>Total EPI readout duration (warning: tricky for home-made sequences with uncompleted headers)   <pre><code>epiROdur = get_metadata_val(hdr{1},'epiReadoutDuration');\n</code></pre></li> <li>EPI echo spacing (warning: tricky for home-made sequences with uncompleted headers)   <pre><code>epiEchoSpacing = get_metadata_val(hdr{1},'EchoSpacing'); </code></pre></li> </ul> </li> <li> <p>Parameters for processing B1 maps (al_b1mapping)</p> <ul> <li>Nominal FA values (betas)   <pre><code>beta = get_metadata_val(hdr{1},'B1mapNominalFAValues');\n</code></pre></li> <li>Mixing time (TM)   <pre><code>TM = get_metadata_val(hdr{1},'B1mapMixingTime'); </code></pre></li> </ul> </li> <li> <p>DWI parameters</p> </li> </ul> <p>This is specific to Siemens DICOM metadata. In that case, the diffusion parameters can be retrieved following two   distinct ways.</p> <pre><code>1. Reading all the directions and b-values at once from CSASeriesHeaderInfo subfield      \n   *NB: the current implementation assumes that Free diffusion mode is used, with a user-defined set of diffusion\n   directions.*\n\n    - Diffusion directions: list of directions as defined in the *.dvs file (normalised or not)\n      ```matlab\n      DiffDir = get_metadata_val(hdr{1},'AllDiffusionDirections'); \n      ```\n    - b-values: list of b-values as defined in the Diff tab of the UI\n      ```matlab\n      bVal = get_metadata_val(hdr{1},'AllBValues'); \n      ```\n\n2. Reading the individual directions and b-values for each image from CSAImageHeaderInfo subfield       \n   *NB: this implementation is expected to work more generally. However, the directions are converted according to\n   the volume orientation and possibly with reference to different axes. Use with care...*\n\n    - Diffusion direction: normalised vector\n      ```matlab\n      DiffDir = get_metadata_val(hdr{1},'DiffusionDirection'); \n      ```\n    - b-values: corresponding b-value\n      ```matlab\n      bVal = get_metadata_val(hdr{1},'BValue'); \n      ```\n</code></pre>"},{"location":"docs/metadataLibrary/#general-examples-searching-for-arbitrary-parameters","title":"General Examples Searching for Arbitrary Parameters","text":"<p>The recursive search of the field names of the Matlab structure follows simple pattern matching rules. Any pattern, partial or full, case-sensitive or not, can be used. One can either use the <code>get_metadata_val</code> script with any desired pattern (see EXAMPLES 1 &amp; 2 below), or use the <code>find_field_name</code> script with more specific matching rules ( see EXAMPLES 3 &amp; 4). In the former case, the search is not case-sensitive and will retrieve any field that contains the pattern. In the latter case, one can specify whether to be case-sensitive or not, and whether to allow partial matches or not.</p> <p>In EXAMPLES 1 &amp; 2, we search for any field containing \u201cdiff\u201d because we want to identify potential diffusion parameters. The search is performed on a DWI image and on a t1-mprage image.</p> <p>EXAMPLE 1 \u2013 search in an (extended) NIfTI file containing a t1-mprage image:</p> <pre><code>[parVal, parFieldNam] = get_metadata_val('t1mprage.nii','diff'); </code></pre> <p>The output is:</p> <pre><code>parVal = \n    ulMode: 1 \nparFieldNam =\n    acqpar.CSASeriesHeaderInfo.MrPhoenixProtocol.sDiffusion\n</code></pre> <p>A single field name is found containing \u201cdiff\u201d and its value is a structure, with a single field ulMode and value 1.</p> <p>EXAMPLE 2 \u2013 search an (extended) NIfTI file containing a DWI image:</p> <pre><code>[parVal, parFieldNam] = get_metadata_val('dwi.nii','diff'); </code></pre> <p>The output is:</p> <pre><code>parVal = {    [3x1 double],    \n              'DIRECTIONAL',    \n              'GAAXkVNRAAD\\/\\/\\/\u2026',       \n              [1x1 struct],    \n              [2],    \n              [72],\n              [1x1 struct],\n              [72],    \n              [71x1 struct] } \n\nparFieldNam = {  acqpar.CSAImageHeaderInfo.DiffusionGradientDirection  \n                 acqpar.CSAImageHeaderInfo.DiffusionDirectionality  \n                 acqpar.CSAImageHeaderInfo.MRDiffusion  \n                 acqpar.CSASeriesHeaderInfo.MrPhoenixProtocol.sDiffusion  \n                 acqpar.CSASeriesHeaderInfo.MrPhoenixProtocol.sDiffusion.lDiffWeightings  \n                 acqpar.CSASeriesHeaderInfo.MrPhoenixProtocol.sDiffusion.lDiffDirections  \n                 acqpar.CSASeriesHeaderInfo.MrPhoenixProtocol.sDiffusion.sFreeDiffusionData  \n                 acqpar.CSASeriesHeaderInfo.MrPhoenixProtocol.sDiffusion.sFreeDiffusionData.lDiffDirections  \n                 acqpar.CSASeriesHeaderInfo.MrPhoenixProtocol.sDiffusion.sFreeDiffusionData.asDiffDirVector } \n</code></pre> <p>In the following examples, we search the same DWI metadata as above using <code>find_field_name</code>. Type <code>help find_field_name</code> in Matlab to know more about <code>find_field_name</code>\u2019s syntax.</p> <p>EXAMPLE 3 \u2013 search for \u201cDiff\u201d (case-sensitive and partial match): `</p> <pre><code>hdr = get_metadata('dwi.nii'); [nFieldFound, fieldList] = find_field_name(hdr{1},'Diff','caseSens', 'sensitive','matchType','partial'); </code></pre> <p>The output is:</p> <pre><code>nFieldFound = \n    9 \nfieldList =     \n'acqpar'  'CSAImageHeaderInfo'   'DiffusionGradient\u2026'             []                    []                 []    \n'acqpar'  'CSAImageHeaderInfo'   'DiffusionDirectio\u2026'             []                    []                 []    \n'acqpar'  'CSAImageHeaderInfo'   'MRDiffusion'                    []                    []                 []    \n'acqpar'  'CSASeriesHeaderInfo'  'MrPhoenixProtocol'    'sDiffusion'                    []                 []    \n'acqpar'  'CSASeriesHeaderInfo'  'MrPhoenixProtocol'    'sDiffusion'  'lDiffWeightings'                    []    \n'acqpar'  'CSASeriesHeaderInfo'  'MrPhoenixProtocol'    'sDiffusion'  'lDiffDirections'                    []    \n'acqpar'  'CSASeriesHeaderInfo'  'MrPhoenixProtocol'    'sDiffusion'  'sFreeDiffusionData'                 []    \n'acqpar'  'CSASeriesHeaderInfo'  'MrPhoenixProtocol'    'sDiffusion'  'sFreeDiffusionData'  'lDiffDirections'    \n'acqpar'  'CSASeriesHeaderInfo'  'MrPhoenixProtocol'    'sDiffusion'  'sFreeDiffusionData'  'asDiffDirVector'\n</code></pre> <p>EXAMPLE 4 \u2013 search for \u201csfreediffusiondata\u201d (case-insensitive and exact match):</p> <pre><code>hdr = get_metadata('dwi.nii'); [nFieldFound, fieldList] = find_field_name(hdr{1},'sfreediffusiondata','caseSens', 'insensitive','matchType','exact'); </code></pre> <p>The output is:</p> <pre><code>nFieldFound =     \n    1 \nfieldList =     \n'acqpar'    'CSASeriesHeaderInfo'    'MrPhoenixProtocol'    'sDiffusion'    'sFreeDiffusionData'\n</code></pre>"},{"location":"docs/processing/","title":"Spatial Processing","text":""},{"location":"docs/processing/#spatial-processing-for-quantitative-maps","title":"Spatial Processing for Quantitative Maps","text":"<p>The spatial processing implementation of the Toolbox relies on the voxel-based quantification (VBQ) approach developed by Draganski2011 to preserve the quantitative nature of qMRI maps during processing. The spatial processing part of the toolbox can be applied to any set of rotationally-invariant qMRI maps, including diffusion MRI scalar parameter maps as well as the standard (R1, PD, MT and R2*) MPM maps.</p> <p>The spatial processing pipeline for quantitative data relies on three main operational steps: segmentation, diffeomorphic deformation and tissue-weighted smoothing. They are organized in separate submodules. Except for the latter, these operations rely on SPM12 functionalities tailored to the specific requirements of qMRI. Furthermore, a standard fully integrated processing pipeline is provided as a separate sub-module to facilitate standard data processing without the need to combine the individual modules.</p> <p>The processing tools and user interface were developed with in mind the user-friendly and easy processing of parametric maps generated from a series of subjects, assuming each subject has the same small number of images (for example the four (MT, PD, R1, R2*) maps). Therefore, each module takes as input several series of images sorted per image type considered (for example the MT maps from all the subjects). The images in each series must follow the same subject-based ordering. In practice one such series of images can easily be selected, manually or through a script, by using the spm_select function features that allow the recursive search of files in all sub-folders and name-filtering according to a specific pattern.</p> <p>The three main steps and the integrated pipeline are described hereafter.</p>"},{"location":"docs/processing/#segmentation","title":"Segmentation","text":"<p>This step relies on the latest Unified Segmentation (US) algorithm as available in SPM12 (Ashburner2005) and is interfaced through a single module. Unlike the SPM12-Segment module (single-subject processing), hMRI-Segment module can handle and process successively a whole series of subjects.</p> <p>The segmentation itself relies on one structural image per subject, typically a MT map, R1 map or T1w image, and a series of tissue probability maps (TPMs). The TPMs used by default in the hMRI Toolbox were specifically derived from multi-parametric maps (Lorio2014). By default, (adjustable in the batch interface) the gray matter (GM), white matter (WM) and CSF tissue class images will be generated in native space (DARTEL imported version) and standard MNI space, with and without modulation. Moreover, the parametric maps are also warped into MNI space (without modulation and using a more basic non-linear registration than in the following section). Notably, in analogy to SPM processing, these \u2018simply normalized\u2019 qMRI maps might be analyzed without generating sample specific templates (next section) after smoothing. However, to generally improve spatial normalization results, the usage of DARTEL is recommended.</p>"},{"location":"docs/processing/#diffeomorphic-deformation","title":"Diffeomorphic deformation","text":"<p>Warning</p> <p>TODO: Reference Ashburner 2007 is missing!</p> <p>This step includes three submodules derived from the DARTEL toolbox (Ashburner2007). The key idea of DARTEL is to iteratively align the tissue class images, e.g. the gray and white matter, from a series of subjects to their own average by successively generating average shaped images with increasing overlap and detail (called \u201cTemplates\u201d). This only depends on the DARTEL-imported tissue class images from each subject.</p> <p>The three submodules included are:</p> <ul> <li>Run DARTEL, create Templates: This module warps together tissue class images from the series of subjects. A set    of Templates (population average tissue class images, with increasing sharpness) as well as, for each subject, the   deformation field to the final template are generated.</li> <li>Run DARTEL, existing Templates: If Templates already exist, this module can be used to estimate only the deformation   fields for another set of subjects (relying on the same tissue class images as those used to generate the Templates).</li> <li>Normalize to MNI: This module applies the estimated deformation field to the parametric and tissue class images and   brings them all in alignment with MNI space through an additional affine transformation. Contrary to the DARTEL   toolbox, no smoothing is applied on the normalized images. A specific smoothing operation is applied at the next   Tissue-weighted smoothing step.</li> </ul> <p>The first two modules are identical to those in the DARTEL toolbox and are also made available in the hMRI toolbox for convenience. The Normalize to MNI module is also based on the equivalent DARTEL toolbox module but was extended to efficiently warp the few parametric maps of each subject.</p>"},{"location":"docs/processing/#tissue-weighted-smoothing","title":"Tissue-weighted smoothing","text":"<p>As proposed in Draganski et al., 2011, the parametric maps should be smoothed while accounting for the partial volume contribution of the tissue density in each voxel in subject space. One tissue-weighted smoothed parameter map is generated per tissue class considered. These images can then be statistically analyzed, per parameter map and tissue class type.</p>"},{"location":"docs/processing/#integrated-pipeline","title":"Integrated pipeline","text":"<p>The standard spatial processing pipeline of parameter maps would combine four modules (Segmentation, Run DARTEL, create Templates, Normalize to MNI and finally Tissue-weighted smoothing) into a single batch. The options of each module can be adjusted and the images passed from one module to the next via virtual dependencies, as available in the batch-GUI, forming a complete processing pipeline. A simpler (but less spatially accurate) approach would skip the diffeomorphotic warping steps and only combine the Segmentation and Tissue-weighted smoothing modules.</p> <p>To help novice user, an Integrated pipeline module directly implements the whole procedure with minimal input from the user. The module only requires a few input:</p> <ul> <li>the series of structural reference images and parametric maps (one per subject),</li> <li>the width of the Tissue-weighted smoothing kernel desired,</li> <li>the type of processing pipeline, i.e. with or without diffeomorphic registration.</li> </ul> <p>All the other options from each of the intermediate steps are set by defaults (e.g. only GM and WM tissue classes are of interest and the TPMs are those from the hMRI toolbox).</p>"},{"location":"docs/processing/#batch-options","title":"Batch options","text":"<p>Work in progress\u2026</p>"},{"location":"docs/processing/#example","title":"Example","text":"<p>Work in progress\u2026</p>"},{"location":"docs/references/","title":"References","text":""},{"location":"docs/references/#abbas2014","title":"Abbas2014","text":"<p>Abbas Z, Gras V, M\u00f6llenhoff K, Keil F, Oros-Peusquens AM, Shah NJ (2014) Analysis of proton-density bias corrections based on T1 measurement for robust quantification of water content in the brain at 3 Tesla. Magn Reson Med 72(6):1735-45.</p>"},{"location":"docs/references/#arn2016","title":"Arn2016","text":"<p>Arn L, Castella R, Dupuis E, Draganski B, Lutti A (2016) Online adjustment of MRI acquisitions for optimal prospective motion correction of neuroimaging data. In: 22nd Annual Meeting of the Organization for Human Brain Mapping.</p>"},{"location":"docs/references/#ashburner2005","title":"Ashburner2005","text":"<p>Ashburner J and KJ Friston (2005) Uni\ufb01ed segmentation. NeuroImage 26(3):839\u2013851.</p>"},{"location":"docs/references/#balbastre2022","title":"Balbastre2022","text":"<p>Balbastre Y, Aghaeifar A, Corbin N, Brudfors M, Ashburner J, Callaghan MF (2022) Correcting inter-scan motion artifacts in quantitative R1 mapping at 7T. Magn Reson Med. 88: 280-291. doi:10.1002/mrm.29216</p>"},{"location":"docs/references/#balteau2018","title":"Balteau2018","text":"<p>Balteau E, Leutritz T, Weiskopf N, Reimer E, Lutti A, Callaghan MF, Mohammadi S, Tabelow K (2018) Evaluating T2* bias impact and correction strategies in quantitative proton density mapping. Proceedings of the Joint Annual Meeting ISMRM-ESMRMB, Paris, France.</p>"},{"location":"docs/references/#balteau2018a","title":"Balteau2018a","text":"<p>Balteau E, Leutritz T, Lutti A, Callaghan MF, Draganski D, Phillips C, Reimer E, Ruthotto L, Seif M, Weiskopf N, Ziegler G, Mohammadi S, Tabelow K (2018a) The hMRI analysis toolbox for quantitative MRI and in vivo histology using MRI (hMRI). Proceedings of the Joint Annual Meeting ISMRM-ESMRMB, Paris, France. [Poster pdf]</p>"},{"location":"docs/references/#bonnici2012","title":"Bonnici2012","text":"<p>Bonnici H, Chadwick M, Kumaran D, Hassabis D, Weiskopf N, Maguire E (2012) Multi-voxel pattern analysis in human hippocampal subfields. Frontiers in Human Neuroscience. 6:290.</p>"},{"location":"docs/references/#callaghan2014","title":"Callaghan2014","text":"<p>Callaghan MF, Freund P, Draganski B, Anderson E, Cappelletti M, Chowdhury R, Diedrichsen J, Fitzgerald THB, Smittenaar P, Helms G, Lutti A, Weiskopf N (2014) Widespread age-related differences in the human brain microstructure revealed by quantitative magnetic resonance imaging. Neurobiol Aging 35(8):1862\u20131872.</p>"},{"location":"docs/references/#callaghan2015a","title":"Callaghan2015a","text":"<p>Callaghan MF, Helms G, Lutti A, Mohammadi S, Weiskopf N (2015a) A general linear relaxometry model of R1 using imaging data. Magn Reson Med. 73(3):1309\u20131314.</p>"},{"location":"docs/references/#callaghan2015b","title":"Callaghan2015b","text":"<p>Callaghan MF, Josephs O, Herbst M, Zaitsev M, Todd N, Weiskopf N (2015b) An evaluation of prospective motion correction (PMC) for high resolution quantitative MRI. Frontiers in Neuroscience 9:97.</p>"},{"location":"docs/references/#callaghan2016","title":"Callaghan2016","text":"<p>Callaghan MF, Mohammadi S, Weiskopf N (2016) Synthetic quantitative MRI through relaxometry modelling. NMR Biomed 29(12):1729\u20131738.</p>"},{"location":"docs/references/#callaghan2019","title":"Callaghan2019","text":"<p>Callaghan MF, Lutti A, Ashburner J, Balteau E, Corbin N, Draganski B, Helms G, Kherif F, Leutritz T, Mohammadi S, Phillips C, Reimer E, Ruthotto L, Seif M, Tabelow K, Ziegler G, Weiskopf N (2019). Example dataset for the hMRI toolbox. Data in Brief 25:104132. doi:10.1016/j.dib.2019.104132</p>"},{"location":"docs/references/#castella2016","title":"Castella2016","text":"<p>Castella R, Dupuis E, Draganski B, Lutti A (2016) Predicting the levels of motion artefacts in R1 maps from real-time measures of head motion. In: 22nd Annual Meeting of the Organization for Human Brain Mapping.</p>"},{"location":"docs/references/#chenevert2014","title":"Chenevert2014","text":"<p>Chenevert TL, Malyarenko DI, Newitt D, Li X, Jayatilake M, Tudorica A, Fedorov A, Kikinis R, Liu TT, Muzi M, Oborski MJ, Laymon CM, Li X, Thomas Y, Jayashree K-C, Mountz JM, Kinahan PE, Rubin DL, Fennessy F, Huang W, Hylton N, Ross BD (2014) Errors in quantitative image analysis due to platform dependent image scaling. Transl Oncol. 7(1): 65\u201371.</p>"},{"location":"docs/references/#chung2010","title":"Chung2010","text":"<p>Chung S, Kim D, Breton E, Axel L (2010) Rapid B1+ mapping using a preconditioning RF pulse with TurboFLASH readout. Magn Reson Med. 64(2):439-46.</p>"},{"location":"docs/references/#corbin2021","title":"Corbin2021","text":"<p>Corbin N, Callaghan MF (2021) Imperfect spoiling in variable flip angle T1 mapping at 7T: Quantifying and minimizing impact. Magn Reson Med. 86:693\u2013708. doi:10.1002/mrm.28720</p>"},{"location":"docs/references/#deppe2007","title":"Deppe2007","text":"<p>Deppe M, Duning T, Mohammadi S, Schwindt W, Kugel H, Knecht S, Ringelstein EB (2007) Diffusion-tensor imaging at 3 T: detection of white matter alterations in neurological patients on the basis of normal values. Invest Radiol. 42(6):338-45.</p>"},{"location":"docs/references/#dick2012","title":"Dick2012","text":"<p>Dick F, Tierney AT, Lutti A, Josephs O, Sereno MI, Weiskopf N (2012) In vivo functional and myeloarchitectonic mapping of human primary auditory areas. J Neurosci. 32(46):16095-105.</p>"},{"location":"docs/references/#draganski2011","title":"Draganski2011","text":"<p>Draganski B, Ashburner J, Hutton C, Kherif F, Frackowiak R, Helms G, Weiskopf N (2011) Regional speci\ufb01city of MRI contrast parameter changes in normal ageing revealed by voxel-based quanti\ufb01cation (VBQ). Neuroimage 55(4): 1423\u20131434. [doi]</p>"},{"location":"docs/references/#edwards2021","title":"Edwards2021","text":"<p>Edwards LJ, Pine KJ, Helms G, Weiskopf N (2021) Rational approximation of the Ernst equation for dual angle R1 mapping revisited: beyond the small flip-angle assumption. In Book of Abstracts ESMRMB 2021, Magn Reson Mater Phy. doi:10.1007/s10334-021-00947-8.</p>"},{"location":"docs/references/#edwards2022","title":"Edwards2022","text":"<p>Edwards LJ, Mohammadi S, Pine KJ, Callaghan MF, Weiskopf N (2022) Robust and efficient R2* estimation in human brain using log-linear weighted least squares. In: Proc Int Soc Magn Reson Med Vol. 31.</p>"},{"location":"docs/references/#ellerbrock2018","title":"Ellerbrock2018","text":"<p>Ellerbrock I, Mohammadi S (2018) Four in vivo g-ratio-weighted imaging methods: Comparability and repeatability at the group level. Hum Brain Mapp 39(1):24-41 &amp; Corrigendum in Hum Brain Mapp 39(3):1467.</p>"},{"location":"docs/references/#ernst1966","title":"Ernst1966","text":"<p>Ernst RR and Anderson WA (1966) Application of Fourier Transform Spectroscopy to Magnetic Resonance. Review of Scientific Instruments 37:93\u2013102.</p>"},{"location":"docs/references/#freund2013","title":"Freund2013","text":"<p>Freund P, Weiskopf N, Ashburner J, Wolf K, Sutter R, Altmann DR, Friston K, Thompson A, Curt A (2013) MRI investigation of the sensorimotor cortex and the corticospinal tract after acute spinal cord injury: a prospective longitudinal study. The Lancet Neurology. 12(9):873\u2013881.</p>"},{"location":"docs/references/#gomez2017","title":"Gomez2017","text":"<p>Gomez J, Barnett MA, Natu V, Mezer A, Palomero-Gallagher N, Weiner KS, Amunts K, Zilles K, Grill-Spector K (2017 ) Microstructural proliferation in human cortex is coupled with the development of face processing. Science. 355( 6320):68\u201371.</p>"},{"location":"docs/references/#gorgolewski2016","title":"Gorgolewski2016","text":"<p>Gorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff EP, Flandin G, Ghosh SS, Glatard T, Halchenko YO, Handwerker DA, Hanke M, Keator D, Li X, Michael Z, Maumet C, Nichols BN, Nichols TE, Pellman J, Poline JB, Rokem A, Schaefer G, Sochat V, Triplett W, Turner JA, Varoquaux G, Poldrack RA (2016) The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Sci Data. 3:160044.</p>"},{"location":"docs/references/#grabher2015","title":"Grabher2015","text":"<p>Grabher P, Callaghan MF, Ashburner J, Weiskopf N, Thompson AJ, Curt A, Freund P (2015) Tracking sensory system atrophy and outcome prediction in spinal cord injury. Ann Neurol. 78(5):751-61.</p>"},{"location":"docs/references/#helms2003","title":"Helms2003","text":"<p>Helms G, Hagberg GE (2003) Quantification of magnetization transfer by sampling the transient signal using MT-prepared single-shot EPI. Concepts in Magnetic Resonance Part A 19A(2):149\u2013152.</p>"},{"location":"docs/references/#helms2008a","title":"Helms2008a","text":"<p>Helms G, Dathe H, Dechent P (2008a) Quantitative FLASH MRI at 3T Using a Rational Approximation of the Ernst Equation. Magnetic Resonance in Medicine 59:667\u2013672.</p>"},{"location":"docs/references/#helms2008b","title":"Helms2008b","text":"<p>Helms G, Dathe H, Kallenberg K, Dechent P (2008b) High-resolution maps of magnetization transfer with inherent correction for RF inhomogeneity and T1 relaxation obtained from 3D FLASH MRI. Magnetic Resonance in Medicine 60(6): 1396\u20131407.</p>"},{"location":"docs/references/#helms2009","title":"Helms2009","text":"<p>Helms G, Draganski B, Frackowiak R, Ashburner J, Weiskopf N (2009). Improved segmentation of deep brain grey matter structures using magnetization transfer (MT) parameter maps. NeuroImage 47(1):194\u2013198.</p>"},{"location":"docs/references/#helms2015","title":"Helms2015","text":"<p>Helms G (2015). Correction for residual effects of B1+ inhomogeniety on MT saturation in FLASH based multi-parameter mapping of the brain. In: Proc. Intl. Soc. Mag. Reson. Med. Vol. 23.</p>"},{"location":"docs/references/#keller2012","title":"Keller2012","text":"<p>Keller SS, Gerdes JS, Mohammadi S, Kellinghaus C, Kugel H, Deppe K, Ringelstein EB, Evers S, Schwindt W, Deppe M ( 2012) Volume estimation of the thalamus using freesurfer and stereology: consistency between methods. Neuroinformatics. 10(4):341-50.</p>"},{"location":"docs/references/#kleffner2008","title":"Kleffner2008","text":"<p>Kleffner I, Deppe M, Mohammadi S, Schiffbauer H, Stupp N, Lohmann H, Young P, Ringelstein EB (2008) Diffusion tensor imaging demonstrates fiber impairment in Susac syndrome. Neurology. 70(19 Pt 2):1867-9.</p>"},{"location":"docs/references/#lambert2013","title":"Lambert2013","text":"<p>Lambert C, Lutti A, Helms G, Frackowiak R, Ashburner J (2013) Multiparametric brainstem segmentation using a modified multivariate mixture of Gaussians. Neuroimage Clin. 2:684-94.</p>"},{"location":"docs/references/#lorio2014","title":"Lorio2014","text":"<p>Lorio S, Lutti A, Kherif F, Ruef A, Dukart J, Chowdhury R, Frackowiak RS, Ashburner J, Helms G, Weiskopf N, Draganski B (2014) Disentangling in vivo the effects of iron content and atrophy on the ageing human brain. Neuroimage. 103:280-9.</p>"},{"location":"docs/references/#lorio2016a","title":"Lorio2016a","text":"<p>Lorio S, Fresard S, Adaszewski S, Kherif F, Chowdhury R, Frackowiak RS, Ashburner J, Helms G, Weiskopf N, Lutti A, Draganski B (2016a) New tissue priors for improved automated classification of subcortical brain structures on MRI. Neuroimage. 130:157-166.</p>"},{"location":"docs/references/#lorio2016b","title":"Lorio2016b","text":"<p>Lorio S, Kherif F, Ruef A, Melie-Garcia L, Frackowiak R, Ashburner J, Helms G, Lutti A, Draganski B (2016b) Neurobiological origin of spurious brain morphological changes: A quantitative MRI study. Hum Brain Mapp. 37(5): 1801-15.</p>"},{"location":"docs/references/#lutti2009","title":"Lutti2009","text":"<p>Lutti A, Hutton C, Weiskopf N (2009) Optimization of 3D EPI technique for radio frequency (B1) \ufb01eld mapping at 3T. In: Proceedings 17th Scienti\ufb01c Meeting, International Society for Magnetic Resonance in Medicine, 2797.</p>"},{"location":"docs/references/#lutti2010","title":"Lutti2010","text":"<p>Lutti A, Hutton C, Finsterbusch J, Helms G, Weiskopf N (2010) Optimization and validation of methods for mapping of the radiofrequency transmit field at 3T. Magn Reson Med 64(1):229-38.</p>"},{"location":"docs/references/#lutti2012","title":"Lutti2012","text":"<p>Lutti A, Stadler J, Josephs O, Windischberger C, Speck O, Bernarding J, Hutton C, Weiskopf N (2012) Robust and fast whole brain mapping of the RF transmit field B1 at 7T. PLoS One. 7(3):e32379.</p>"},{"location":"docs/references/#lutti2014","title":"Lutti2014","text":"<p>Lutti A, Dick F, Sereno MI, Weiskopf N (2014) Using high-resolution quantitative mapping of R1 as an index of cortical myelination. Neuroimage. 93(2):176-88.</p>"},{"location":"docs/references/#lutti2022","title":"Lutti2022","text":"<p>Lutti A, et al. (2022) Restoring statistical validity in group analyses of motion-corrupted MRI data. Human Brain Mapping. doi:10.1002/hbm.25767</p>"},{"location":"docs/references/#mezer2016","title":"Mezer2016","text":"<p>Mezer A, Rokem A, Berman S, Hastie T, Wandell BA (2016) Evaluating quantitative proton-density-mapping methods. Hum Brain Mapp 37(10):3623-35.</p>"},{"location":"docs/references/#neeb2006","title":"Neeb2006","text":"<p>Neeb H, Zilles K, Shah NJ (2006). A new method for fast quantitative mapping of absolute water content in vivo. Neuroimage. 31(3):1156-68.</p>"},{"location":"docs/references/#mohammadi2015","title":"Mohammadi2015","text":"<p>Mohammadi S, Carey D, Dick F, Diedrichsen J, Sereno MI, Reisert M, Callaghan MF, Weiskopf N (2015) Whole-Brain In-vivo Measurements of the Axonal G-Ratio in a Group of 37 Healthy Volunteers. Front Neurosci 9, 441. doi:10.3389/fnins.2015.00441</p>"},{"location":"docs/references/#mohammadi2017","title":"Mohammadi2017","text":"<p>Mohammadi S, D\u2019alonzo Ch, Ruthotto L, Polzehl J, Ellerbrock I, Callaghan MF, Weiskopf N, Tabelow K (2017) Simultaneous adaptive smoothing of relaxometry and quantitative magnetization transfer mapping. Preprint no. 2432, WIAS, Berlin, doi: 10.20347/WIAS.PREPRINT.2432</p>"},{"location":"docs/references/#papp2016","title":"Papp2016","text":"<p>Papp, D., Callaghan, M. F., Meyer, H., Buckley, C., Weiskopf, N. (2016) Correction of inter-scan motion artifacts in quantitative R1 mapping by accounting for receive coil sensitivity effects. Magn. Reson. Med. 76(5), 1478\u20131485.</p>"},{"location":"docs/references/#phillips2018","title":"Phillips2018","text":"<p>Phillips C, Balteau E, Leutritz T, Lutti A, Callaghan MF, Draganski D, Reimer E, Ruthotto L, Seif M, Weiskopf N, Ziegler G, Mohammadi S, Tabelow K (2018) The hMRI analysis toolbox for quantitative MRI and in vivo histology using MRI (hMRI). Organization for Human Brain Mapping Annual Meeting, Singapore. [Poster pdf]</p>"},{"location":"docs/references/#preibisch2009","title":"Preibisch2009","text":"<p>Preibisch C, Deichmann R (2009) Influence of RF spoiling on the stability and accuracy of T1 mapping based on spoiled FLASH with varying flip angles. Magn Reson Med. 61(1):125-35.</p>"},{"location":"docs/references/#samson2013","title":"Samson2013","text":"<p>Samson RS, Ciccarelli O, Kachramanoglou C, Brightman L, Lutti A, Thomas DL, Weiskopf N, Wheeler-Kingshott CA ( 2013) Tissue and column-specific measurements from multi-parameter mapping of the human cervical spinal cord at 3 T. NMR Biomed. 26(12):1823-30.</p>"},{"location":"docs/references/#sereno2013","title":"Sereno2013","text":"<p>Sereno MI, Lutti A, Weiskopf N, Dick F (2013) Mapping the human cortical surface by combining quantitative T(1) with retinotopy. Cereb Cortex. 23(9):2261-8.</p>"},{"location":"docs/references/#sinclear2010","title":"Sinclear2010","text":"<p>Sinclair CD, Samson RS, Thomas DL, Weiskopf N, Lutti A, Thornton JS, Golay X (2010) Quantitative magnetization transfer in in vivo healthy human skeletal muscle at 3T. Magn Reson Med. 64(6):1739-48.</p>"},{"location":"docs/references/#tabelow2016","title":"Tabelow2016","text":"<p>Tabelow K, D\u2019Alonzo C, Polzehl J, Callaghan MF, Ruthotto L, Weiskopf N, Mohammadi S (2016) How to achieve very high resolution quantitative MRI at 3T. In: 22nd Annual Meeting of the Organization for Human Brain Mapping, Geneva, Switzerland.</p>"},{"location":"docs/references/#tabelow2017","title":"Tabelow2017","text":"<p>Tabelow K, D\u2019alonzo Ch, Ruthotto L, Callaghan MF, Weiskopf N, Polzehl J, Mohammadi S (2017). Removing the estimation bias due to the noise floor in multi-parameter maps. The International Society for Magnetic Resonance in Medicine (ISMRM) 25th Annual Meeting &amp; Exhibition, Honolulu, USA.</p>"},{"location":"docs/references/#tabelow2019","title":"Tabelow2019","text":"<p>Tabelow K, Balteau E, Ashburner J, Callaghan MF, Draganski B, Helms G, Kherif F, Leutritz T, Lutti A, Phillips C, Reimer E, Ruthotto L, Seif M, Weiskopf N, Ziegler G, Mohammadi S (2019) hMRI \u2013 A toolbox for quantitative MRI in neuroscience and clinical research. Neuroimage. doi:10.1016/j.neuroimage.2019.01.029.</p>"},{"location":"docs/references/#tofts2003","title":"Tofts2003","text":"<p>Tofts PS (2003) PD: Proton Density of Tissue Water. In: Quantitative MRI of the Brain: Measuring Changes Caused by Disease. Wiley &amp; Sons, Chichester, UK, pp.85\u2013110.</p>"},{"location":"docs/references/#trampel2017","title":"Trampel2017","text":"<p>Trampel R, Bazin PL, Pine K, Weiskopf N (2017) In-vivo magnetic resonance imaging (MRI) of laminae in the human cortex. Neuroimage. doi: 10.1016/j.neuroimage.2017.09.037.</p>"},{"location":"docs/references/#volz2012","title":"Volz2012","text":"<p>Volz S, N\u00f6th U, Deichmann R (2012) Correction of systematic errors in quantitative proton density mapping. Magn Reson Med. 68(1):74-85.</p>"},{"location":"docs/references/#weiskopf2008","title":"Weiskopf2008","text":"<p>Weiskopf N and G Helms (2008) Multi-parameter mapping of the human brain at 1mm resolution in less than 20 minutes. In: Proceedings of ISMRM 16, Toronto, Canada. 2241.</p>"},{"location":"docs/references/#weiskopf2011","title":"Weiskopf2011","text":"<p>Weiskopf N, Lutti A, Helms G, Novak M, Ashburner J, Hutton C (2011) Uni\ufb01ed segmentation based correction of R1 brain maps for RF transmit field inhomogeneities (UNICORT). Neuroimage 54(3):2116\u20132124.</p>"},{"location":"docs/references/#weiskopf2013","title":"Weiskopf2013","text":"<p>Weiskopf N, Suckling J, Williams G, Correia MM, Inkster B, Tait R, Ooi C, Bullmore ET, Lutti A (2013) Quantitative multi-parameter mapping of R1, PD*, MT, and R2* at 3T: a multi-center validation. Frontiers in Neuroscience 7:95. doi:10.3389/fnins.2013.00095</p>"},{"location":"docs/references/#weiskopf2014","title":"Weiskopf2014","text":"<p>Weiskopf N, Callaghan MF, Josephs O, Lutti A, Mohammadi S (2014) Estimating the apparent transverse relaxation time (R2*) from images with different contrasts (ESTATICS) reduces motion artifacts. Frontiers in Neuroscience 8:278.</p>"},{"location":"docs/references/#weiskopf2015","title":"Weiskopf2015","text":"<p>Weiskopf N, Mohammadi S, Lutti A, Callaghan MF (2015) Advances in MRI-based computational neuroanatomy: from morphometry to in-vivo histology. Curr Opin Neurol. 28(4): 313-22. doi:10.1097/WCO.0000000000000222</p>"},{"location":"docs/references/#wheeler-kingshott2014","title":"Wheeler-Kingshott2014","text":"<p>Wheeler-Kingshott CA, Stroman PW, Schwab JM, Bacon M, Bosma R, Brooks J, Cadotte DW, Carlstedt T, Ciccarelli O, Cohen-Adad J, Curt A, Evangelou N, Fehlings MG, Filippi M, Kelley BJ, Kollias S, Mackay A, Porro CA, Smith S, Strittmatter SM, Summers P, Thompson AJ, Tracey I (2014) The current state-of-the-art of spinal cord imaging: applications. Neuroimage. 84:1082-93.</p>"},{"location":"docs/references/#woollett2008","title":"Woollett2008","text":"<p>Woollett K, Glensman J, Maguire EA (2008) Non-spatial expertise and hippocampal gray matter volume in humans. Hippocampus. 18(10):981-4.</p>"},{"location":"docs/references/#yarnykh2007","title":"Yarnykh2007","text":"<p>Yarnykh VL (2007) Actual flip-angle imaging in the pulsed steady state: a method for rapid three-dimensional mapping of the transmitted radiofrequency field. Magn Reson Med. 57(1):192-200.</p>"},{"location":"docs/references/#yeatman2014","title":"Yeatman2014","text":"<p>Yeatman JD, Wandell BA, Mezer AA (2014) Lifespan maturation and degeneration of human brain white matter. Nat Commun. 5:4932.</p>"},{"location":"docs/releases/","title":"Releases","text":""},{"location":"docs/releases/#releases-and-versioning","title":"Releases and Versioning","text":"<p>In general, using the latest version of the toolbox is recommended. However, for a given study, it is important to process all the data with the same version of the toolbox.</p> <p>Warning</p> <p>Do not update the toolbox version halfway through processing your data!</p> <p>Please report the release version number used when describing and publishing your results.</p>"},{"location":"docs/releases/#releases-and-master-branch","title":"Releases and Master Branch","text":"<p>Official releases and tags are listed on the repository\u2019s releases page.</p> <p>The versions, notable changes between them and their backward compatibility are documented in the CHANGELOG.md file.</p> <p>The master branch of the repository may include recent developments not included in the last official release, but it is not a development branch. The master branch can include additional small bug fixes and minor changes, but no major changes impairing the backward compatibility of the toolbox. Refer to the diff link on the releases page (commit(s) to master since this release) to compare a release to the current state of the master branch.</p> <p>Developments are carried out on the developer\u2019s own repository forked from the master branch and merged to the master branch when appropriate (see Develop &amp; Contribute for details).</p>"},{"location":"docs/releases/#versioning","title":"Versioning","text":"<p>Version numbers follow broadly the principles of the semantic versioning system. The format of the version number is <code>major.minor.patch</code>. For example:</p> <ul> <li>Bug fix: increment the patch number (e.g. <code>1.0.1</code> to <code>1.0.2</code>)</li> <li>New feature (with backward compatibility ensuring that toolbox behaviour is identical if not making use of the new   feature): increment the minor number and reset patch (e.g. <code>1.2.2</code> to <code>1.3.0</code>)</li> <li>Major change: refactoring and important new features that may or may not alter the backward compatibility (refer to   the CHANGELOG.md file to check for compatibility): increment the major number and reset minor and   patch (e.g. <code>1.2.2</code> to <code>2.0.0</code>).</li> </ul>"}]}